"""
This file is part of Intellicrack.
Copyright (C) 2025 Zachary Flint

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.

AI-powered vulnerability research controller for managing research workflows.
"""

import sys
import traceback
from typing import Any, Dict, List, Optional

from PyQt6.QtCore import QObject, QRunnable, QThreadPool, pyqtSignal, pyqtSlot

from intellicrack.logger import logger

try:
    from ...ai.vulnerability_research_integration import VulnerabilityResearchAI
    from ...ai.llm_backends import LLMBackends
    from ...ai.multi_agent_system import MultiAgentSystem
    from ...ai.predictive_intelligence import PredictiveIntelligence
    AI_AVAILABLE = True
except ImportError as e:
    logger.error("AI integration import error: %s", e)
    AI_AVAILABLE = False
    
    class VulnerabilityResearchAI:
        def analyze_target_with_ai(self, target_path: str, analysis_options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
            return {"success": False, "error": "AI components not available"}
        
        def execute_automated_exploitation(self, target_info: Dict[str, Any], exploitation_config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
            return {"success": False, "error": "AI components not available"}
        
        def get_ai_insights(self, target_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
            return {"error": "AI components not available"}


class WorkerSignals(QObject):
    """
    Defines the signals available from a running worker thread.
    Supported signals are:
    - finished: No data
    - error: tuple (exctype, value, traceback.format_exc())
    - result: object data returned from processing
    - progress: str indicating progress message
    """
    finished = pyqtSignal()
    error = pyqtSignal(tuple)
    result = pyqtSignal(object)
    progress = pyqtSignal(str)


class AIAnalysisWorker(QRunnable):
    """
    Worker thread for AI analysis operations.
    Inherits from QRunnable to handle worker thread setup, signals and wrap-up.
    """
    
    def __init__(self, ai_service, operation, *args, **kwargs):
        super().__init__()
        self.ai_service = ai_service
        self.operation = operation
        self.args = args
        self.kwargs = kwargs
        self.signals = WorkerSignals()
        
    @pyqtSlot()
    def run(self):
        """Execute the AI operation in background thread."""
        try:
            if self.operation == "analyze":
                self.signals.progress.emit("Starting AI-powered vulnerability analysis...")
                result = self.ai_service.analyze_target_with_ai(*self.args, **self.kwargs)
                
            elif self.operation == "exploit":
                self.signals.progress.emit("Executing automated exploitation workflow...")
                result = self.ai_service.execute_automated_exploitation(*self.args, **self.kwargs)
                
            elif self.operation == "insights":
                self.signals.progress.emit("Generating AI insights and recommendations...")
                result = self.ai_service.get_ai_insights(*self.args, **self.kwargs)
                
            else:
                raise ValueError(f"Unknown operation: {self.operation}")
                
            self.signals.progress.emit("AI operation completed successfully.")
            
        except Exception:
            traceback.print_exc()
            exctype, value = sys.exc_info()[:2]
            self.signals.error.emit((exctype, value, traceback.format_exc()))
        else:
            self.signals.result.emit(result)
        finally:
            self.signals.finished.emit()


class VulnerabilityResearchController(QObject):
    """
    Controller for AI-powered vulnerability research operations.
    Manages coordination between UI and AI services using background workers.
    """
    
    # Analysis signals
    analysis_started = pyqtSignal()
    analysis_progress = pyqtSignal(str)
    analysis_finished = pyqtSignal(dict)
    
    # Exploitation signals
    exploitation_started = pyqtSignal()
    exploitation_progress = pyqtSignal(str)
    exploitation_finished = pyqtSignal(dict)
    
    # Insights signals
    insights_started = pyqtSignal()
    insights_ready = pyqtSignal(dict)
    
    # General signals
    error_occurred = pyqtSignal(str)
    operation_finished = pyqtSignal()
    
    def __init__(self, parent: QObject = None):
        """Initialize the vulnerability research controller."""
        super().__init__(parent)
        
        self.logger = logger.getChild("VulnerabilityResearchController")
        
        # Initialize AI services
        if AI_AVAILABLE:
            self.ai_service = VulnerabilityResearchAI()
            self.llm_backends = LLMBackends()
            self.multi_agent = MultiAgentSystem()
            self.predictive_intelligence = PredictiveIntelligence()
        else:
            self.ai_service = VulnerabilityResearchAI()
            self.llm_backends = None
            self.multi_agent = None
            self.predictive_intelligence = None
        
        # Thread pool for background operations
        self.threadpool = QThreadPool()
        self.threadpool.setMaxThreadCount(4)  # Limit concurrent AI operations
        
        self.logger.info(f"Controller initialized with {self.threadpool.maxThreadCount()} worker threads")
        
        # Track active operations
        self.active_operations = set()
        
    @pyqtSlot(str, dict)
    def start_vulnerability_analysis(self, target_path: str, options: Dict[str, Any]):
        """Start AI-powered vulnerability analysis."""
        if not AI_AVAILABLE:
            self.error_occurred.emit("AI components not available - analysis cannot proceed")
            return
            
        if "analysis" in self.active_operations:
            self.error_occurred.emit("Analysis already in progress")
            return
            
        self.logger.info(f"Starting vulnerability analysis for: {target_path}")
        
        # Enhanced analysis options with AI configuration
        enhanced_options = {
            **options,
            "ai_enabled": True,
            "use_llm_analysis": options.get("use_llm", True),
            "multi_agent_enabled": options.get("multi_agent", False),
            "predictive_analysis": options.get("predictive", True),
            "confidence_threshold": options.get("confidence_threshold", 0.7)
        }
        
        self.active_operations.add("analysis")
        self.analysis_started.emit()
        
        worker = AIAnalysisWorker(self.ai_service, "analyze", target_path, enhanced_options)
        worker.signals.result.connect(self._on_analysis_finished)
        worker.signals.error.connect(self._handle_error)
        worker.signals.progress.connect(self._on_analysis_progress)
        worker.signals.finished.connect(lambda: self._cleanup_operation("analysis"))
        
        self.threadpool.start(worker)
        
    @pyqtSlot(dict, dict)
    def start_automated_exploitation(self, target_info: Dict[str, Any], config: Dict[str, Any]):
        """Start automated exploitation workflow."""
        if not AI_AVAILABLE:
            self.error_occurred.emit("AI components not available - exploitation cannot proceed")
            return
            
        if "exploitation" in self.active_operations:
            self.error_occurred.emit("Exploitation already in progress")
            return
            
        self.logger.info("Starting automated exploitation workflow")
        
        # Enhanced exploitation config with AI features
        enhanced_config = {
            **config,
            "ai_guided": True,
            "adaptive_strategy": config.get("adaptive", True),
            "automated_learning": config.get("learning", True),
            "real_time_adaptation": config.get("real_time", False)
        }
        
        self.active_operations.add("exploitation")
        self.exploitation_started.emit()
        
        worker = AIAnalysisWorker(self.ai_service, "exploit", target_info, enhanced_config)
        worker.signals.result.connect(self._on_exploitation_finished)
        worker.signals.error.connect(self._handle_error)
        worker.signals.progress.connect(self._on_exploitation_progress)
        worker.signals.finished.connect(lambda: self._cleanup_operation("exploitation"))
        
        self.threadpool.start(worker)
        
    @pyqtSlot()
    def request_ai_insights(self, target_info: Optional[Dict[str, Any]] = None):
        """Request AI insights and recommendations."""
        if not AI_AVAILABLE:
            self.error_occurred.emit("AI components not available - insights cannot be generated")
            return
            
        self.logger.info("Requesting AI insights")
        
        self.insights_started.emit()
        
        worker = AIAnalysisWorker(self.ai_service, "insights", target_info)
        worker.signals.result.connect(self._on_insights_ready)
        worker.signals.error.connect(self._handle_error)
        worker.signals.finished.connect(self.operation_finished)
        
        self.threadpool.start(worker)
        
    @pyqtSlot(dict)
    def prioritize_vulnerabilities(self, vulnerabilities: Dict[str, Any]):
        """Use AI to prioritize and classify vulnerabilities."""
        if not AI_AVAILABLE or not self.predictive_intelligence:
            self.error_occurred.emit("Predictive intelligence not available")
            return
            
        try:
            # Use predictive intelligence for vulnerability prioritization
            prioritized = self.predictive_intelligence.prioritize_vulnerabilities(vulnerabilities)
            self.analysis_finished.emit({"prioritized_vulnerabilities": prioritized})
            
        except Exception as e:
            self.logger.error(f"Vulnerability prioritization failed: {e}")
            self.error_occurred.emit(f"Prioritization failed: {str(e)}")
            
    @pyqtSlot(dict)
    def assess_exploit_feasibility(self, vulnerability: Dict[str, Any]):
        """Assess exploit feasibility using AI analysis."""
        if not AI_AVAILABLE:
            self.error_occurred.emit("AI components not available for feasibility assessment")
            return
            
        try:
            # Use AI service for feasibility assessment
            assessment = self.ai_service.analyze_target_with_ai(
                vulnerability.get("target_path", ""),
                {"focus": "exploit_feasibility", "vulnerability": vulnerability}
            )
            
            feasibility_data = {
                "vulnerability_id": vulnerability.get("id"),
                "feasibility_score": assessment.get("risk_assessment", {}).get("exploitation_likelihood", 0.5),
                "confidence": assessment.get("risk_assessment", {}).get("risk_score", 0.5),
                "recommendations": assessment.get("ai_recommendations", []),
                "exploitation_strategies": assessment.get("exploitation_strategies", [])
            }
            
            self.analysis_finished.emit({"feasibility_assessment": feasibility_data})
            
        except Exception as e:
            self.logger.error(f"Feasibility assessment failed: {e}")
            self.error_occurred.emit(f"Feasibility assessment failed: {str(e)}")
            
    def _on_analysis_finished(self, result: Dict[str, Any]):
        """Handle analysis completion."""
        self.logger.info("Vulnerability analysis completed")
        
        # Enhance results with additional AI insights
        enhanced_result = self._enhance_analysis_results(result)
        self.analysis_finished.emit(enhanced_result)
        
    def _on_exploitation_finished(self, result: Dict[str, Any]):
        """Handle exploitation completion."""
        self.logger.info("Automated exploitation completed")
        self.exploitation_finished.emit(result)
        
    def _on_insights_ready(self, result: Dict[str, Any]):
        """Handle insights completion."""
        self.logger.info("AI insights generated")
        self.insights_ready.emit(result)
        
    def _on_analysis_progress(self, message: str):
        """Handle analysis progress updates."""
        self.analysis_progress.emit(message)
        
    def _on_exploitation_progress(self, message: str):
        """Handle exploitation progress updates."""
        self.exploitation_progress.emit(message)
        
    def _enhance_analysis_results(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """Enhance analysis results with additional AI insights."""
        enhanced = results.copy()
        
        try:
            # Add confidence scoring
            if "analysis_results" in enhanced:
                analysis_results = enhanced["analysis_results"]
                
                # Calculate overall confidence score
                vulnerabilities = analysis_results.get("vulnerabilities", [])
                if vulnerabilities:
                    confidence_scores = []
                    for vuln in vulnerabilities:
                        # Use AI to assess confidence in vulnerability detection
                        base_confidence = vuln.get("confidence", 0.7)
                        ai_confidence = self._calculate_ai_confidence(vuln)
                        combined_confidence = (base_confidence + ai_confidence) / 2
                        vuln["ai_confidence"] = combined_confidence
                        confidence_scores.append(combined_confidence)
                    
                    enhanced["overall_confidence"] = sum(confidence_scores) / len(confidence_scores)
                    
            # Add AI reasoning for top vulnerabilities
            if "ai_recommendations" in enhanced:
                recommendations = enhanced["ai_recommendations"]
                if isinstance(recommendations, list) and recommendations:
                    # Use LLM to generate detailed reasoning
                    if self.llm_backends:
                        try:
                            reasoning = self._generate_ai_reasoning(enhanced)
                            enhanced["ai_reasoning"] = reasoning
                        except Exception as e:
                            self.logger.debug(f"Could not generate AI reasoning: {e}")
                            
            # Add exploitation timeline predictions
            if "exploitation_strategies" in enhanced:
                strategies = enhanced["exploitation_strategies"]
                for strategy in strategies:
                    strategy["ai_timeline_prediction"] = self._predict_exploitation_timeline(strategy)
                    
        except Exception as e:
            self.logger.error(f"Error enhancing analysis results: {e}")
            
        return enhanced
        
    def _calculate_ai_confidence(self, vulnerability: Dict[str, Any]) -> float:
        """Calculate AI confidence score for vulnerability."""
        base_score = 0.5
        
        # Boost confidence based on vulnerability characteristics
        severity = vulnerability.get("severity", "low").lower()
        if severity == "critical":
            base_score += 0.3
        elif severity == "high":
            base_score += 0.2
        elif severity == "medium":
            base_score += 0.1
            
        # Boost confidence if multiple detection methods agree
        detection_methods = vulnerability.get("detection_methods", [])
        if len(detection_methods) > 1:
            base_score += 0.1 * (len(detection_methods) - 1)
            
        return min(1.0, base_score)
        
    def _generate_ai_reasoning(self, results: Dict[str, Any]) -> str:
        """Generate AI reasoning for analysis results."""
        if not self.llm_backends:
            return "AI reasoning not available"
            
        try:
            # Prepare context for LLM
            context = {
                "vulnerability_count": len(results.get("analysis_results", {}).get("vulnerabilities", [])),
                "risk_level": results.get("risk_assessment", {}).get("overall_risk", "unknown"),
                "confidence": results.get("overall_confidence", 0.5)
            }
            
            prompt = f"""
            Based on the vulnerability analysis results:
            - Found {context['vulnerability_count']} vulnerabilities
            - Overall risk level: {context['risk_level']}
            - AI confidence: {context['confidence']:.2f}
            
            Provide a concise technical reasoning for these findings and recommended next steps.
            """
            
            response = self.llm_backends.generate_response(prompt, max_tokens=200)
            return response.get("content", "Unable to generate reasoning")
            
        except Exception as e:
            self.logger.error(f"Error generating AI reasoning: {e}")
            return f"Reasoning generation failed: {str(e)}"
            
    def _predict_exploitation_timeline(self, strategy: Dict[str, Any]) -> Dict[str, str]:
        """Predict exploitation timeline using AI."""
        # Default timeline based on strategy complexity
        default_timeline = {
            "preparation": "2-4 hours",
            "exploitation": "1-2 hours", 
            "post_exploitation": "1-3 hours"
        }
        
        try:
            if self.predictive_intelligence:
                predicted = self.predictive_intelligence.predict_exploitation_timeline(strategy)
                return predicted if predicted else default_timeline
        except Exception:
            pass
            
        return default_timeline
        
    def _handle_error(self, error_tuple):
        """Handle errors from worker threads."""
        exctype, value, tb = error_tuple
        error_msg = f"AI operation failed: {str(value)}"
        self.logger.error(f"Worker thread error: {error_msg}\n{tb}")
        self.error_occurred.emit(error_msg)
        
    def _cleanup_operation(self, operation_name: str):
        """Clean up completed operation."""
        self.active_operations.discard(operation_name)
        self.operation_finished.emit()
        
    def get_ai_status(self) -> Dict[str, Any]:
        """Get current AI system status."""
        return {
            "ai_available": AI_AVAILABLE,
            "active_operations": list(self.active_operations),
            "worker_threads": self.threadpool.activeThreadCount(),
            "max_threads": self.threadpool.maxThreadCount(),
            "llm_available": self.llm_backends is not None,
            "multi_agent_available": self.multi_agent is not None,
            "predictive_available": self.predictive_intelligence is not None
        }
        
    def shutdown(self):
        """Shutdown the controller and clean up resources."""
        self.logger.info("Shutting down vulnerability research controller")
        self.threadpool.clear()
        self.threadpool.waitForDone(5000)  # Wait up to 5 seconds