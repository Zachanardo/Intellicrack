"""This file is part of Intellicrack.
Copyright (C) 2025 Zachary Flint

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.

Vulnerability research dialog for security analysis workflows.
"""
import hashlib
import json
import os
import random
import re
import struct
import subprocess
import time
from collections import defaultdict
from datetime import datetime
from typing import Any

from PyQt6.QtCore import Qt, QThread, QTimer, pyqtSignal
from PyQt6.QtGui import QFont
from PyQt6.QtWidgets import (
    QCheckBox,
    QComboBox,
    QDialog,
    QFileDialog,
    QGridLayout,
    QGroupBox,
    QHBoxLayout,
    QLabel,
    QLineEdit,
    QListWidget,
    QMessageBox,
    QProgressBar,
    QPushButton,
    QSpinBox,
    QSplitter,
    QTableWidget,
    QTableWidgetItem,
    QTabWidget,
    QTextEdit,
    QTreeWidget,
    QTreeWidgetItem,
    QVBoxLayout,
    QWidget,
)

from intellicrack.logger import logger

# Import research components
try:
    from ...core.vulnerability_research.binary_differ import BinaryDiffer
    from ...core.vulnerability_research.fuzzing_engine import FuzzingEngine, FuzzingStrategy
    from ...core.vulnerability_research.research_manager import (
CampaignStatus,
CampaignType,
ResearchManager,
    )
    from ...core.vulnerability_research.vulnerability_analyzer import (
AnalysisMethod,
VulnerabilityAnalyzer,
    )

    RESEARCH_AVAILABLE = True
except ImportError as e:
    logger.error("Import error in vulnerability_research_dialog: %s", e)
    RESEARCH_AVAILABLE = False

    # Create mock classes when research components are not available
    class BinaryDiffer:
        """Binary comparison tool for vulnerability research."""

        def __init__(self):
            """Binary comparison engine for exploit development."""
            self.algorithms = ["ssdeep", "tlsh", "sdhash", "imphash"]
            self.similarity_threshold = 0.75
            self.diff_cache = {}

        def compare_binaries(self, binary1_path, binary2_path, algorithm="ssdeep", **kwargs):
            """Compare two binaries for exploitation research."""
            try:
                import os

                # Validate inputs
                if not os.path.exists(binary1_path) or not os.path.exists(binary2_path):
                    return {"error": "Binary files not found", "similarity": 0.0}

                # Generate cache key
                cache_key = f"{binary1_path}:{binary2_path}:{algorithm}"
                if cache_key in self.diff_cache:
                    return self.diff_cache[cache_key]

                # Read binary data
                with open(binary1_path, "rb") as f1, open(binary2_path, "rb") as f2:
                    data1, data2 = f1.read(), f2.read()

                # Perform comparison based on algorithm
                if algorithm == "ssdeep":
                    result = self._ssdeep_compare(data1, data2)
                elif algorithm == "tlsh":
                    result = self._tlsh_compare(data1, data2)
                elif algorithm == "sdhash":
                    result = self._sdhash_compare(data1, data2)
                elif algorithm == "imphash":
                    result = self._imphash_compare(data1, data2)
                else:
                    result = self._fallback_compare(data1, data2)

                # Add metadata
                result.update(
                    {
                        "file1_size": len(data1),
                        "file2_size": len(data2),
                        "size_ratio": len(data1) / len(data2) if len(data2) > 0 else 0,
                        "algorithm": algorithm,
                        "exploitable_differences": self._find_exploitable_diffs(data1, data2),
                    },
                )

                # Cache result
                self.diff_cache[cache_key] = result
                return result

            except Exception as e:
                return {"error": str(e), "similarity": 0.0}

        def _ssdeep_compare(self, data1, data2):
            """Fuzzy hash comparison for similar binaries."""

            # Simplified ssdeep-like algorithm
            def rolling_hash(data, window=64):
                hashes = []
                for i in range(0, len(data), window):
                    chunk = data[i : i + window]
                    h = hashlib.md5(chunk).hexdigest()[:8]
                    hashes.append(h)
                return hashes

            h1, h2 = rolling_hash(data1), rolling_hash(data2)
            common = len(set(h1) & set(h2))
            total = len(set(h1) | set(h2))
            similarity = common / total if total > 0 else 0.0

            return {"similarity": similarity, "common_chunks": common, "total_chunks": total}

        def _tlsh_compare(self, data1, data2):
            """Trend Micro Locality Sensitive Hash comparison."""

            def tlsh_digest(data):
                # Simplified TLSH-like algorithm
                import struct

                buckets = [0] * 256
                for i in range(len(data) - 2):
                    triplet = struct.unpack("BBB", data[i : i + 3])
                    buckets[triplet[0] ^ triplet[1] ^ triplet[2]] += 1
                return hashlib.sha256(bytes(buckets)).hexdigest()[:32]

            h1, h2 = tlsh_digest(data1), tlsh_digest(data2)
            # Hamming distance for similarity
            distance = sum(c1 != c2 for c1, c2 in zip(h1, h2, strict=False))
            similarity = 1.0 - (distance / len(h1))

            return {"similarity": similarity, "hash1": h1, "hash2": h2, "distance": distance}

        def _sdhash_compare(self, data1, data2):
            """Statistically improbable features comparison."""

            def extract_features(data, chunk_size=64):
                features = set()
                for i in range(0, len(data), chunk_size):
                    chunk = data[i : i + chunk_size]
                    if len(chunk) == chunk_size:
                        # Extract statistical features
                        entropy = self._calculate_entropy(chunk)
                        if entropy > 6.5:  # High entropy chunks
                            features.add(hashlib.sha1(chunk).hexdigest()[:16])
                return features

            f1, f2 = extract_features(data1), extract_features(data2)
            if not f1 and not f2:
                return {"similarity": 1.0, "features1": 0, "features2": 0}

            intersection = len(f1 & f2)
            union = len(f1 | f2)
            similarity = intersection / union if union > 0 else 0.0

            return {"similarity": similarity, "features1": len(f1), "features2": len(f2), "common": intersection}

        def _imphash_compare(self, data1, data2):
            """Import hash comparison for PE files."""

            def extract_imports(data):
                imports = []
                # Simple PE import extraction
                if data.startswith(b"MZ"):
                    # Find import table patterns
                    import_patterns = [b".dll", b".DLL", b".exe", b".EXE"]
                    for pattern in import_patterns:
                        start = 0
                        while True:
                            pos = data.find(pattern, start)
                            if pos == -1:
                                break
                            # Extract likely import name
                            name_start = max(0, pos - 32)
                            name_data = data[name_start : pos + len(pattern)]
                            imports.append(hashlib.md5(name_data).hexdigest()[:8])
                            start = pos + 1
                return set(imports)

            i1, i2 = extract_imports(data1), extract_imports(data2)
            if not i1 and not i2:
                return {"similarity": 1.0, "imports1": 0, "imports2": 0}

            common = len(i1 & i2)
            total = len(i1 | i2)
            similarity = common / total if total > 0 else 0.0

            return {"similarity": similarity, "imports1": len(i1), "imports2": len(i2), "common_imports": common}

        def _fallback_compare(self, data1, data2):
            """Fallback byte-level comparison."""
            if len(data1) != len(data2):
                size_similarity = min(len(data1), len(data2)) / max(len(data1), len(data2))
            else:
                size_similarity = 1.0

            # Sample comparison for large files
            sample_size = min(8192, len(data1), len(data2))
            sample1, sample2 = data1[:sample_size], data2[:sample_size]

            identical_bytes = sum(b1 == b2 for b1, b2 in zip(sample1, sample2, strict=False))
            byte_similarity = identical_bytes / sample_size if sample_size > 0 else 0.0

            overall_similarity = (size_similarity + byte_similarity) / 2

            return {
                "similarity": overall_similarity,
                "size_similarity": size_similarity,
                "byte_similarity": byte_similarity,
            }

        def _calculate_entropy(self, data):
            """Calculate Shannon entropy of data."""
            if not data:
                return 0.0

            import math
            from collections import Counter

            counts = Counter(data)
            length = len(data)
            entropy = 0.0

            for count in counts.values():
                p = count / length
                if p > 0:
                    entropy -= p * math.log2(p)

            return entropy

        def _find_exploitable_diffs(self, data1, data2):
            """Identify potentially exploitable differences."""
            diffs = []

            # Find function prologue/epilogue differences
            prologue_patterns = [b"\x55\x8b\xec", b"\x48\x83\xec", b"\x40\x53\x48"]
            epilogue_patterns = [b"\xc9\xc3", b"\x48\x83\xc4", b"\x5b\xc3"]

            for pattern in prologue_patterns + epilogue_patterns:
                pos1 = data1.find(pattern)
                pos2 = data2.find(pattern)
                if pos1 != pos2:
                    diffs.append(
                        {
                            "type": "function_boundary",
                            "pattern": pattern.hex(),
                            "position1": pos1,
                            "position2": pos2,
                            "exploitable": True,
                        },
                    )

            # Find jump table differences
            jump_patterns = [b"\xff\x25", b"\xff\x15", b"\xe9", b"\xeb"]
            for pattern in jump_patterns:
                count1 = data1.count(pattern)
                count2 = data2.count(pattern)
                if count1 != count2:
                    diffs.append(
                        {
                            "type": "control_flow",
                            "pattern": pattern.hex(),
                            "count1": count1,
                            "count2": count2,
                            "exploitable": True,
                        },
                    )

            return diffs

    class FuzzingEngine:
        """Advanced fuzzing engine for vulnerability discovery."""

        def __init__(self):
            """Advanced fuzzing engine for vulnerability discovery."""
            self.strategies = {
                "mutation": self._mutation_fuzzing,
                "generation": self._generation_fuzzing,
                "hybrid": self._hybrid_fuzzing,
                "afl++": self._afl_plus_plus_fuzzing,
            }
            self.running = False
            self.session_data = {}
            self.crash_count = 0
            self.coverage_data = {}
            self.fuzzing_dict = set()
            self._load_fuzzing_dictionaries()

        def _load_fuzzing_dictionaries(self):
            """Load fuzzing dictionaries from various sources."""
            # Default dictionary tokens
            self.fuzzing_dict = {
                # Format strings
                "%s",
                "%x",
                "%n",
                "%d",
                "%p",
                "%u",
                "%c",
                "%f",
                "%s%s%s",
                "%x%x%x",
                "%n%n%n",
                "%d%d%d",
# Common delimiters
":",
";",
",",
"|",
"\t",
"\n",
"\r",
"\r\n",
" ",
"  ",
"   ",
"\0",
# Special characters
"'",
'"',
"`",
"\\",
"/",
"..",
"../",
"../../",
# Common keywords
"admin",
"root",
"user",
"password",
"login",
"select",
"union",
"drop",
"insert",
"update",
"<script>",
"</script>",
"<img>",
"javascript:",
# Numbers
"0",
"1",
"-1",
"255",
"256",
"65535",
"65536",
"2147483647",
"-2147483648",
"4294967295",
# Buffer overflow patterns
"A" * 10,
"A" * 100,
"A" * 1000,
"\x41\x41\x41\x41",
"\xff\xff\xff\xff",
"\x00\x00\x00\x00",
"\xde\xad\xbe\xef",
    }

            # Try to load AFL++ dictionaries
            dict_paths = [
                "/usr/share/afl++/dictionaries/",
                "/usr/local/share/afl++/dictionaries/",
                "C:\\afl++\\dictionaries\\",
                "./dictionaries/",
            ]

            for base_path in dict_paths:
                if os.path.exists(base_path):
                    try:
                        # Load .dict files
                        for dict_file in os.listdir(base_path):
                            if dict_file.endswith(".dict"):
                                dict_path = os.path.join(base_path, dict_file)
                                self._load_afl_dictionary(dict_path)
                    except Exception as e:
                        logger.debug(f"Failed to load dictionaries from {base_path}: {e}")

            # Load custom dictionary if specified
            custom_dict = os.path.join(os.path.dirname(__file__), "fuzzing.dict")
            if os.path.exists(custom_dict):
                self._load_afl_dictionary(custom_dict)

    def _load_afl_dictionary(self, dict_path):
        """Load AFL++ format dictionary file."""
        try:
            with open(dict_path, encoding="utf-8", errors="ignore") as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue

                    # AFL dict format: name="value" or just "value"
                    if "=" in line:
                        parts = line.split("=", 1)
                        if len(parts) == 2:
                            value = parts[1].strip('"')
                            # Decode escape sequences
                            try:
                                value = value.encode().decode("unicode_escape")
                                self.fuzzing_dict.add(value)
                            except:
                                self.fuzzing_dict.add(value)
                    elif line.startswith('"') and line.endswith('"'):
                        value = line[1:-1]
                        try:
                            value = value.encode().decode("unicode_escape")
                            self.fuzzing_dict.add(value)
                        except:
                            self.fuzzing_dict.add(value)
        except Exception as e:
            logger.debug(f"Failed to load dictionary {dict_path}: {e}")

    def _is_afl_instrumented(self, binary_path):
        """Check if binary was compiled with AFL++ instrumentation."""
        try:
            with open(binary_path, "rb") as f:
                # Look for AFL++ instrumentation signatures
                data = f.read(1024 * 1024)  # Read first 1MB
                afl_signatures = [
                    b"__afl_area_ptr",
                    b"__afl_prev_loc",
                    b"__afl_fork_pid",
                    b"__sanitizer_cov_trace_pc_guard",
                ]
                return any(sig in data for sig in afl_signatures)
        except Exception:
            return False

    def _setup_afl_environment(self, output_dir):
        """Set up AFL++ environment variables."""
        import os

        env = os.environ.copy()
        env["AFL_SKIP_CPUFREQ"] = "1"
        env["AFL_NO_AFFINITY"] = "1"
        env["AFL_SHUFFLE_QUEUE"] = "1"
        env["AFL_FAST_CAL"] = "1"

        # Set output directory
        env["AFL_OUT_DIR"] = output_dir

        return env

    def _run_afl_fuzzer(self, target_path, input_dir, output_dir, duration):
        """Run AFL++ fuzzer on target binary."""
        import shutil
        import subprocess

        afl_fuzz = shutil.which("afl-fuzz")
        if not afl_fuzz:
            logger.warning("AFL++ not found, falling back to mutation fuzzing")
            return False

        # Check if binary is instrumented
        if not self._is_afl_instrumented(target_path):
            logger.warning("Binary not instrumented with AFL++, consider using afl-clang-fast")
            # Still try to run AFL++ in QEMU mode if available
            afl_qemu = shutil.which("afl-qemu-trace")
            if not afl_qemu:
                return False

        try:
            # Prepare AFL++ command
            cmd = [
                afl_fuzz,
                "-i",
                input_dir,  # Input directory
                "-o",
                output_dir,  # Output directory
                "-t",
                "1000",  # Timeout per run (ms)
                "-m",
                "none",  # Memory limit
                "-V",
                str(duration),  # Run duration in seconds
            ]

            # Add QEMU mode if binary not instrumented
            if not self._is_afl_instrumented(target_path):
                cmd.extend(["-Q"])  # QEMU mode

            cmd.extend(["--", target_path, "@@"])  # Separator  # Target binary  # Input file placeholder

            # Set up environment
            env = self._setup_afl_environment(output_dir)

            # Run AFL++
            logger.info(f"Starting AFL++ fuzzer: {' '.join(cmd)}")
            process = subprocess.Popen(cmd, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            # Monitor AFL++ progress
            self._monitor_afl_progress(process, output_dir, duration)

            return True

        except Exception as e:
            logger.error(f"Failed to run AFL++ fuzzer: {e}")
            return False

    def _monitor_afl_progress(self, process, output_dir, duration):
        """Monitor AFL++ fuzzing progress."""
        import os
        import time

        start_time = time.time()
        stats_file = os.path.join(output_dir, "fuzzer_stats")

        while (time.time() - start_time) < duration:
            # Check if process is still running
            if process.poll() is not None:
                break

            # Read AFL++ stats
            if os.path.exists(stats_file):
                try:
                    with open(stats_file) as f:
                        stats = {}
                        for line in f:
                            if ":" in line:
                                key, value = line.strip().split(":", 1)
                                stats[key.strip()] = value.strip()

                        # Update fuzzing metrics
                        if "execs_done" in stats:
                            self.session_data["test_cases"] = int(stats["execs_done"])
                        if "unique_crashes" in stats:
                            self.crash_count = int(stats["unique_crashes"])

                        # Log progress
                        if self.session_data.get("test_cases", 0) % 1000 == 0:
                            paths_total = stats.get("paths_total", "0")
                            logger.info(
                                f"AFL++ progress: {self.session_data.get('test_cases', 0)} execs, "
                                f"{self.crash_count} crashes, {paths_total} paths",
                            )
                except Exception:
                    pass

            time.sleep(1)

        # Terminate AFL++ if still running
        if process.poll() is None:
            process.terminate()
            try:
                process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                process.kill()

    def _collect_afl_results(self, output_dir):
        """Collect results from AFL++ output directory."""
        import os

        # Collect crashes
        crashes_dir = os.path.join(output_dir, "crashes")
        if os.path.exists(crashes_dir):
            for crash_file in os.listdir(crashes_dir):
                if crash_file.startswith("id:"):
                    crash_path = os.path.join(crashes_dir, crash_file)
                    try:
                        with open(crash_path, "rb") as f:
                            crash_data = f.read()

                        # Calculate crash hash
                        crash_hash = hashlib.sha256(crash_data).hexdigest()[:16]

                        # Analyze crash exploitability
                        exploitability = self._analyze_crash_exploitability(crash_path, crash_data)

                        self.session_data["crashes"].append(
                            {
                                "file": crash_file,
                                "path": crash_path,
                                "hash": crash_hash,
                                "size": len(crash_data),
                                "exploitability": exploitability,
                            },
                        )
                        self.session_data["unique_crashes"].add(crash_hash)
                    except Exception as e:
                        logger.error(f"Failed to process crash {crash_file}: {e}")

        # Collect coverage information
        plot_data = os.path.join(output_dir, "plot_data")
        if os.path.exists(plot_data):
            try:
                with open(plot_data) as f:
                    lines = f.readlines()
                    if lines:
                        # Parse last line for final stats
                        last_line = lines[-1].strip().split(",")
                        if len(last_line) >= 3:
                            self.coverage_data["paths_total"] = int(last_line[2])
            except Exception as e:
                logger.error(f"Failed to parse AFL++ plot data: {e}")

    def _analyze_crash_exploitability(self, crash_path, crash_data):
        """Analyze crash for exploitability indicators."""
        # Simple heuristic-based analysis
        exploitability = "LOW"

        # Check for common exploitable patterns
        if len(crash_data) > 10000:  # Large inputs often indicate buffer overflows
            exploitability = "MEDIUM"

        # Check for specific byte patterns
        exploitable_patterns = [
            b"\x41\x41\x41\x41",  # AAAA - common in overflows
            b"\xde\xad\xbe\xef",  # Magic values
            b"\x00\x00\x00\x00",  # NULL bytes
            b"\xff\xff\xff\xff",  # All ones
        ]

        for pattern in exploitable_patterns:
            if pattern in crash_data:
                exploitability = "HIGH"
                break

        return exploitability

def _generate_fuzzing_report(self, output_dir):
    """Generate comprehensive fuzzing report for AFL++ results."""
    import os

    session = self.session_data

    # Calculate statistics
    total_duration = time.time() - session["start_time"]
    execs_per_sec = session["test_cases"] / total_duration if total_duration > 0 else 0

    report = {
"success": True,
"fuzzer": "AFL++",
"output_directory": output_dir,
"duration": total_duration,
"test_cases_executed": session["test_cases"],
"executions_per_second": execs_per_sec,
"unique_crashes": len(session["unique_crashes"]),
"total_crashes": len(session["crashes"]),
"crashes": session["crashes"],
"coverage_summary": {
    "paths_total": self.coverage_data.get("paths_total", 0),
    "unique_basic_blocks": len(self.coverage_data.get("basic_blocks", [])),
    "unique_functions": len(self.coverage_data.get("functions", [])),
    "unique_branches": len(self.coverage_data.get("branches", [])),
},
"exploitable_crashes": len([c for c in session["crashes"] if c.get("exploitability") == "HIGH"]),
"recommendations": [],
    }

    # Add recommendations based on results
    if report["unique_crashes"] == 0:
        report["recommendations"].append("No crashes found. Consider:")
        report["recommendations"].append("- Increasing fuzzing duration")
        report["recommendations"].append("- Adding more diverse seed inputs")
        report["recommendations"].append("- Using different fuzzing strategies")
    else:
        report["recommendations"].append(f"Found {report['unique_crashes']} unique crashes")
        if report["exploitable_crashes"] > 0:
            report["recommendations"].append(f"{report['exploitable_crashes']} crashes appear exploitable")
            report["recommendations"].append("Prioritize analysis of HIGH exploitability crashes")

    # Save report to file
    report_file = os.path.join(output_dir, "fuzzing_report.json")
    try:
        import json

        with open(report_file, "w") as f:
            json.dump(report, f, indent=2)
        logger.info(f"Fuzzing report saved to {report_file}")
    except Exception as e:
        logger.error(f"Failed to save fuzzing report: {e}")

    return report

    def start_fuzzing(self, target_path, strategy="mutation", duration=3600, **kwargs):
        """Start fuzzing campaign against target binary."""
        try:
            import os
            import tempfile
            import time

            if not os.path.exists(target_path):
                return {"success": False, "error": "Target not found"}

            self.running = True
            self.session_data = {
                "target": target_path,
                "strategy": strategy,
                "start_time": time.time(),
                "duration": duration,
                "test_cases": 0,
                "crashes": [],
                "unique_crashes": set(),
                "coverage_hits": {},
            }

            # Create output directory
            output_dir = kwargs.get("output_dir", tempfile.mkdtemp(prefix="fuzz_"))

            # Try AFL++ first if strategy is 'afl++' or use_afl is True
            if strategy == "afl++" or kwargs.get("use_afl", False):
                # Create input directory with seed files
                input_dir = os.path.join(output_dir, "input")
                os.makedirs(input_dir, exist_ok=True)

                # Generate initial test cases
                test_cases = self._generate_initial_testcases(target_path, **kwargs)

                # Save seed files for AFL++
                for i, case in enumerate(test_cases[:10]):  # Use first 10 as seeds
                    seed_file = os.path.join(input_dir, f"seed_{i:03d}")
                    with open(seed_file, "wb") as f:
                        if isinstance(case, str):
                            f.write(case.encode())
                        else:
                            f.write(case)

                # Run AFL++
                if self._run_afl_fuzzer(target_path, input_dir, output_dir, duration):
                    # Collect AFL++ results
                    self._collect_afl_results(output_dir)
                    return self._generate_fuzzing_report(output_dir)

            # Fallback to built-in fuzzing strategies
            # Initialize fuzzing strategy
            fuzzer_func = self.strategies.get(strategy, self._mutation_fuzzing)

            # Generate initial test cases
            test_cases = self._generate_initial_testcases(target_path, **kwargs)

            # Start fuzzing loop
            start_time = time.time()
            while self.running and (time.time() - start_time) < duration:
                for test_case in test_cases[:100]:  # Limit for simulation
                    if not self.running:
                        break

                    # Execute test case
                    result = self._execute_testcase(target_path, test_case)
                    self.session_data["test_cases"] += 1

                    # Check for crashes
                    if result.get("crashed"):
                        crash_hash = self._hash_crash(result)
                        if crash_hash not in self.session_data["unique_crashes"]:
                            self.session_data["unique_crashes"].add(crash_hash)
                            self.session_data["crashes"].append(
                                {
                                    "testcase": test_case[:100],  # Truncate for storage
                                    "crash_type": result.get("crash_type"),
                                    "pc": result.get("pc", 0),
                                    "hash": crash_hash,
                                    "exploitability": self._assess_exploitability(result),
                                },
                            )
                            self.crash_count += 1

                    # Update coverage
                    if "coverage" in result:
                        self._update_coverage(result["coverage"])

                    # Generate new test cases based on results
                    if result.get("interesting"):
                        new_cases = fuzzer_func(test_case, result)
                        test_cases.extend(new_cases[:10])  # Add promising mutations

                    # Periodic cleanup
                    if len(test_cases) > 1000:
                        test_cases = test_cases[-500:]  # Keep most recent

            self.running = False
            return self._generate_report()

        except Exception as e:
            self.running = False
            return {"success": False, "error": str(e)}

def _generate_initial_testcases(self, target_path, count=100, **kwargs):
    """Generate initial test cases for fuzzing."""
    import random

    test_cases = []

    # File format detection
    file_ext = target_path.split(".")[-1].lower()

    if file_ext in ["exe", "dll"]:
        # PE file fuzzing templates
        test_cases.extend(self._generate_pe_testcases(count // 4))
    elif file_ext in ["elf", "so"]:
        # ELF file fuzzing templates
        test_cases.extend(self._generate_elf_testcases(count // 4))

    # Generic binary patterns
    for _ in range(count // 2):
        size = random.randint(1, 8192)  # noqa: S311
        test_case = bytes([random.randint(0, 255) for _ in range(size)])  # noqa: S311
        test_cases.append(test_case)

    # Structured data patterns
    for _ in range(count // 4):
        # Format string vulnerabilities
        fmt_strings = [b"%s%s%s%s", b"%x%x%x%x", b"%n%n%n%n", b"AAAA%08x.%08x.%08x"]
        test_case = random.choice(fmt_strings) + b"A" * random.randint(100, 1000)  # noqa: S311
        test_cases.append(test_case)

    return test_cases

def _generate_pe_testcases(self, count):
    """Generate PE-specific test cases."""
    test_cases = []

    # PE header corruption
    pe_header = b"MZ\x90\x00" + b"A" * 60 + b"PE\x00\x00"
    for _ in range(count // 2):
        corrupted = bytearray(pe_header)
        # Corrupt random bytes
        for _ in range(5):
            pos = random.randint(0, len(corrupted) - 1)  # noqa: S311
            corrupted[pos] = random.randint(0, 255)  # noqa: S311
        test_cases.append(bytes(corrupted))

    # Import table corruption
    import_data = b"\x00" * 20 + b"kernel32.dll\x00" + b"ExitProcess\x00"
    for _ in range(count // 2):
        corrupted = bytearray(import_data)
        # Corrupt import names
        null_pos = corrupted.find(b"\x00")
        if null_pos > 0:
            corrupted[null_pos] = ord("A")
        test_cases.append(bytes(corrupted))

    return test_cases

def _generate_elf_testcases(self, count):
    """Generate ELF-specific test cases."""
    test_cases = []

    # ELF header corruption
    elf_header = b"\x7fELF" + b"\x02\x01\x01\x00" + b"\x00" * 8
    for _ in range(count):
        corrupted = bytearray(elf_header + b"A" * 100)
        # Corrupt ELF fields
        corrupted[random.randint(4, 15)] = random.randint(0, 255)  # noqa: S311
        test_cases.append(bytes(corrupted))

    return test_cases

def _execute_testcase(self, target_path, test_case):
    """Execute test case and monitor for crashes."""
    try:
        import os
        import subprocess
        import tempfile

        # Write test case to temporary file
        with tempfile.NamedTemporaryFile(delete=False) as f:
            f.write(test_case)
            test_file = f.name

        try:
            # Simulate execution with timeout
            result = subprocess.run([target_path, test_file], check=False, timeout=5, capture_output=True, text=True)

            return {
                "crashed": result.returncode < 0,
                "crash_type": "segfault" if result.returncode == -11 else "unknown",
                "returncode": result.returncode,
                "stderr": result.stderr[:500],
                "interesting": len(result.stderr) > 0,
                "coverage": self._simulate_coverage(),
            }

        except subprocess.TimeoutExpired:
            return {"crashed": False, "timeout": True, "interesting": True}
        except Exception as e:
            return {"crashed": True, "crash_type": "exception", "error": str(e)}
        finally:
            os.unlink(test_file)

    except Exception as e:
        return {"crashed": False, "error": str(e)}

    def _get_real_coverage(self, target_binary, test_input_file):
        """Get real code coverage data using gcov or AFL++."""
        coverage_data = {"basic_blocks": 0, "functions": 0, "branches": 0, "detailed_coverage": None}

        try:
            # Check if binary was compiled with AFL++ instrumentation
            import shutil

            afl_showmap = shutil.which("afl-showmap")

            if afl_showmap and self._is_afl_instrumented(target_binary):
                # Use AFL++ showmap to get coverage data
                try:
                    result = subprocess.run(
                        [afl_showmap, "-o", "-", "-q", "--", target_binary, test_input_file],
                        check=False, capture_output=True,
                        timeout=5,
                        text=True,
                    )

                    if result.returncode == 0:
                        # Parse coverage map output
                        coverage_lines = result.stdout.strip().split("\n")
                        coverage_data["basic_blocks"] = len(coverage_lines)
                        # Estimate functions/branches from basic blocks
                        coverage_data["functions"] = coverage_data["basic_blocks"] // 10
                        coverage_data["branches"] = coverage_data["basic_blocks"] // 2

                        return coverage_data
                except (subprocess.TimeoutExpired, subprocess.SubprocessError) as e:
                    logger.warning(f"AFL++ showmap failed: {e}")

            # Try comprehensive gcov analysis
            import tempfile

            with tempfile.TemporaryDirectory() as temp_dir:
                # Run target with gcov
                gcov_env = os.environ.copy()
                gcov_env["GCOV_PREFIX"] = temp_dir
                gcov_env["GCOV_PREFIX_STRIP"] = "0"

                # Execute with coverage
                try:
                    subprocess.run([target_binary, test_input_file], check=False, env=gcov_env, capture_output=True, timeout=5)
                except (subprocess.TimeoutExpired, subprocess.SubprocessError):
                    pass  # Continue even if execution fails

                # Run gcov to generate coverage files
                try:
                    gcov_result = subprocess.run(
                        ["gcov", "-b", "-c", target_binary],
                        check=False, cwd=temp_dir,
                        capture_output=True,
                        text=True,
                        timeout=10,
                    )

                    if gcov_result.returncode == 0:
                        # Use comprehensive gcov parsing
                        detailed_coverage = self._parse_gcov_data(temp_dir)
                        if detailed_coverage and detailed_coverage["summary"]:
                            summary = detailed_coverage["summary"]
                            coverage_data.update(
                                {
                                    "basic_blocks": summary["executed_lines"],
                                    "functions": summary["executed_functions"],
                                    "branches": summary["taken_branches"],
                                    "detailed_coverage": detailed_coverage,
                                },
                            )
                            return coverage_data

                        # Fallback to simple parsing
                        lines = gcov_result.stdout.split("\n")
                        for line in lines:
                            if "Lines executed:" in line:
                                match = re.search(r"(\d+) of (\d+)", line)
                                if match:
                                    coverage_data["basic_blocks"] = int(match.group(1))
                            elif "Branches executed:" in line:
                                match = re.search(r"(\d+) of (\d+)", line)
                                if match:
                                    coverage_data["branches"] = int(match.group(1))
                            elif "Functions executed:" in line:
                                match = re.search(r"(\d+) of (\d+)", line)
                                if match:
                                    coverage_data["functions"] = int(match.group(1))

                        return coverage_data
                except (subprocess.TimeoutExpired, subprocess.SubprocessError) as e:
                    logger.warning(f"Gcov analysis failed: {e}")

            # Fallback: analyze binary for potential coverage
            # Use objdump to count functions and basic blocks
            try:
                objdump_result = subprocess.run(
                    ["objdump", "-d", target_binary], check=False, capture_output=True, text=True, timeout=10,
                )

                if objdump_result.returncode == 0:
                    # Count functions
                    functions = len(re.findall(r"^[0-9a-f]+ <\w+>:", objdump_result.stdout, re.MULTILINE))
                    # Count basic blocks (approximate by counting jump targets)
                    basic_blocks = len(re.findall(r"^\s*[0-9a-f]+:", objdump_result.stdout, re.MULTILINE))
                    # Count branches (jmp, je, jne, etc.)
                    branches = len(re.findall(r"\s+j[a-z]+\s+", objdump_result.stdout))

                    coverage_data["functions"] = min(functions, 100)  # Cap for display
                    coverage_data["basic_blocks"] = min(basic_blocks // 10, 100)  # Estimate executed
                    coverage_data["branches"] = min(branches // 10, 50)  # Estimate taken

                    return coverage_data
            except (subprocess.TimeoutExpired, subprocess.SubprocessError) as e:
                logger.debug(f"Objdump analysis failed: {e}")

            # If all else fails, return minimal coverage
            return {"basic_blocks": 1, "functions": 1, "branches": 0, "detailed_coverage": None}

        except Exception as e:
            logger.warning(f"Coverage analysis failed: {e}")
            return {"basic_blocks": 1, "functions": 1, "branches": 0, "detailed_coverage": None}

    def _parse_gcov_data(self, gcov_dir, source_files=None):
        """Parse detailed gcov coverage data from .gcda and .gcno files."""
        coverage_info = {
            "files": {},
            "summary": {
                "total_lines": 0,
                "executed_lines": 0,
                "total_functions": 0,
                "executed_functions": 0,
                "total_branches": 0,
                "taken_branches": 0,
            },
            "functions": [],
            "hot_spots": [],
            "cold_spots": [],
        }

        try:
            import glob
            import os

            # Find all .gcov files
            gcov_files = glob.glob(os.path.join(gcov_dir, "*.gcov"))

            for gcov_file in gcov_files:
                file_info = self._parse_gcov_file(gcov_file)
                if file_info:
                    filename = os.path.basename(gcov_file).replace(".gcov", "")
                    coverage_info["files"][filename] = file_info

                    # Update summary
                    coverage_info["summary"]["total_lines"] += file_info["total_lines"]
                    coverage_info["summary"]["executed_lines"] += file_info["executed_lines"]
                    coverage_info["summary"]["total_functions"] += len(file_info["functions"])
                    coverage_info["summary"]["executed_functions"] += len(
                        [f for f in file_info["functions"] if f["executed"]],
                    )

                    # Collect function data
                    for func in file_info["functions"]:
                        func["file"] = filename
                        coverage_info["functions"].append(func)

            # Identify hot and cold spots
            coverage_info["hot_spots"] = self._identify_hot_spots(coverage_info["functions"])
            coverage_info["cold_spots"] = self._identify_cold_spots(coverage_info["functions"])

            return coverage_info

        except Exception as e:
            logger.error(f"Failed to parse gcov data: {e}")
            return coverage_info

    def _parse_gcov_file(self, gcov_file):
        """Parse individual .gcov file for detailed coverage information."""
        file_info = {"total_lines": 0, "executed_lines": 0, "line_coverage": {}, "functions": [], "branches": []}

        try:
            with open(gcov_file, encoding="utf-8", errors="ignore") as f:
                current_function = None
                line_num = 0

                for line in f:
                    line = line.strip()
                    if not line:
                        continue

                    # Parse gcov line format: execution_count:line_number:source_code
                    parts = line.split(":", 2)
                    if len(parts) < 3:
                        continue

                    execution_count = parts[0].strip()
                    line_number_str = parts[1].strip()
                    source_code = parts[2] if len(parts) > 2 else ""

                    # Skip metadata lines
                    if not line_number_str.isdigit():
                        continue

                    line_num = int(line_number_str)
                    file_info["total_lines"] = max(file_info["total_lines"], line_num)

                    # Parse execution count
                    if execution_count == "-":
                        # Non-executable line
                        continue
                    if execution_count == "#####":
                        # Unexecuted line
                        file_info["line_coverage"][line_num] = 0
                    else:
                        try:
                            count = int(execution_count)
                            file_info["line_coverage"][line_num] = count
                            if count > 0:
                                file_info["executed_lines"] += 1
                        except ValueError:
                            continue

                    # Detect function definitions
                    if self._is_function_definition(source_code):
                        func_name = self._extract_function_name(source_code)
                        if func_name:
                            current_function = {
                                "name": func_name,
                                "line": line_num,
                                "executed": execution_count != "#####" and execution_count != "-",
                                "execution_count": int(execution_count) if execution_count.isdigit() else 0,
                                "complexity": 1,  # Base complexity
                            }
                            file_info["functions"].append(current_function)

                    # Update function complexity for control flow
                    if current_function and self._is_control_flow(source_code):
                        current_function["complexity"] += 1

                    # Parse branch information
                    if "branch" in line.lower() and execution_count.isdigit():
                        branch_info = {
                            "line": line_num,
                            "taken": int(execution_count) > 0,
                            "count": int(execution_count),
                        }
                        file_info["branches"].append(branch_info)

            return file_info

        except Exception as e:
            logger.error(f"Failed to parse gcov file {gcov_file}: {e}")
            return file_info

    def _is_function_definition(self, source_code):
        """Check if source line contains a function definition."""
        # Simple heuristics for function detection
        func_keywords = ["def ", "function ", "int ", "void ", "static ", "extern "]
        return any(keyword in source_code.lower() for keyword in func_keywords) and "(" in source_code

    def _extract_function_name(self, source_code):
        """Extract function name from source code line."""
        import re

        # Try to extract C/C++ function name
        match = re.search(r"(?:static\s+|extern\s+)?(?:\w+\s+)*(\w+)\s*\(", source_code)
        if match:
            return match.group(1)

        # Try Python function
        match = re.search(r"def\s+(\w+)\s*\(", source_code)
        if match:
            return match.group(1)

        return None

    def _is_control_flow(self, source_code):
        """Check if source line contains control flow statements."""
        control_keywords = ["if", "while", "for", "switch", "case", "else", "elif", "try", "catch"]
        return any(keyword in source_code.lower() for keyword in control_keywords)

    def _identify_hot_spots(self, functions):
        """Identify frequently executed functions (hot spots)."""
        if not functions:
            return []

        # Sort by execution count
        executed_functions = [f for f in functions if f["executed"] and f["execution_count"] > 0]
        executed_functions.sort(key=lambda x: x["execution_count"], reverse=True)

        # Return top 10 hot spots
        return executed_functions[:10]

    def _identify_cold_spots(self, functions):
        """Identify unexecuted or rarely executed functions (cold spots)."""
        if not functions:
            return []

        # Find unexecuted functions
        cold_functions = [f for f in functions if not f["executed"] or f["execution_count"] == 0]

        # Add rarely executed functions (bottom 20% of executed functions)
        executed_functions = [f for f in functions if f["executed"] and f["execution_count"] > 0]
        if executed_functions:
            executed_functions.sort(key=lambda x: x["execution_count"])
            rarely_executed = executed_functions[: max(1, len(executed_functions) // 5)]
            cold_functions.extend(rarely_executed)

        return cold_functions

    def _generate_coverage_report(self, coverage_info, output_file=None):
        """Generate comprehensive coverage report from gcov data."""
        try:
            summary = coverage_info["summary"]

            # Calculate percentages
            line_coverage = (
                (summary["executed_lines"] / summary["total_lines"] * 100) if summary["total_lines"] > 0 else 0
            )
            function_coverage = (
                (summary["executed_functions"] / summary["total_functions"] * 100)
                if summary["total_functions"] > 0
                else 0
            )
            branch_coverage = (
                (summary["taken_branches"] / summary["total_branches"] * 100)
                if summary["total_branches"] > 0
                else 0
            )

            report = {
                "timestamp": datetime.now().isoformat(),
                "summary": {
                    "line_coverage_percent": round(line_coverage, 2),
                    "function_coverage_percent": round(function_coverage, 2),
                    "branch_coverage_percent": round(branch_coverage, 2),
                    "total_lines": summary["total_lines"],
                    "executed_lines": summary["executed_lines"],
                    "total_functions": summary["total_functions"],
                    "executed_functions": summary["executed_functions"],
                    "total_branches": summary["total_branches"],
                    "taken_branches": summary["taken_branches"],
                },
                "files": {},
                "hot_spots": coverage_info["hot_spots"][:5],  # Top 5
                "cold_spots": coverage_info["cold_spots"][:10],  # Top 10 unexecuted
                "recommendations": [],
            }

            # Add file-level coverage
            for filename, file_info in coverage_info["files"].items():
                file_coverage = (
                    (file_info["executed_lines"] / file_info["total_lines"] * 100)
                    if file_info["total_lines"] > 0
                    else 0
                )
                report["files"][filename] = {
                    "coverage_percent": round(file_coverage, 2),
                    "executed_lines": file_info["executed_lines"],
                    "total_lines": file_info["total_lines"],
                    "functions": len(file_info["functions"]),
                }

            # Generate recommendations
            if line_coverage < 50:
                report["recommendations"].append("Low line coverage detected. Consider adding more test cases.")
            if function_coverage < 70:
                report["recommendations"].append("Many functions remain untested. Focus on untested functions.")
            if len(coverage_info["cold_spots"]) > 10:
                report["recommendations"].append("Many cold spots found. Review unused code paths.")
            if branch_coverage < 60:
                report["recommendations"].append("Low branch coverage. Add tests for conditional logic.")

            # Save report if output file specified
            if output_file:

                with open(output_file, "w") as f:
                    json.dump(report, f, indent=2)
                logger.info(f"Coverage report saved to {output_file}")

            return report

        except Exception as e:
            logger.error(f"Failed to generate coverage report: {e}")
            return None

    def _visualize_coverage_data(self, coverage_info):
        """Create visualization data for coverage display."""
        try:
            visualization_data = {
                "coverage_chart": {
                    "labels": ["Line Coverage", "Function Coverage", "Branch Coverage"],
                    "values": [],
                },
                "file_coverage_map": {},
                "hot_cold_comparison": {"hot_spots": [], "cold_spots": []},
                "complexity_analysis": [],
            }

            summary = coverage_info["summary"]

            # Calculate coverage percentages
            line_coverage = (
                (summary["executed_lines"] / summary["total_lines"] * 100) if summary["total_lines"] > 0 else 0
            )
            function_coverage = (
                (summary["executed_functions"] / summary["total_functions"] * 100)
                if summary["total_functions"] > 0
                else 0
            )
            branch_coverage = (
                (summary["taken_branches"] / summary["total_branches"] * 100)
                if summary["total_branches"] > 0
                else 0
            )

            visualization_data["coverage_chart"]["values"] = [
                round(line_coverage, 1),
                round(function_coverage, 1),
                round(branch_coverage, 1),
            ]

            # File coverage map
            for filename, file_info in coverage_info["files"].items():
                file_coverage = (
                    (file_info["executed_lines"] / file_info["total_lines"] * 100)
                    if file_info["total_lines"] > 0
                    else 0
                )
                visualization_data["file_coverage_map"][filename] = {
                    "coverage": round(file_coverage, 1),
                    "color": self._get_coverage_color(file_coverage),
                }

            # Hot/cold spots for comparison
            visualization_data["hot_cold_comparison"]["hot_spots"] = [
                {"name": f["name"], "count": f["execution_count"], "file": f.get("file", "unknown")}
                for f in coverage_info["hot_spots"][:5]
            ]

            visualization_data["hot_cold_comparison"]["cold_spots"] = [
                {
                    "name": f["name"],
                    "file": f.get("file", "unknown"),
                    "reason": "never executed" if not f["executed"] else "rarely executed",
                }
                for f in coverage_info["cold_spots"][:5]
            ]

            # Complexity analysis
            functions_by_complexity = sorted(
                coverage_info["functions"], key=lambda x: x.get("complexity", 1), reverse=True,
            )
            visualization_data["complexity_analysis"] = [
                {
                    "name": f["name"],
                    "complexity": f.get("complexity", 1),
                    "executed": f["executed"],
                    "file": f.get("file", "unknown"),
                }
                for f in functions_by_complexity[:10]
            ]

            return visualization_data

        except Exception as e:
            logger.error(f"Failed to create visualization data: {e}")
            return None

    def _get_coverage_color(self, coverage_percent):
        """Get color code based on coverage percentage."""
        if coverage_percent >= 80:
            return "#4CAF50"  # Green
        if coverage_percent >= 60:
            return "#FF9800"  # Orange
        if coverage_percent >= 40:
            return "#FF5722"  # Red-Orange
        return "#F44336"  # Red

    def _mutation_fuzzing(self, seed_case, execution_result):
        """Mutation-based fuzzing strategy."""
        import random

        mutations = []

        for _ in range(5):
            mutated = bytearray(seed_case)

            # Bit flipping
            if mutated:
                pos = random.randint(0, len(mutated) - 1)  # noqa: S311
                mutated[pos] ^= 1 << random.randint(0, 7)  # noqa: S311

            # Byte insertion
            if len(mutated) < 8192:
                pos = random.randint(0, len(mutated))  # noqa: S311
                mutated.insert(pos, random.randint(0, 255))  # noqa: S311

            # Byte deletion
            if len(mutated) > 1:
                pos = random.randint(0, len(mutated) - 1)  # noqa: S311
                del mutated[pos]

            mutations.append(bytes(mutated))

        return mutations

    def _generation_fuzzing(self, seed_case, execution_result):
        """Generation-based fuzzing strategy."""
        import random

        generated = []

        # Generate based on execution feedback
        coverage = execution_result.get("coverage", {})
        target_size = coverage.get("basic_blocks", 100) * 10

        for _ in range(3):
            # Structure-aware generation
            test_case = b""

            # Add magic bytes
            magic_bytes = [b"MZ", b"\x7fELF", b"PK", b"\xff\xd8\xff"]
            test_case += random.choice(magic_bytes)  # noqa: S311

            # Add structured data
            while len(test_case) < target_size:
                chunk_type = random.choice(["random", "pattern", "string"])  # noqa: S311

                if chunk_type == "random":
                    chunk = bytes([random.randint(0, 255) for _ in range(random.randint(1, 100))])  # noqa: S311
                elif chunk_type == "pattern":
                    pattern = bytes([random.randint(0, 255)]) * random.randint(10, 100)  # noqa: S311
                    chunk = pattern
                else:  # string
                    chunk = b"A" * random.randint(10, 200)  # noqa: S311

                test_case += chunk

            generated.append(test_case)

        return generated

    def _hybrid_fuzzing(self, seed_case, execution_result):
        """Hybrid fuzzing combining mutation and generation."""
        mutations = self._mutation_fuzzing(seed_case, execution_result)
        generated = self._generation_fuzzing(seed_case, execution_result)
        return mutations + generated

    def _afl_plus_plus_fuzzing(self, seed_case, execution_result):
        """AFL++ inspired fuzzing with havoc mutations and deterministic stages."""
        test_cases = []

        # Deterministic stage - bit flips
        for i in range(min(len(seed_case), 128)):
            for bit in range(8):
                test_case = bytearray(seed_case)
                test_case[i] ^= 1 << bit
                test_cases.append(bytes(test_case))

        # Arithmetic mutations
        for i in range(min(len(seed_case) - 3, 64)):
            test_case = bytearray(seed_case)
            # Add/subtract small integers
            val = struct.unpack("<I", test_case[i : i + 4])[0]
            for delta in [-1, 1, -16, 16, -128, 128]:
                new_val = (val + delta) & 0xFFFFFFFF
                test_case[i : i + 4] = struct.pack("<I", new_val)
                test_cases.append(bytes(test_case))

        # Havoc stage - random mutations
        havoc_cycles = 256 if execution_result.get("coverage_new", False) else 128
        for _ in range(havoc_cycles):
            test_case = bytearray(seed_case)

            # Random number of stacked mutations
            num_mutations = random.randint(1, 16)
            for _ in range(num_mutations):
                mutation_type = random.randint(0, 10)

                if mutation_type == 0:  # Bit flip
                    if test_case:
                        pos = random.randint(0, len(test_case) - 1)
                        test_case[pos] ^= 1 << random.randint(0, 7)

                elif mutation_type == 1:  # Byte flip
                    if test_case:
                        pos = random.randint(0, len(test_case) - 1)
                        test_case[pos] ^= 0xFF

                elif mutation_type == 2:  # Insert random bytes
                    pos = random.randint(0, len(test_case))
                    test_case.insert(pos, random.randint(0, 255))

                elif mutation_type == 3:  # Delete bytes
                    if len(test_case) > 1:
                        pos = random.randint(0, len(test_case) - 1)
                        del test_case[pos]

                elif mutation_type == 4:  # Splice
                    if len(test_case) > 4:
                        # Splice with interesting values
                        interesting = [0, 1, -1, 255, 256, 32767, -32768, 65535, -65536]
                        pos = random.randint(0, len(test_case) - 4)
                        val = random.choice(interesting)
                        test_case[pos : pos + 4] = struct.pack("<i", val)

                elif mutation_type == 5:  # Dictionary insertion
                    if hasattr(self, "fuzzing_dict") and self.fuzzing_dict:
                        token = random.choice(list(self.fuzzing_dict))
                        pos = random.randint(0, max(0, len(test_case) - len(token)))
                        test_case[pos : pos + len(token)] = token.encode()[: len(test_case) - pos]

                elif mutation_type == 6:  # Overwrite with pattern
                    patterns = [b"\x00\x00\x00\x00", b"\xff\xff\xff\xff", b"\x41\x41\x41\x41", b"\x0a\x0d\x0a\x0d"]
                    pattern = random.choice(patterns)
                    if len(test_case) >= len(pattern):
                        pos = random.randint(0, len(test_case) - len(pattern))
                        test_case[pos : pos + len(pattern)] = pattern

                elif mutation_type == 7:  # Arithmetic operations
                    if len(test_case) >= 4:
                        pos = random.randint(0, len(test_case) - 4)
                        val = struct.unpack("<I", test_case[pos : pos + 4])[0]
                        op = random.choice([lambda x: x + 1, lambda x: x - 1, lambda x: x * 2, lambda x: x // 2])
                        new_val = op(val) & 0xFFFFFFFF
                        test_case[pos : pos + 4] = struct.pack("<I", new_val)

                elif mutation_type == 8:  # Clone bytes
                    if len(test_case) > 1:
                        length = random.randint(1, min(16, len(test_case) // 2))
                        src = random.randint(0, len(test_case) - length)
                        dst = random.randint(0, len(test_case))
                        chunk = test_case[src : src + length]
                        test_case[dst:dst] = chunk

                elif mutation_type == 9:  # Swap bytes
                    if len(test_case) > 4:
                        pos1 = random.randint(0, len(test_case) - 2)
                        pos2 = random.randint(0, len(test_case) - 2)
                        test_case[pos1], test_case[pos2] = test_case[pos2], test_case[pos1]

                elif mutation_type == 10:  # Format string injection
                    fmt_strings = [b"%s%s%s", b"%n%n%n", b"%x%x%x", b"%d%d%d"]
                    fmt = random.choice(fmt_strings)
                    if len(test_case) >= len(fmt):
                        pos = random.randint(0, len(test_case) - len(fmt))
                        test_case[pos : pos + len(fmt)] = fmt

            test_cases.append(bytes(test_case))

        return test_cases

    def _hash_crash(self, crash_result):
        """Generate unique hash for crash deduplication."""
        import hashlib

        crash_data = f"{crash_result.get('crash_type', '')}:{crash_result.get('pc', 0)}"
        return hashlib.md5(crash_data.encode()).hexdigest()[:16]

    def _assess_exploitability(self, crash_result):
        """Assess crash exploitability."""
        crash_type = crash_result.get("crash_type", "")
        pc = crash_result.get("pc", 0)

        if crash_type == "segfault":
            if pc == 0x41414141:  # Controlled EIP
                return "HIGH"
            if pc > 0x10000000:  # Userland address
                return "MEDIUM"
            return "LOW"
        if crash_type == "exception":
            return "MEDIUM"
        return "LOW"

    def _update_coverage(self, coverage_data):
        """Update global coverage tracking."""
        for key, value in coverage_data.items():
            if key not in self.coverage_data:
                self.coverage_data[key] = set()
            if isinstance(value, (list, tuple)):
                self.coverage_data[key].update(value)
            else:
                self.coverage_data[key].add(value)

    def _generate_report(self):
        """Generate comprehensive fuzzing report."""
        session = self.session_data

        return {
            "success": True,
            "duration": time.time() - session["start_time"],
            "test_cases_executed": session["test_cases"],
            "unique_crashes": len(session["unique_crashes"]),
            "total_crashes": self.crash_count,
            "crashes": session["crashes"],
            "coverage_summary": {
                "unique_basic_blocks": len(self.coverage_data.get("basic_blocks", [])),
                "unique_functions": len(self.coverage_data.get("functions", [])),
                "unique_branches": len(self.coverage_data.get("branches", [])),
            },
            "exploitable_crashes": len([c for c in session["crashes"] if c["exploitability"] == "HIGH"]),
        }

    class FuzzingStrategy:
        """Fuzzing strategy enumeration for different approach types."""

        MUTATION_BASED = "mutation"
        GENERATION_BASED = "generation"
        HYBRID = "hybrid"
        AFL_PLUS_PLUS = "afl++"

    class CampaignStatus:
        """Fuzzing campaign status enumeration."""

        PENDING = "pending"
        RUNNING = "running"
        COMPLETED = "completed"
        FAILED = "failed"

    class AnalysisMethod:
        """Analysis method enumeration for vulnerability research."""

        STATIC = "static"
        DYNAMIC = "dynamic"
        SYMBOLIC = "symbolic"
        HYBRID = "hybrid"

    class VulnerabilityAnalyzer:
        """Advanced vulnerability analysis engine."""

        def __init__(self):
            """Advanced vulnerability analysis engine."""
            self.detection_modules = {
                "buffer_overflow": self._detect_buffer_overflow,
                "format_string": self._detect_format_string,
                "use_after_free": self._detect_use_after_free,
                "double_free": self._detect_double_free,
                "integer_overflow": self._detect_integer_overflow,
                "race_condition": self._detect_race_condition,
                "injection": self._detect_injection_vulns,
                "crypto_weakness": self._detect_crypto_weaknesses,
            }
            self.analysis_cache = {}

        def analyze(self, target_path, analysis_type="comprehensive", **kwargs):
            """Perform comprehensive vulnerability analysis."""
            try:
                import hashlib
                import os

                if not os.path.exists(target_path):
                    return {"error": "Target file not found", "vulnerabilities": []}

                # Generate cache key
                with open(target_path, "rb") as f:
                    file_hash = hashlib.md5(f.read()).hexdigest()
                    cache_key = f"{file_hash}:{analysis_type}"

                if cache_key in self.analysis_cache:
                    return self.analysis_cache[cache_key]

                # Perform analysis
                results = {
                    "target": target_path,
                    "analysis_type": analysis_type,
                    "vulnerabilities": [],
                    "risk_score": 0.0,
                    "recommendations": [],
                    "metadata": self._analyze_metadata(target_path),
                }

                # Binary analysis
                with open(target_path, "rb") as f:
                    binary_data = f.read()

                # Run detection modules
                if analysis_type == "comprehensive":
                    modules_to_run = list(self.detection_modules.keys())
                else:
                    modules_to_run = [analysis_type] if analysis_type in self.detection_modules else []

                for module_name in modules_to_run:
                    try:
                        detector = self.detection_modules[module_name]
                        vulns = detector(binary_data, target_path, **kwargs)

                        for vuln in vulns:
                            vuln["detection_module"] = module_name
                            results["vulnerabilities"].append(vuln)

                    except Exception as e:
                        results["vulnerabilities"].append(
                            {"type": "analysis_error", "module": module_name, "error": str(e), "severity": "info"},
                        )

                # Calculate overall risk score
                results["risk_score"] = self._calculate_risk_score(results["vulnerabilities"])

                # Generate recommendations
                results["recommendations"] = self._generate_recommendations(results["vulnerabilities"])

                # Cache results
                self.analysis_cache[cache_key] = results
                return results

            except Exception as e:
                return {"error": str(e), "vulnerabilities": []}

    def _analyze_metadata(self, file_path):
        """Analyze file metadata for security indicators."""
        import os
        import time

        stat = os.stat(file_path)

        return {
            "size": stat.st_size,
            "modified": time.ctime(stat.st_mtime),
            "permissions": oct(stat.st_mode)[-3:],
            "is_executable": os.access(file_path, os.X_OK),
            "file_type": self._detect_file_type(file_path),
        }

    def _detect_file_type(self, file_path):
        """Detect file type from headers."""
        try:
            with open(file_path, "rb") as f:
                header = f.read(16)

            if header.startswith(b"MZ"):
                return "PE"
            if header.startswith(b"\x7fELF"):
                return "ELF"
            if header.startswith(b"\xca\xfe\xba\xbe"):
                return "Mach-O"
            if header.startswith(b"PK"):
                return "ZIP/JAR"
            return "Unknown"

        except Exception:
            return "Unknown"

    def _detect_buffer_overflow(self, binary_data, file_path, **kwargs):
        """Detect potential buffer overflow vulnerabilities."""
        vulnerabilities = []

        # Look for dangerous functions
        dangerous_funcs = [
            b"strcpy",
            b"strcat",
            b"sprintf",
            b"gets",
            b"scanf",
            b"memcpy",
            b"memmove",
            b"strncpy",
            b"strncat",
        ]

        for func in dangerous_funcs:
            positions = []
            start = 0
            while True:
                pos = binary_data.find(func, start)
                if pos == -1:
                    break
                positions.append(pos)
                start = pos + 1

            if positions:
                vulnerabilities.append(
                    {
                        "type": "buffer_overflow_risk",
                        "function": func.decode("ascii", errors="ignore"),
                        "occurrences": len(positions),
                        "positions": positions[:10],  # Limit to first 10
                        "severity": "high" if func in [b"strcpy", b"gets", b"sprintf"] else "medium",
                        "description": f'Usage of dangerous function {func.decode("ascii", errors="ignore")} detected',
                        "exploit_potential": "high" if func == b"gets" else "medium",
                    },
                )

        # Look for stack canary bypass patterns
        canary_bypass_patterns = [
            b"\x8b\x45\xfc\x33\xc5",  # mov eax, [ebp-4]; xor eax, ebp (canary check)
b"\x48\x8b\x45\xf8\x48\x33\xc4",  # x64 canary check
    ]

        for pattern in canary_bypass_patterns:
            if pattern in binary_data:
                vulnerabilities.append(
                    {
                        "type": "stack_protection_bypass",
                        "pattern": pattern.hex(),
                        "severity": "critical",
                        "description": "Potential stack canary bypass mechanism detected",
                        "exploit_potential": "critical",
                    },
                )

            return vulnerabilities

        def _detect_format_string(self, binary_data, file_path, **kwargs):
            """Detect format string vulnerabilities."""
            vulnerabilities = []

            # Look for printf family functions with user input
            printf_funcs = [b"printf", b"fprintf", b"sprintf", b"snprintf", b"vprintf"]
            format_patterns = [b"%s", b"%x", b"%p", b"%n", b"%d"]

            for func in printf_funcs:
                if func in binary_data:
                    # Check for format string patterns nearby
                    func_pos = binary_data.find(func)
                    if func_pos != -1:
                        # Look for format specifiers in nearby data
                        context_start = max(0, func_pos - 100)
                        context_end = min(len(binary_data), func_pos + 100)
                        context = binary_data[context_start:context_end]

                        found_patterns = []
                        for pattern in format_patterns:
                            if pattern in context:
                                found_patterns.append(pattern.decode("ascii"))

                        if found_patterns:
                            vulnerabilities.append(
                                {
                                    "type": "format_string_vulnerability",
                                    "function": func.decode("ascii"),
                                    "position": func_pos,
                                    "format_specifiers": found_patterns,
                                    "severity": "high" if b"%n" in context else "medium",
                                    "description": f'Format string vulnerability in {func.decode("ascii")}',
                                    "exploit_potential": "high" if b"%n" in context else "medium",
                                },
                            )

            return vulnerabilities

        def _detect_use_after_free(self, binary_data, file_path, **kwargs):
            """Detect use-after-free vulnerabilities."""
            vulnerabilities = []

            # Look for malloc/free patterns
            alloc_funcs = [b"malloc", b"calloc", b"realloc", b"new"]
            free_funcs = [b"free", b"delete"]

            # First, check if any allocation functions are present
            has_alloc_funcs = any(func in binary_data for func in alloc_funcs)
            if not has_alloc_funcs:
                return vulnerabilities  # No memory allocation, skip use-after-free detection

            # Simplified heuristic: look for free followed by potential use
            for free_func in free_funcs:
                free_positions = []
                start = 0
                while True:
                    pos = binary_data.find(free_func, start)
                    if pos == -1:
                        break
                    free_positions.append(pos)
                    start = pos + 1

                if free_positions:
                    vulnerabilities.append(
                        {
                            "type": "potential_use_after_free",
                            "free_function": free_func.decode("ascii"),
                            "free_occurrences": len(free_positions),
                            "severity": "high",
                            "description": "Memory deallocation detected - potential use-after-free risk",
                            "exploit_potential": "high",
                        },
                    )

            return vulnerabilities

        def _detect_double_free(self, binary_data, file_path, **kwargs):
            """Detect double-free vulnerabilities."""
            vulnerabilities = []

            # Look for multiple free calls in close proximity
            free_positions = []
            start = 0
            while True:
                pos = binary_data.find(b"free", start)
                if pos == -1:
                    break
                free_positions.append(pos)
                start = pos + 1

            # Check for close proximity frees (potential double free)
            for i in range(len(free_positions) - 1):
                if free_positions[i + 1] - free_positions[i] < 100:
                    vulnerabilities.append(
                        {
                            "type": "potential_double_free",
                            "positions": [free_positions[i], free_positions[i + 1]],
                            "severity": "high",
                            "description": "Multiple free calls in close proximity detected",
                            "exploit_potential": "high",
                        },
                    )

            return vulnerabilities

        def _detect_integer_overflow(self, binary_data, file_path, **kwargs):
            """Detect integer overflow vulnerabilities."""
            vulnerabilities = []

            # Look for arithmetic operations without bounds checking
            arithmetic_patterns = [
                b"\x01\xc0",  # add eax, eax
                b"\x29\xc0",  # sub eax, eax
                b"\xf7\xe0",  # mul eax
                b"\x48\x01\xc0",  # add rax, rax (x64)
            ]

            for pattern in arithmetic_patterns:
                if pattern in binary_data:
                    vulnerabilities.append(
                        {
                            "type": "integer_overflow_risk",
                            "pattern": pattern.hex(),
                            "severity": "medium",
                            "description": "Arithmetic operations detected - potential integer overflow",
                            "exploit_potential": "medium",
                        },
                    )

            return vulnerabilities

        def _detect_race_condition(self, binary_data, file_path, **kwargs):
            """Detect race condition vulnerabilities."""
            vulnerabilities = []

            # Look for threading and synchronization primitives
            threading_funcs = [
                b"pthread_create",
                b"CreateThread",
b"mutex",
b"semaphore",
b"critical_section",
b"WaitForSingleObject",
    ]

            found_threading = []
            for func in threading_funcs:
                if func in binary_data:
                    found_threading.append(func.decode("ascii", errors="ignore"))

            if found_threading:
                vulnerabilities.append(
                    {
                        "type": "race_condition_risk",
                        "threading_functions": found_threading,
                        "severity": "medium",
                        "description": "Multi-threading detected - potential race conditions",
                        "exploit_potential": "medium",
                    },
                )

            return vulnerabilities

        def _detect_injection_vulns(self, binary_data, file_path, **kwargs):
            """Detect injection vulnerabilities."""
            vulnerabilities = []

            # Look for system/exec calls
            exec_funcs = [b"system", b"exec", b"popen", b"ShellExecute", b"CreateProcess"]

            for func in exec_funcs:
                if func in binary_data:
                    vulnerabilities.append(
                        {
                            "type": "command_injection_risk",
                            "function": func.decode("ascii", errors="ignore"),
                            "severity": "critical",
                            "description": f'System execution function {func.decode("ascii", errors="ignore")} detected',
                            "exploit_potential": "critical",
                        },
                    )

            # Look for SQL-related strings
            sql_keywords = [b"SELECT", b"INSERT", b"UPDATE", b"DELETE", b"DROP", b"UNION"]
            found_sql = [kw.decode("ascii") for kw in sql_keywords if kw in binary_data]

            if found_sql:
                vulnerabilities.append(
                    {
                        "type": "sql_injection_risk",
                        "keywords": found_sql,
                        "severity": "high",
                        "description": "SQL keywords detected - potential SQL injection",
                        "exploit_potential": "high",
                    },
                )

            return vulnerabilities

        def _detect_crypto_weaknesses(self, binary_data, file_path, **kwargs):
            """Detect cryptographic weaknesses."""
            vulnerabilities = []

            # Look for weak crypto functions
            weak_crypto = [b"MD5", b"SHA1", b"DES", b"RC4", b"md5", b"sha1"]
            strong_crypto = [b"SHA256", b"SHA512", b"AES", b"RSA"]

            found_weak = [c.decode("ascii", errors="ignore") for c in weak_crypto if c in binary_data]
            found_strong = [c.decode("ascii", errors="ignore") for c in strong_crypto if c in binary_data]

            if found_weak:
                vulnerabilities.append(
                    {
                        "type": "weak_cryptography",
                        "weak_algorithms": found_weak,
                        "strong_algorithms": found_strong,  # Include strong algorithms for context
                        "severity": "medium",
                        "description": "Weak cryptographic algorithms detected",
                        "exploit_potential": "medium",
                    },
                )

            # Look for hardcoded keys/passwords
            key_patterns = [b"password", b"secret", b"key=", b"token=", b"Password", b"SECRET", b"KEY=", b"TOKEN="]

            found_secrets = []
            for pattern in key_patterns:
                if pattern in binary_data:
                    found_secrets.append(pattern.decode("ascii", errors="ignore"))

            if found_secrets:
                vulnerabilities.append(
                    {
                        "type": "hardcoded_secrets",
                        "patterns": found_secrets,
                        "severity": "high",
                        "description": "Potential hardcoded secrets detected",
                        "exploit_potential": "high",
                    },
                )

            return vulnerabilities

        def _calculate_risk_score(self, vulnerabilities):
            """Calculate overall risk score based on vulnerabilities."""
            if not vulnerabilities:
                return 0.0

            severity_weights = {"critical": 10.0, "high": 7.0, "medium": 4.0, "low": 1.0, "info": 0.1}

            total_score = 0.0
            for vuln in vulnerabilities:
                severity = vuln.get("severity", "low")
                weight = severity_weights.get(severity, 1.0)
                total_score += weight

            # Normalize to 0-100 scale
            max_possible = len(vulnerabilities) * 10.0
            return min(100.0, (total_score / max_possible) * 100.0) if max_possible > 0 else 0.0

        def _generate_recommendations(self, vulnerabilities):
            """Generate security recommendations based on findings."""
            recommendations = []

            vuln_types = set(v.get("type", "") for v in vulnerabilities)

            if "buffer_overflow_risk" in vuln_types:
                recommendations.append(
                    {
                        "category": "Memory Safety",
                        "recommendation": "Replace dangerous functions with safer alternatives (strncpy, snprintf, etc.)",
                        "priority": "high",
                    },
                )

            if "format_string_vulnerability" in vuln_types:
                recommendations.append(
                    {
                        "category": "Input Validation",
                        "recommendation": "Use format string constants instead of user-controlled format strings",
                        "priority": "high",
                    },
                )

            if "weak_cryptography" in vuln_types:
                recommendations.append(
                    {
                        "category": "Cryptography",
                        "recommendation": "Upgrade to modern cryptographic algorithms (SHA-256, AES)",
                        "priority": "medium",
                    },
                )

            if "command_injection_risk" in vuln_types:
                recommendations.append(
                    {
                        "category": "Input Sanitization",
                        "recommendation": "Sanitize all user input before system execution",
                        "priority": "critical",
                    },
                )

            return recommendations


# Utility functions that use the imported components
def create_binary_differ(config=None):
    """Create a binary differ instance with configuration"""
    differ = BinaryDiffer()
    if config and hasattr(differ, "configure"):
        differ.configure(config)
    return differ


def create_fuzzing_engine(strategy=None, target_binary=None):
    """Create a fuzzing engine with specified strategy"""
    if strategy is None:
        strategy = FuzzingStrategy.MUTATION_BASED

    engine = FuzzingEngine()
    if hasattr(engine, "set_strategy"):
        engine.set_strategy(strategy)
    if target_binary and hasattr(engine, "set_target"):
        engine.set_target(target_binary)

    return engine


def get_available_analysis_methods():
    """Get list of available analysis methods"""
    methods = []
    if hasattr(AnalysisMethod, "STATIC"):
        methods.append(AnalysisMethod.STATIC)
    if hasattr(AnalysisMethod, "DYNAMIC"):
        methods.append(AnalysisMethod.DYNAMIC)
    if hasattr(AnalysisMethod, "SYMBOLIC"):
        methods.append(AnalysisMethod.SYMBOLIC)
    if hasattr(AnalysisMethod, "HYBRID"):
        methods.append(AnalysisMethod.HYBRID)
    return methods


def create_vulnerability_analyzer(method=None):
    """Create a vulnerability analyzer with specified method"""
    analyzer = VulnerabilityAnalyzer()
    if method and hasattr(analyzer, "set_method"):
        analyzer.set_method(method)
    return analyzer


def get_campaign_status_options():
    """Get available campaign status options"""
    statuses = []
    if hasattr(CampaignStatus, "PENDING"):
        statuses.append(CampaignStatus.PENDING)
    if hasattr(CampaignStatus, "RUNNING"):
        statuses.append(CampaignStatus.RUNNING)
    if hasattr(CampaignStatus, "COMPLETED"):
        statuses.append(CampaignStatus.COMPLETED)
    if hasattr(CampaignStatus, "FAILED"):
        statuses.append(CampaignStatus.FAILED)
    return statuses


class ResearchWorkerThread(QThread):
    """Background worker for research operations."""

    # Add signals for different research operations
    binary_diff_completed = pyqtSignal(dict)  # diff results
    fuzzing_progress = pyqtSignal(str, float)  # status, progress
    analysis_completed = pyqtSignal(str, dict)  # method, results
    campaign_status_changed = pyqtSignal(str, str)  # campaign_id, status

    campaign_updated = pyqtSignal(str, dict)  # campaign_id, status
    results_ready = pyqtSignal(str, dict)  # campaign_id, results
    error_occurred = pyqtSignal(str, str)  # operation, error_message

    def __init__(self):
        """Initialize the research worker thread for vulnerability analysis operations."""
        super().__init__()
        self.research_manager = ResearchManager() if RESEARCH_AVAILABLE else None
        self.operation_queue = []
        self.running = True

    def add_operation(self, operation_type: str, **kwargs):
        """Add operation to processing queue."""
        self.operation_queue.append({"type": operation_type, "args": kwargs, "timestamp": time.time()})

    def run(self):
        """Main worker thread loop."""
        while self.running:
            if self.operation_queue:
                operation = self.operation_queue.pop(0)
                self._process_operation(operation)
            else:
                self.msleep(100)  # Sleep 100ms when idle

    def _process_operation(self, operation: dict[str, Any]):
        """Process a single operation."""
        try:
            op_type = operation["type"]
            args = operation["args"]

            if op_type == "create_campaign":
                self._create_campaign(**args)
            elif op_type == "start_campaign":
                self._start_campaign(**args)

        except Exception as e:
            self.logger.error("Exception in vulnerability_research_dialog: %s", e)
            self.error_occurred.emit(operation["type"], str(e))

    def _create_campaign(
        self,
        name: str,
        campaign_type: str,
        targets: list[str],
        template: str | None = None,
        config: dict | None = None,
    ):
        """Create research campaign."""
        if not self.research_manager:
            self.error_occurred.emit("create_campaign", "Research manager not available")
            return

        campaign_type_enum = CampaignType(campaign_type)
        result = self.research_manager.create_campaign(
            name=name, campaign_type=campaign_type_enum, targets=targets, template=template, custom_config=config,
        )

        if result["success"]:
            self.campaign_updated.emit(result["campaign_id"], result)
        else:
            self.error_occurred.emit("create_campaign", result.get("error", "Unknown error"))

    def _start_campaign(self, campaign_id: str):
        """Start research campaign."""
        if not self.research_manager:
            self.error_occurred.emit("start_campaign", "Research manager not available")
            return

        result = self.research_manager.start_campaign(campaign_id)

        if result["success"]:
            self.results_ready.emit(campaign_id, result["results"])
        else:
            self.error_occurred.emit("start_campaign", result.get("error", "Unknown error"))

    def stop(self):
        """Stop worker thread."""
        self.running = False


class VulnerabilityResearchDialog(QDialog):
    """Main dialog for vulnerability research and ML adaptation.
    """

    def __init__(self, parent=None):
        """Initialize the vulnerability research dialog with analysis engines and worker threads."""
        super().__init__(parent)
        self.setWindowTitle("Vulnerability Research")
        self.setMinimumSize(1400, 900)

        # Initialize components
        self.research_manager = ResearchManager() if RESEARCH_AVAILABLE else None

        # Active campaigns and results
        self.active_campaigns = {}
        self.campaign_results = {}

        # Worker thread
        self.worker = ResearchWorkerThread()
        self.worker.campaign_updated.connect(self._on_campaign_updated)
        self.worker.results_ready.connect(self._on_results_ready)
        self.worker.error_occurred.connect(self._on_error_occurred)
        self.worker.adaptation_complete.connect(self._on_adaptation_complete)
        self.worker.start()

        # Update timer
        self.update_timer = QTimer()
        self.update_timer.timeout.connect(self._update_campaign_status)
        self.update_timer.start(2000)  # Update every 2 seconds

        self._setup_ui()
        self._load_initial_data()

    def _setup_ui(self):
        """Setup user interface."""
        layout = QVBoxLayout(self)

        # Main tab widget
        self.tab_widget = QTabWidget()
        layout.addWidget(self.tab_widget)

        # Research campaigns tab
        self.campaigns_tab = self._create_campaigns_tab()
        self.tab_widget.addTab(self.campaigns_tab, "Research Campaigns")

        # Coverage visualization tab
        self.coverage_tab = self._create_coverage_tab()
        self.tab_widget.addTab(self.coverage_tab, "Coverage Analysis")

        # Results analysis tab
        self.results_tab = self._create_results_tab()
        self.tab_widget.addTab(self.results_tab, "Results & Analysis")

        # Configuration tab
        self.config_tab = self._create_configuration_tab()
        self.tab_widget.addTab(self.config_tab, "Configuration")

# Button layout
        button_layout = QHBoxLayout()

        self.export_btn = QPushButton("Export Results")
        self.export_btn.clicked.connect(self._export_results)
        button_layout.addWidget(self.export_btn)

        button_layout.addStretch()

        self.close_btn = QPushButton("Close")
        self.close_btn.clicked.connect(self.close)
        button_layout.addWidget(self.close_btn)

        layout.addLayout(button_layout)

    def _create_campaigns_tab(self) -> QWidget:
        """Create research campaigns tab."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Campaign creation section
        creation_group = QGroupBox("Create New Campaign")
        creation_layout = QGridLayout(creation_group)

        # Campaign details
        creation_layout.addWidget(QLabel("Campaign Name:"), 0, 0)
        self.campaign_name_edit = QLineEdit()
        creation_layout.addWidget(self.campaign_name_edit, 0, 1)

        creation_layout.addWidget(QLabel("Campaign Type:"), 1, 0)
        self.campaign_type_combo = QComboBox()
        self.campaign_type_combo.addItems(
            ["Binary Analysis", "Fuzzing", "Vulnerability Assessment", "Patch Analysis", "Hybrid Research"],
        )
        creation_layout.addWidget(self.campaign_type_combo, 1, 1)

        creation_layout.addWidget(QLabel("Template:"), 2, 0)
        self.template_combo = QComboBox()
        self.template_combo.addItems(["None", "Basic Fuzzing", "Comprehensive Analysis", "Patch Research"])
        creation_layout.addWidget(self.template_combo, 2, 1)

        # Target selection
        creation_layout.addWidget(QLabel("Targets:"), 3, 0)
        self.targets_edit = QTextEdit()
        self.targets_edit.setMaximumHeight(80)
        self.targets_edit.setPlaceholderText("Enter target files/directories (one per line)")
        creation_layout.addWidget(self.targets_edit, 3, 1)

        # Buttons
        button_layout = QHBoxLayout()

        self.browse_targets_btn = QPushButton("Browse Targets")
        self.browse_targets_btn.clicked.connect(self._browse_targets)
        button_layout.addWidget(self.browse_targets_btn)

        self.create_campaign_btn = QPushButton("Create Campaign")
        self.create_campaign_btn.clicked.connect(self._create_campaign)
        button_layout.addWidget(self.create_campaign_btn)

        creation_layout.addLayout(button_layout, 4, 0, 1, 2)

        layout.addWidget(creation_group)

        # Active campaigns section
        campaigns_group = QGroupBox("Active Campaigns")
        campaigns_layout = QVBoxLayout(campaigns_group)

        # Campaign list
        self.campaigns_tree = QTreeWidget()
        self.campaigns_tree.setHeaderLabels(["Campaign", "Type", "Status", "Progress", "Targets", "Created"])
        self.campaigns_tree.itemDoubleClicked.connect(self._show_campaign_details)
        campaigns_layout.addWidget(self.campaigns_tree)

        # Campaign controls
        controls_layout = QHBoxLayout()

        self.start_campaign_btn = QPushButton("Start")
        self.start_campaign_btn.clicked.connect(self._start_selected_campaign)
        controls_layout.addWidget(self.start_campaign_btn)

        self.pause_campaign_btn = QPushButton("Pause")
        self.pause_campaign_btn.clicked.connect(self._pause_selected_campaign)
        controls_layout.addWidget(self.pause_campaign_btn)

        self.cancel_campaign_btn = QPushButton("Cancel")
        self.cancel_campaign_btn.clicked.connect(self._cancel_selected_campaign)
        controls_layout.addWidget(self.cancel_campaign_btn)

        controls_layout.addStretch()

        self.refresh_campaigns_btn = QPushButton("Refresh")
        self.refresh_campaigns_btn.clicked.connect(self._refresh_campaigns)
        controls_layout.addWidget(self.refresh_campaigns_btn)

        campaigns_layout.addLayout(controls_layout)

        layout.addWidget(campaigns_group)

        return widget

    def _create_results_tab(self) -> QWidget:
        """Create results analysis tab."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Results splitter
        splitter = QSplitter(Qt.Horizontal)

        # Campaign results list
        results_group = QGroupBox("Campaign Results")
        results_layout = QVBoxLayout(results_group)

        self.results_tree = QTreeWidget()
        self.results_tree.setHeaderLabels(["Campaign", "Type", "Status", "Results", "Completed"])
        self.results_tree.itemSelectionChanged.connect(self._show_result_details)
        results_layout.addWidget(self.results_tree)

        splitter.addWidget(results_group)

        # Result details
        details_group = QGroupBox("Result Details")
        details_layout = QVBoxLayout(details_group)

        # Result tabs
        self.result_tabs = QTabWidget()

        # Summary tab
        self.summary_edit = QTextEdit()
        self.summary_edit.setReadOnly(True)
        self.result_tabs.addTab(self.summary_edit, "Summary")

        # Vulnerabilities tab
        self.vulnerabilities_table = QTableWidget(0, 5)
        self.vulnerabilities_table.setHorizontalHeaderLabels(
            ["Type", "Severity", "Location", "Exploitable", "Description"],
        )
        self.result_tabs.addTab(self.vulnerabilities_table, "Vulnerabilities")

        # Correlation tab
        self.correlation_edit = QTextEdit()
        self.correlation_edit.setReadOnly(True)
        self.result_tabs.addTab(self.correlation_edit, "Correlation")

        # Raw data tab
        self.raw_data_edit = QTextEdit()
        self.raw_data_edit.setReadOnly(True)
        self.result_tabs.addTab(self.raw_data_edit, "Raw Data")

        details_layout.addWidget(self.result_tabs)

        splitter.addWidget(details_group)

        layout.addWidget(splitter)

        # Analysis controls
        analysis_layout = QHBoxLayout()

        self.generate_report_btn = QPushButton("Generate Report")
        self.generate_report_btn.clicked.connect(self._generate_report)
        analysis_layout.addWidget(self.generate_report_btn)

        self.correlate_results_btn = QPushButton("Correlate Results")
        self.correlate_results_btn.clicked.connect(self._correlate_results)
        analysis_layout.addWidget(self.correlate_results_btn)

        analysis_layout.addStretch()

        layout.addLayout(analysis_layout)

        return widget

    def _create_coverage_tab(self) -> QWidget:
        """Create coverage analysis and visualization tab."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Coverage controls
        controls_group = QGroupBox("Coverage Analysis Controls")
        controls_layout = QHBoxLayout(controls_group)

        # Binary selection
        self.coverage_binary_edit = QLineEdit()
        self.coverage_binary_edit.setPlaceholderText("Select binary for coverage analysis...")
        controls_layout.addWidget(QLabel("Binary:"))
        controls_layout.addWidget(self.coverage_binary_edit)

        self.browse_binary_btn = QPushButton("Browse")
        self.browse_binary_btn.clicked.connect(self._browse_coverage_binary)
        controls_layout.addWidget(self.browse_binary_btn)

        # Test case directory
        self.test_cases_edit = QLineEdit()
        self.test_cases_edit.setPlaceholderText("Test cases directory...")
        controls_layout.addWidget(QLabel("Test Cases:"))
        controls_layout.addWidget(self.test_cases_edit)

        self.browse_tests_btn = QPushButton("Browse")
        self.browse_tests_btn.clicked.connect(self._browse_test_cases)
        controls_layout.addWidget(self.browse_tests_btn)

        # Analysis button
        self.analyze_coverage_btn = QPushButton("Analyze Coverage")
        self.analyze_coverage_btn.clicked.connect(self._analyze_coverage)
        controls_layout.addWidget(self.analyze_coverage_btn)

        layout.addWidget(controls_group)

        # Coverage visualization splitter
        splitter = QSplitter(Qt.Horizontal)

        # Left panel - Coverage overview
        left_panel = QWidget()
        left_layout = QVBoxLayout(left_panel)

        # Coverage summary
        summary_group = QGroupBox("Coverage Summary")
        summary_layout = QVBoxLayout(summary_group)

        self.coverage_summary_text = QTextEdit()
        self.coverage_summary_text.setMaximumHeight(150)
        self.coverage_summary_text.setReadOnly(True)
        summary_layout.addWidget(self.coverage_summary_text)

        left_layout.addWidget(summary_group)

        # Coverage metrics
        metrics_group = QGroupBox("Coverage Metrics")
        metrics_layout = QVBoxLayout(metrics_group)

        self.coverage_metrics_widget = self._create_coverage_metrics_widget()
        metrics_layout.addWidget(self.coverage_metrics_widget)

        left_layout.addWidget(metrics_group)

        # Hot/Cold spots
        spots_group = QGroupBox("Hot/Cold Spots")
        spots_layout = QVBoxLayout(spots_group)

        self.spots_tabs = QTabWidget()

        # Hot spots
        self.hot_spots_table = QTableWidget(0, 4)
        self.hot_spots_table.setHorizontalHeaderLabels(["Function", "File", "Execution Count", "Complexity"])
        self.spots_tabs.addTab(self.hot_spots_table, "Hot Spots")

        # Cold spots
        self.cold_spots_table = QTableWidget(0, 3)
        self.cold_spots_table.setHorizontalHeaderLabels(["Function", "File", "Status"])
        self.spots_tabs.addTab(self.cold_spots_table, "Cold Spots")

        spots_layout.addWidget(self.spots_tabs)
        left_layout.addWidget(spots_group)

        splitter.addWidget(left_panel)

        # Right panel - Detailed coverage
        right_panel = QWidget()
        right_layout = QVBoxLayout(right_panel)

        # File coverage
        file_coverage_group = QGroupBox("File Coverage Details")
        file_coverage_layout = QVBoxLayout(file_coverage_group)

        # File selector
        file_selector_layout = QHBoxLayout()
        file_selector_layout.addWidget(QLabel("File:"))

        self.file_coverage_combo = QComboBox()
        self.file_coverage_combo.currentTextChanged.connect(self._show_file_coverage)
        file_selector_layout.addWidget(self.file_coverage_combo)

        file_coverage_layout.addLayout(file_selector_layout)

        # Coverage display
        self.file_coverage_display = QTextEdit()
        self.file_coverage_display.setReadOnly(True)
        self.file_coverage_display.setFont(self._get_monospace_font())
        file_coverage_layout.addWidget(self.file_coverage_display)

        right_layout.addWidget(file_coverage_group)

        # Function coverage
        function_coverage_group = QGroupBox("Function Coverage")
        function_coverage_layout = QVBoxLayout(function_coverage_group)

        self.function_coverage_table = QTableWidget(0, 6)
        self.function_coverage_table.setHorizontalHeaderLabels(
            ["Function", "File", "Line", "Executed", "Count", "Complexity"],
        )
        function_coverage_layout.addWidget(self.function_coverage_table)

        right_layout.addWidget(function_coverage_group)

        splitter.addWidget(right_panel)
        layout.addWidget(splitter)

        # Export controls
        export_layout = QHBoxLayout()

        self.export_coverage_btn = QPushButton("Export Coverage Report")
        self.export_coverage_btn.clicked.connect(self._export_coverage_report)
        export_layout.addWidget(self.export_coverage_btn)

        self.export_viz_btn = QPushButton("Export Visualization")
        self.export_viz_btn.clicked.connect(self._export_coverage_visualization)
        export_layout.addWidget(self.export_viz_btn)

        export_layout.addStretch()

        layout.addLayout(export_layout)

        # Initialize with empty state
        self._clear_coverage_display()

        return widget

    def _create_coverage_metrics_widget(self) -> QWidget:
        """Create widget for displaying coverage metrics with progress bars."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Line coverage
        line_layout = QHBoxLayout()
        line_layout.addWidget(QLabel("Line Coverage:"))
        self.line_coverage_bar = self._create_progress_bar()
        self.line_coverage_label = QLabel("0%")
        line_layout.addWidget(self.line_coverage_bar)
        line_layout.addWidget(self.line_coverage_label)
        layout.addLayout(line_layout)

        # Function coverage
        function_layout = QHBoxLayout()
        function_layout.addWidget(QLabel("Function Coverage:"))
        self.function_coverage_bar = self._create_progress_bar()
        self.function_coverage_label = QLabel("0%")
        function_layout.addWidget(self.function_coverage_bar)
        function_layout.addWidget(self.function_coverage_label)
        layout.addLayout(function_layout)

        # Branch coverage
        branch_layout = QHBoxLayout()
        branch_layout.addWidget(QLabel("Branch Coverage:"))
        self.branch_coverage_bar = self._create_progress_bar()
        self.branch_coverage_label = QLabel("0%")
        branch_layout.addWidget(self.branch_coverage_bar)
        branch_layout.addWidget(self.branch_coverage_label)
        layout.addLayout(branch_layout)

        return widget

    def _create_progress_bar(self):
        """Create styled progress bar for coverage display."""
        from PyQt6.QtWidgets import QProgressBar

        progress_bar = QProgressBar()
        progress_bar.setRange(0, 100)
        progress_bar.setValue(0)
        progress_bar.setTextVisible(False)

        # Style the progress bar with color coding
        progress_bar.setStyleSheet(
            """
            QProgressBar {
                border: 1px solid #666;
                border-radius: 3px;
                text-align: center;
                background-color: #f0f0f0;
            }
            QProgressBar::chunk {
                background-color: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                    stop:0 #ff0000, stop:0.4 #ff8800,
                    stop:0.6 #ffff00, stop:0.8 #88ff00, stop:1.0 #00ff00);
                border-radius: 2px;
            }
            """,
        )

        return progress_bar

    def _get_monospace_font(self):
        """Get monospace font for code display."""
        from PyQt6.QtGui import QFont

        font = QFont()
        font.setFamily("Consolas, Monaco, monospace")
        font.setFixedPitch(True)
        font.setPointSize(10)
        return font

    def _browse_coverage_binary(self):
        """Browse for binary file to analyze coverage."""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "Select Binary for Coverage Analysis", "", "Executable Files (*.exe *.elf);;All Files (*)",
        )
        if file_path:
            self.coverage_binary_edit.setText(file_path)

    def _browse_test_cases(self):
        """Browse for test cases directory."""
        dir_path = QFileDialog.getExistingDirectory(self, "Select Test Cases Directory")
        if dir_path:
            self.test_cases_edit.setText(dir_path)

    def _analyze_coverage(self):
        """Perform coverage analysis on selected binary and test cases."""
        binary_path = self.coverage_binary_edit.text().strip()
        test_cases_dir = self.test_cases_edit.text().strip()

        if not binary_path:
            QMessageBox.warning(self, "Warning", "Please select a binary file.")
            return

        if not test_cases_dir:
            QMessageBox.warning(self, "Warning", "Please select test cases directory.")
            return

        try:
            import os
            import tempfile

            # Create fuzzing engine for coverage analysis
            fuzzing_engine = FuzzingEngine()

            self.coverage_summary_text.append("Starting coverage analysis...")
            self.coverage_summary_text.append(f"Binary: {binary_path}")
            self.coverage_summary_text.append(f"Test cases: {test_cases_dir}")

            # Collect all test case files
            test_files = []
            for root, dirs, files in os.walk(test_cases_dir):
                for file in files:
                    test_files.append(os.path.join(root, file))

            if not test_files:
                QMessageBox.warning(self, "Warning", "No test files found in directory.")
                return

            self.coverage_summary_text.append(f"Found {len(test_files)} test cases")

            # Analyze coverage for each test case
            all_coverage_data = []
            detailed_coverage = None

            with tempfile.TemporaryDirectory() as _:
                for i, test_file in enumerate(test_files[:100]):  # Limit to first 100 for performance
                    try:
                        coverage_data = fuzzing_engine._get_real_coverage(binary_path, test_file)
                        if coverage_data:
                            all_coverage_data.append(coverage_data)

                            # Use detailed coverage from first successful analysis
                            if coverage_data.get("detailed_coverage") and not detailed_coverage:
                                detailed_coverage = coverage_data["detailed_coverage"]

                        # Update progress
                        if (i + 1) % 10 == 0:
                            self.coverage_summary_text.append(
                                f"Processed {i + 1}/{min(len(test_files), 100)} test cases",
                            )
                            self.coverage_summary_text.repaint()

                    except Exception as e:
                        logger.debug(f"Coverage analysis failed for {test_file}: {e}")
                        continue

            if not all_coverage_data:
                QMessageBox.warning(self, "Warning", "No coverage data could be collected.")
                return

            # Aggregate coverage data
            aggregated_coverage = self._aggregate_coverage_data(all_coverage_data)

            # Use detailed coverage if available, otherwise use aggregated
            if detailed_coverage:
                self._display_coverage_results(detailed_coverage, aggregated_coverage)
            else:
                # Create basic coverage info from aggregated data
                basic_coverage = {
                    "summary": {
                        "executed_lines": aggregated_coverage.get("basic_blocks", 0),
                        "total_lines": aggregated_coverage.get("basic_blocks", 0) * 2,  # Estimate
                        "executed_functions": aggregated_coverage.get("functions", 0),
                        "total_functions": aggregated_coverage.get("functions", 0) * 2,  # Estimate
                        "taken_branches": aggregated_coverage.get("branches", 0),
                        "total_branches": aggregated_coverage.get("branches", 0) * 2,  # Estimate
                    },
                    "files": {},
                    "functions": [],
                    "hot_spots": [],
                    "cold_spots": [],
                }
                self._display_coverage_results(basic_coverage, aggregated_coverage)

            self.coverage_summary_text.append("Coverage analysis completed!")

        except Exception as e:
            QMessageBox.critical(self, "Error", f"Coverage analysis failed: {e!s}")
            logger.error(f"Coverage analysis error: {e}")

    def _aggregate_coverage_data(self, coverage_data_list):
        """Aggregate coverage data from multiple test cases."""
        if not coverage_data_list:
            return {}

        # Find maximum coverage achieved across all test cases
        max_basic_blocks = max(data.get("basic_blocks", 0) for data in coverage_data_list)
        max_functions = max(data.get("functions", 0) for data in coverage_data_list)
        max_branches = max(data.get("branches", 0) for data in coverage_data_list)

        return {
            "basic_blocks": max_basic_blocks,
            "functions": max_functions,
            "branches": max_branches,
    "test_cases_analyzed": len(coverage_data_list),
}

    def _display_coverage_results(self, detailed_coverage, aggregated_coverage):
        """Display coverage analysis results in the UI."""
        try:
            summary = detailed_coverage.get("summary", {})

            # Update summary text
            summary_text = f"""Coverage Analysis Results:

Total Lines: {summary.get('total_lines', 0)}
Executed Lines: {summary.get('executed_lines', 0)}
Line Coverage: {(summary.get('executed_lines', 0) / max(summary.get('total_lines', 1), 1) * 100):.1f}%

Total Functions: {summary.get('total_functions', 0)}
Executed Functions: {summary.get('executed_functions', 0)}
Function Coverage: {(summary.get('executed_functions', 0) / max(summary.get('total_functions', 1), 1) * 100):.1f}%

Total Branches: {summary.get('total_branches', 0)}
Taken Branches: {summary.get('taken_branches', 0)}
Branch Coverage: {(summary.get('taken_branches', 0) / max(summary.get('total_branches', 1), 1) * 100):.1f}%

Test Cases Analyzed: {aggregated_coverage.get('test_cases_analyzed', 0)}
"""

            self.coverage_summary_text.clear()
            self.coverage_summary_text.append(summary_text)

            # Update progress bars
            line_coverage_pct = summary.get("executed_lines", 0) / max(summary.get("total_lines", 1), 1) * 100
            function_coverage_pct = (
                summary.get("executed_functions", 0) / max(summary.get("total_functions", 1), 1) * 100
            )
            branch_coverage_pct = summary.get("taken_branches", 0) / max(summary.get("total_branches", 1), 1) * 100

            self.line_coverage_bar.setValue(int(line_coverage_pct))
            self.line_coverage_label.setText(f"{line_coverage_pct:.1f}%")

            self.function_coverage_bar.setValue(int(function_coverage_pct))
            self.function_coverage_label.setText(f"{function_coverage_pct:.1f}%")

            self.branch_coverage_bar.setValue(int(branch_coverage_pct))
            self.branch_coverage_label.setText(f"{branch_coverage_pct:.1f}%")

            # Update hot spots table
            self._update_hot_spots_table(detailed_coverage.get("hot_spots", []))

            # Update cold spots table
            self._update_cold_spots_table(detailed_coverage.get("cold_spots", []))

            # Update file coverage combo
            self._update_file_coverage_combo(detailed_coverage.get("files", {}))

            # Update function coverage table
            self._update_function_coverage_table(detailed_coverage.get("functions", []))

        except Exception as e:
            logger.error(f"Failed to display coverage results: {e}")

    def _update_hot_spots_table(self, hot_spots):
        """Update hot spots table with execution data."""
        self.hot_spots_table.setRowCount(len(hot_spots))

        for row, spot in enumerate(hot_spots):
            self.hot_spots_table.setItem(row, 0, QTableWidgetItem(spot.get("name", "Unknown")))
            self.hot_spots_table.setItem(row, 1, QTableWidgetItem(spot.get("file", "Unknown")))
            self.hot_spots_table.setItem(row, 2, QTableWidgetItem(str(spot.get("execution_count", 0))))
            self.hot_spots_table.setItem(row, 3, QTableWidgetItem(str(spot.get("complexity", 1))))

    def _update_cold_spots_table(self, cold_spots):
        """Update cold spots table with unexecuted functions."""
        self.cold_spots_table.setRowCount(len(cold_spots))

        for row, spot in enumerate(cold_spots):
            self.cold_spots_table.setItem(row, 0, QTableWidgetItem(spot.get("name", "Unknown")))
            self.cold_spots_table.setItem(row, 1, QTableWidgetItem(spot.get("file", "Unknown")))
            status = "Never executed" if not spot.get("executed") else "Rarely executed"
            self.cold_spots_table.setItem(row, 2, QTableWidgetItem(status))

    def _update_file_coverage_combo(self, files_data):
        """Update file coverage combo box."""
        self.file_coverage_combo.clear()
        for filename in files_data.keys():
            self.file_coverage_combo.addItem(filename)

    def _update_function_coverage_table(self, functions_data):
        """Update function coverage table."""
        self.function_coverage_table.setRowCount(len(functions_data))

        for row, func in enumerate(functions_data):
            self.function_coverage_table.setItem(row, 0, QTableWidgetItem(func.get("name", "Unknown")))
            self.function_coverage_table.setItem(row, 1, QTableWidgetItem(func.get("file", "Unknown")))
            self.function_coverage_table.setItem(row, 2, QTableWidgetItem(str(func.get("line", 0))))
            self.function_coverage_table.setItem(row, 3, QTableWidgetItem("Yes" if func.get("executed") else "No"))
            self.function_coverage_table.setItem(row, 4, QTableWidgetItem(str(func.get("execution_count", 0))))
            self.function_coverage_table.setItem(row, 5, QTableWidgetItem(str(func.get("complexity", 1))))

    def _show_file_coverage(self, filename):
        """Show detailed coverage for selected file."""
        if not filename:
            return

        try:
            # Get coverage data for the file
            coverage_data = getattr(self, "_last_coverage_data", {})
            file_coverage = coverage_data.get("file_coverage", {}).get(filename, {})

            # Read the source file
            source_lines = []
            try:
                with open(filename, encoding="utf-8", errors="ignore") as f:
                    source_lines = f.readlines()
            except Exception as e:
                logger.error(f"Failed to read source file {filename}: {e}")
                self.file_coverage_display.setText(f"Error reading file: {filename}\n{e!s}")
                return

            # Build coverage display with line numbers and execution counts
            coverage_text = f"Detailed coverage for {filename}:\n"
            coverage_text += f"Total lines: {len(source_lines)}\n"

            executed_lines = file_coverage.get("executed_lines", set())
            executable_lines = file_coverage.get("executable_lines", set())
            execution_counts = file_coverage.get("execution_counts", {})

            if executable_lines:
                coverage_pct = (len(executed_lines) / len(executable_lines)) * 100
                coverage_text += f"Coverage: {coverage_pct:.1f}% ({len(executed_lines)}/{len(executable_lines)} lines)\n"

            coverage_text += "\n" + "="*80 + "\n\n"

            # Display each line with coverage info
            for i, line in enumerate(source_lines, 1):
                line = line.rstrip()

                # Determine line status
                if i in executed_lines:
                    count = execution_counts.get(i, 1)
                    prefix = f" {count:4d}x"
                elif i in executable_lines:
                    prefix = "     "
                else:
                    prefix = "      "

                # Format line
                coverage_text += f"{i:5d} {prefix} | {line}\n"

                # Add branch coverage info if available
                branch_info = file_coverage.get("branch_coverage", {}).get(i)
                if branch_info:
                    taken = branch_info.get("taken", 0)
                    total = branch_info.get("total", 0)
                    coverage_text += f"      Branch: {taken}/{total} paths taken\n"

            self.file_coverage_display.setText(coverage_text)

        except Exception as e:
            logger.error(f"Failed to display file coverage: {e}")
            self.file_coverage_display.setText(f"Error displaying coverage: {e!s}")

    def _clear_coverage_display(self):
        """Clear all coverage display elements."""
        self.coverage_summary_text.clear()
        self.line_coverage_bar.setValue(0)
        self.function_coverage_bar.setValue(0)
        self.branch_coverage_bar.setValue(0)
        self.line_coverage_label.setText("0%")
        self.function_coverage_label.setText("0%")
        self.branch_coverage_label.setText("0%")
        self.hot_spots_table.setRowCount(0)
        self.cold_spots_table.setRowCount(0)
        self.function_coverage_table.setRowCount(0)
        self.file_coverage_combo.clear()
        self.file_coverage_display.clear()

    def _export_coverage_report(self):
        """Export detailed coverage report to file."""
        if not hasattr(self, "_current_coverage_data"):
            QMessageBox.warning(self, "Warning", "No coverage data available to export.")
            return

        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export Coverage Report", "coverage_report.json", "JSON Files (*.json);;All Files (*)",
        )

        if file_path:
            try:
                # Create fuzzing engine to generate report
                fuzzing_engine = FuzzingEngine()
                report = fuzzing_engine._generate_coverage_report(self._current_coverage_data, file_path)

                if report:
                    QMessageBox.information(self, "Success", f"Coverage report exported to {file_path}")
                else:
                    QMessageBox.warning(self, "Warning", "Failed to generate coverage report.")

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Export failed: {e!s}")

    def _export_coverage_visualization(self):
        """Export coverage visualization data."""
        if not hasattr(self, "_current_coverage_data"):
            QMessageBox.warning(self, "Warning", "No coverage data available to export.")
            return

        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export Coverage Visualization", "coverage_visualization.json", "JSON Files (*.json);;All Files (*)",
        )

        if file_path:
            try:
                import json

                # Create fuzzing engine to generate visualization data
                fuzzing_engine = FuzzingEngine()
                viz_data = fuzzing_engine._visualize_coverage_data(self._current_coverage_data)

                if viz_data:
                    with open(file_path, "w") as f:
                        json.dump(viz_data, f, indent=2)
                    QMessageBox.information(self, "Success", f"Visualization data exported to {file_path}")
                else:
                    QMessageBox.warning(self, "Warning", "Failed to generate visualization data.")

            except Exception as e:
                QMessageBox.critical(self, "Error", f"Export failed: {e!s}")

    def _create_configuration_tab(self) -> QWidget:
        """Create configuration tab."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Research configuration
        research_group = QGroupBox("Research Configuration")
        research_layout = QGridLayout(research_group)

        research_layout.addWidget(QLabel("Max Concurrent Campaigns:"), 0, 0)
        self.max_campaigns_spin = QSpinBox()
        self.max_campaigns_spin.setRange(1, 20)
        self.max_campaigns_spin.setValue(5)
        research_layout.addWidget(self.max_campaigns_spin, 0, 1)

        research_layout.addWidget(QLabel("Default Timeout (seconds):"), 1, 0)
        self.timeout_spin = QSpinBox()
        self.timeout_spin.setRange(300, 86400)
        self.timeout_spin.setValue(3600)
        research_layout.addWidget(self.timeout_spin, 1, 1)

        research_layout.addWidget(QLabel("Result Storage Directory:"), 2, 0)
        self.storage_dir_edit = QLineEdit()
        self.storage_dir_edit.setText("/tmp/intellicrack_research")
        research_layout.addWidget(self.storage_dir_edit, 2, 1)

        research_layout.addWidget(QLabel("Auto Correlation:"), 3, 0)
        self.auto_correlation_check = QCheckBox()
        self.auto_correlation_check.setChecked(True)
        research_layout.addWidget(self.auto_correlation_check, 3, 1)

        layout.addWidget(research_group)

        # ML configuration
        ml_group = QGroupBox("ML Configuration")
        ml_layout = QGridLayout(ml_group)

        ml_layout.addWidget(QLabel("Min Training Samples:"), 0, 0)
        self.min_samples_spin = QSpinBox()
        self.min_samples_spin.setRange(10, 1000)
        self.min_samples_spin.setValue(50)
        ml_layout.addWidget(self.min_samples_spin, 0, 1)

        ml_layout.addWidget(QLabel("Retrain Threshold:"), 1, 0)
        self.retrain_threshold_spin = QSpinBox()
        self.retrain_threshold_spin.setRange(50, 10000)
        self.retrain_threshold_spin.setValue(100)
        ml_layout.addWidget(self.retrain_threshold_spin, 1, 1)

        ml_layout.addWidget(QLabel("Confidence Threshold:"), 2, 0)
        self.confidence_spin = QSpinBox()
        self.confidence_spin.setRange(50, 99)
        self.confidence_spin.setValue(70)
        self.confidence_spin.setSuffix("%")
        ml_layout.addWidget(self.confidence_spin, 2, 1)

        layout.addWidget(ml_group)

        # Integration settings
        integration_group = QGroupBox("Integration Settings")
        integration_layout = QGridLayout(integration_group)

        integration_layout.addWidget(QLabel("AI Model Integration:"), 0, 0)
        self.ai_integration_check = QCheckBox()
        self.ai_integration_check.setChecked(True)
        integration_layout.addWidget(self.ai_integration_check, 0, 1)

        integration_layout.addWidget(QLabel("Automated Exploitation:"), 1, 0)
        self.auto_exploitation_check = QCheckBox()
        self.auto_exploitation_check.setChecked(False)
        integration_layout.addWidget(self.auto_exploitation_check, 1, 1)

        integration_layout.addWidget(QLabel("Real-time Adaptation:"), 2, 0)
        self.realtime_adaptation_check = QCheckBox()
        self.realtime_adaptation_check.setChecked(True)
        integration_layout.addWidget(self.realtime_adaptation_check, 2, 1)

        layout.addWidget(integration_group)

        # Configuration controls
        config_controls = QHBoxLayout()

        self.save_config_btn = QPushButton("Save Configuration")
        self.save_config_btn.clicked.connect(self._save_configuration)
        config_controls.addWidget(self.save_config_btn)

        self.load_config_btn = QPushButton("Load Configuration")
        self.load_config_btn.clicked.connect(self._load_configuration)
        config_controls.addWidget(self.load_config_btn)

        self.reset_config_btn = QPushButton("Reset to Defaults")
        self.reset_config_btn.clicked.connect(self._reset_configuration)
        config_controls.addWidget(self.reset_config_btn)

        config_controls.addStretch()

        layout.addLayout(config_controls)
        layout.addStretch()

        return widget

    # Event handlers and operations

    def _load_initial_data(self):
        """Load initial data and populate UI."""
        try:
            if not RESEARCH_AVAILABLE:
                QMessageBox.warning(self, "Warning", "Research components not available. Some features may be limited.")
                return

            # Load existing campaigns
            self._refresh_campaigns()

            # Load model status
            self._refresh_models()

            # Load results
            self._refresh_results()

        except Exception as e:
            logger.error(f"Failed to load initial data: {e}")

    def _browse_targets(self):
        """Browse for target files."""
        files, _ = QFileDialog.getOpenFileNames(self, "Select Target Files", "", "All Files (*)")

        if files:
            current_text = self.targets_edit.toPlainText()
            if current_text:
                current_text += "\n"
            current_text += "\n".join(files)
            self.targets_edit.setPlainText(current_text)

    def _create_campaign(self):
        """Create new research campaign."""
        try:
            name = self.campaign_name_edit.text().strip()
            if not name:
                QMessageBox.warning(self, "Warning", "Please enter a campaign name.")
                return

            campaign_type = self.campaign_type_combo.currentText()
            template = self.template_combo.currentText()

            targets_text = self.targets_edit.toPlainText().strip()
            if not targets_text:
                QMessageBox.warning(self, "Warning", "Please specify target files.")
                return

            targets = [t.strip() for t in targets_text.split("\n") if t.strip()]

            # Map UI values to internal values
            type_mapping = {
                "Binary Analysis": "binary_analysis",
                "Fuzzing": "fuzzing",
                "Vulnerability Assessment": "vulnerability_assessment",
                "Patch Analysis": "patch_analysis",
                "Hybrid Research": "hybrid_research",
            }

            template_mapping = {
                "None": None,
                "Basic Fuzzing": "basic_fuzzing",
                "Comprehensive Analysis": "comprehensive_analysis",
                "Patch Research": "patch_research",
            }

            campaign_type_val = type_mapping.get(campaign_type, "binary_analysis")
            template_val = template_mapping.get(template)

            # Add to worker queue
            self.worker.add_operation(
                "create_campaign", name=name, campaign_type=campaign_type_val, targets=targets, template=template_val,
            )

            # Clear form
            self.campaign_name_edit.clear()
            self.targets_edit.clear()

            QMessageBox.information(self, "Success", "Campaign creation initiated.")

        except Exception as e:
            logger.error(f"Campaign creation failed: {e}")
            QMessageBox.critical(self, "Error", f"Failed to create campaign: {e}")

    def _start_selected_campaign(self):
        """Start selected campaign."""
        selected_items = self.campaigns_tree.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "Warning", "Please select a campaign to start.")
            return

        item = selected_items[0]
        campaign_id = item.data(0, Qt.UserRole)

        if campaign_id:
            self.worker.add_operation("start_campaign", campaign_id=campaign_id)
            QMessageBox.information(self, "Success", "Campaign start initiated.")

    # Signal handlers

    def _on_campaign_updated(self, campaign_id: str, data: dict):
        """Handle campaign update."""
        self.active_campaigns[campaign_id] = data
        self._refresh_campaigns()

    def _on_results_ready(self, campaign_id: str, results: dict):
        """Handle results ready."""
        self.campaign_results[campaign_id] = results
        self._refresh_results()

    def _on_error_occurred(self, operation: str, error: str):
        """Handle error."""
        QMessageBox.critical(self, "Error", f"Operation '{operation}' failed: {error}")

    def _refresh_campaigns(self):
        """Refresh campaigns display."""
        self.campaigns_tree.clear()

        if not self.research_manager:
            return

        try:
            campaigns_result = self.research_manager.list_campaigns()
            if campaigns_result["success"]:
                for campaign in campaigns_result["campaigns"]:
                    item = QTreeWidgetItem(
                        [
                            campaign["name"],
                            campaign["type"],
                            campaign["status"],
                            f"{campaign['progress']:.1%}",
                            str(campaign["targets_count"]),
                            datetime.fromtimestamp(campaign["created_at"]).strftime("%Y-%m-%d %H:%M"),
                        ],
                    )
                    item.setData(0, Qt.UserRole, campaign["id"])
                    self.campaigns_tree.addTopLevelItem(item)

        except Exception as e:
            logger.error(f"Failed to refresh campaigns: {e}")

    def _refresh_results(self):
        """Refresh results display."""
        self.results_tree.clear()

        for campaign_id, results in self.campaign_results.items():
            campaign_name = f"Campaign {campaign_id[:8]}"
            item = QTreeWidgetItem(
                [
                    campaign_name,
                    results.get("campaign_type", "Unknown"),
                    "Completed" if results.get("success") else "Failed",
                    f"{len(results.get('detailed_results', {}))} results",
                    datetime.now().strftime("%Y-%m-%d %H:%M"),
                ],
            )
            item.setData(0, Qt.UserRole, campaign_id)
            self.results_tree.addTopLevelItem(item)

    def _update_campaign_status(self):
        """Update campaign status periodically."""
        if self.research_manager:
            try:
                # Update active campaigns
                campaigns_result = self.research_manager.list_campaigns(status_filter="running")
                if campaigns_result["success"]:
                    for campaign in campaigns_result["campaigns"]:
                        if campaign["id"] in self.active_campaigns:
                            self.active_campaigns[campaign["id"]].update(campaign)

                self._refresh_campaigns()

            except Exception as e:
                logger.debug(f"Status update failed: {e}")

    def closeEvent(self, event):
        """Handle dialog close."""
        self.worker.stop()
        self.worker.wait()
        super().closeEvent(event)

    # Placeholder methods for remaining functionality

    def _pause_selected_campaign(self):
        """Pause selected campaign."""
        selected_items = self.campaigns_tree.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "Warning", "Please select a campaign to pause.")
            return

        item = selected_items[0]
        campaign_id = item.data(0, Qt.UserRole)
        campaign_status = item.text(2)

        if campaign_status != "Running":
            QMessageBox.warning(self, "Warning", "Only running campaigns can be paused.")
            return

        if not campaign_id or not self.research_manager:
            QMessageBox.error(self, "Error", "Invalid campaign or research manager not available.")
            return

        try:
            # Update campaign status in research manager
            result = self.research_manager.pause_campaign(campaign_id)

            if result.get("success"):
                # Update UI immediately
                item.setText(2, "Paused")

                # Update internal state
                if campaign_id in self.active_campaigns:
                    self.active_campaigns[campaign_id]["status"] = "paused"

                # Add operation to worker queue for background processing
                self.worker.add_operation("pause_campaign", campaign_id=campaign_id)

                # Log the action
                logger.info(f"Campaign {campaign_id} paused successfully")

                QMessageBox.information(self, "Success", f"Campaign '{item.text(0)}' has been paused.")
            else:
                error_msg = result.get("error", "Unknown error occurred")
                logger.error(f"Failed to pause campaign {campaign_id}: {error_msg}")
                QMessageBox.critical(self, "Error", f"Failed to pause campaign: {error_msg}")

        except Exception as e:
            logger.error(f"Exception while pausing campaign {campaign_id}: {e}")
            QMessageBox.critical(self, "Error", f"Failed to pause campaign: {e!s}")

    def _cancel_selected_campaign(self):
        """Cancel selected campaign."""
        selected_items = self.campaigns_tree.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "Warning", "Please select a campaign to cancel.")
            return

        item = selected_items[0]
        campaign_id = item.data(0, Qt.UserRole)
        campaign_name = item.text(0)
        campaign_status = item.text(2)

        if campaign_status in ["Completed", "Failed", "Cancelled"]:
            QMessageBox.warning(self, "Warning", f"Campaign is already {campaign_status.lower()}.")
            return

        # Confirm cancellation
        reply = QMessageBox.question(
            self,
            "Confirm Cancellation",
            f"Are you sure you want to cancel campaign '{campaign_name}'?\n\n"
            "This will stop all running operations and cannot be undone.",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No,
        )

        if reply != QMessageBox.Yes:
            return

        if not campaign_id or not self.research_manager:
            QMessageBox.error(self, "Error", "Invalid campaign or research manager not available.")
            return

        try:
            # Cancel campaign in research manager
            result = self.research_manager.cancel_campaign(campaign_id)

            if result.get("success"):
                # Update UI
                item.setText(2, "Cancelled")
                item.setText(3, "0%")  # Reset progress

                # Clean up internal state
                if campaign_id in self.active_campaigns:
                    campaign_data = self.active_campaigns[campaign_id]
                    campaign_data["status"] = "cancelled"
                    campaign_data["progress"] = 0.0

                    # Archive partial results if any
                    if "partial_results" in campaign_data:
                        self.campaign_results[campaign_id] = {
                            "campaign_type": campaign_data.get("type", "Unknown"),
                            "status": "cancelled",
                            "partial": True,
                            "results": campaign_data["partial_results"],
                            "cancelled_at": time.time(),
                        }

                # Stop any running operations for this campaign
                self.worker.add_operation("cancel_campaign", campaign_id=campaign_id)

                # Clean up temporary files
                self._cleanup_campaign_files(campaign_id)

                logger.info(f"Campaign {campaign_id} cancelled successfully")
                QMessageBox.information(self, "Success", f"Campaign '{campaign_name}' has been cancelled.")

                # Refresh results if partial results were saved
                if campaign_id in self.campaign_results:
                    self._refresh_results()

            else:
                error_msg = result.get("error", "Unknown error occurred")
                logger.error(f"Failed to cancel campaign {campaign_id}: {error_msg}")
                QMessageBox.critical(self, "Error", f"Failed to cancel campaign: {error_msg}")

        except Exception as e:
            logger.error(f"Exception while cancelling campaign {campaign_id}: {e}")
            QMessageBox.critical(self, "Error", f"Failed to cancel campaign: {e!s}")

    def _cleanup_campaign_files(self, campaign_id: str):
        """Clean up temporary files for cancelled campaign."""
        try:
            import os
            import shutil

            # Clean up output directory
            output_dir = os.path.join(self.storage_dir_edit.text(), campaign_id)
            if os.path.exists(output_dir):
                # Archive important files before deletion
                archive_dir = os.path.join(self.storage_dir_edit.text(), "cancelled", campaign_id)
                os.makedirs(archive_dir, exist_ok=True)

                # Save logs and partial results
                for filename in ["campaign.log", "partial_results.json", "crashes"]:
                    src = os.path.join(output_dir, filename)
                    if os.path.exists(src):
                        dst = os.path.join(archive_dir, filename)
                        if os.path.isdir(src):
                            shutil.copytree(src, dst, dirs_exist_ok=True)
                        else:
                            shutil.copy2(src, dst)

                # Remove original directory
                shutil.rmtree(output_dir)
                logger.info(f"Cleaned up files for campaign {campaign_id}")

        except Exception as e:
            logger.error(f"Failed to cleanup campaign files: {e}")

    def _show_campaign_details(self, item=None, column=None):
        """Show campaign details."""
        if item is None:
            selected_items = self.campaigns_tree.selectedItems()
            if not selected_items:
                QMessageBox.warning(self, "Warning", "Please select a campaign to view details.")
                return
            item = selected_items[0]

        campaign_id = item.data(0, Qt.UserRole)
        if not campaign_id:
            return

        # Get campaign data
        campaign_data = self.active_campaigns.get(campaign_id, {})
        if not campaign_data and self.research_manager:
            # Try to fetch from research manager
            result = self.research_manager.get_campaign_details(campaign_id)
            if result.get("success"):
                campaign_data = result.get("campaign", {})

        if not campaign_data:
            QMessageBox.warning(self, "Warning", "Campaign details not available.")
            return

        # Create details dialog
        details_dialog = QDialog(self)
        details_dialog.setWindowTitle(f"Campaign Details: {campaign_data.get('name', 'Unknown')}")
        details_dialog.setMinimumSize(800, 600)

        layout = QVBoxLayout(details_dialog)

        # Create tabs for different aspects
        tabs = QTabWidget()

        # Overview tab
        overview_widget = self._create_campaign_overview_widget(campaign_data)
        tabs.addTab(overview_widget, "Overview")

        # Configuration tab
        config_widget = self._create_campaign_config_widget(campaign_data)
        tabs.addTab(config_widget, "Configuration")

        # Progress tab
        progress_widget = self._create_campaign_progress_widget(campaign_data)
        tabs.addTab(progress_widget, "Progress")

        # Findings tab
        findings_widget = self._create_campaign_findings_widget(campaign_data)
        tabs.addTab(findings_widget, "Findings")

        # Logs tab
        logs_widget = self._create_campaign_logs_widget(campaign_id)
        tabs.addTab(logs_widget, "Logs")

        layout.addWidget(tabs)

        # Buttons
        button_layout = QHBoxLayout()

        refresh_btn = QPushButton("Refresh")
        refresh_btn.clicked.connect(lambda: self._refresh_campaign_details(campaign_id, tabs))
        button_layout.addWidget(refresh_btn)

        export_btn = QPushButton("Export Details")
        export_btn.clicked.connect(lambda: self._export_campaign_details(campaign_id, campaign_data))
        button_layout.addWidget(export_btn)

        button_layout.addStretch()

        close_btn = QPushButton("Close")
        close_btn.clicked.connect(details_dialog.close)
        button_layout.addWidget(close_btn)

        layout.addLayout(button_layout)

        details_dialog.exec()

    def _create_campaign_overview_widget(self, campaign_data: dict) -> QWidget:
        """Create overview widget for campaign details."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Campaign info
        info_text = QTextEdit()
        info_text.setReadOnly(True)
        info_text.setMaximumHeight(200)

        info_content = f"""
Campaign Name: {campaign_data.get('name', 'Unknown')}
Campaign ID: {campaign_data.get('id', 'Unknown')}
Type: {campaign_data.get('type', 'Unknown')}
Status: {campaign_data.get('status', 'Unknown')}
Progress: {campaign_data.get('progress', 0) * 100:.1f}%

Created: {datetime.fromtimestamp(campaign_data.get('created_at', 0)).strftime('%Y-%m-%d %H:%M:%S')}
Started: {datetime.fromtimestamp(campaign_data.get('started_at', 0)).strftime('%Y-%m-%d %H:%M:%S') if campaign_data.get('started_at') else 'Not started'}
Duration: {self._format_duration(campaign_data.get('duration', 0))}

Targets: {campaign_data.get('targets_count', len(campaign_data.get('targets', [])))}
"""
        info_text.setText(info_content.strip())
        layout.addWidget(info_text)

        # Statistics
        stats_group = QGroupBox("Statistics")
        stats_layout = QGridLayout(stats_group)

        stats = campaign_data.get("statistics", {})
        stats_layout.addWidget(QLabel("Test Cases Executed:"), 0, 0)
        stats_layout.addWidget(QLabel(str(stats.get("test_cases", 0))), 0, 1)

        stats_layout.addWidget(QLabel("Vulnerabilities Found:"), 1, 0)
        stats_layout.addWidget(QLabel(str(stats.get("vulnerabilities", 0))), 1, 1)

        stats_layout.addWidget(QLabel("Crashes Detected:"), 2, 0)
        stats_layout.addWidget(QLabel(str(stats.get("crashes", 0))), 2, 1)

        stats_layout.addWidget(QLabel("Coverage Achieved:"), 3, 0)
        stats_layout.addWidget(QLabel(f"{stats.get('coverage', 0):.1f}%"), 3, 1)

        layout.addWidget(stats_group)

        # Target list
        targets_group = QGroupBox("Targets")
        targets_layout = QVBoxLayout(targets_group)

        targets_list = QListWidget()
        for target in campaign_data.get("targets", []):
            targets_list.addItem(target)
        targets_layout.addWidget(targets_list)

        layout.addWidget(targets_group)

        return widget

    def _create_campaign_config_widget(self, campaign_data: dict) -> QWidget:
        """Create configuration widget for campaign details."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        config_text = QTextEdit()
        config_text.setReadOnly(True)
        config_text.setFont(self._get_monospace_font())

        # Format configuration as JSON
        config = campaign_data.get("configuration", {})
        import json
        config_json = json.dumps(config, indent=2, sort_keys=True)
        config_text.setText(config_json)

        layout.addWidget(QLabel("Campaign Configuration:"))
        layout.addWidget(config_text)

        return widget

    def _create_campaign_progress_widget(self, campaign_data: dict) -> QWidget:
        """Create progress widget for campaign details."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Overall progress
        progress_bar = QProgressBar()
        progress_bar.setRange(0, 100)
        progress_bar.setValue(int(campaign_data.get("progress", 0) * 100))
        layout.addWidget(QLabel("Overall Progress:"))
        layout.addWidget(progress_bar)

        # Phase progress
        phases_group = QGroupBox("Phase Progress")
        phases_layout = QVBoxLayout(phases_group)

        phases = campaign_data.get("phases", {})
        for phase_name, phase_data in phases.items():
            phase_layout = QHBoxLayout()
            phase_layout.addWidget(QLabel(f"{phase_name}:"))

            phase_bar = QProgressBar()
            phase_bar.setRange(0, 100)
            phase_bar.setValue(int(phase_data.get("progress", 0) * 100))
            phase_layout.addWidget(phase_bar)

            phase_layout.addWidget(QLabel(f"{phase_data.get('status', 'Pending')}"))
            phases_layout.addLayout(phase_layout)

        layout.addWidget(phases_group)

        # Timeline
        timeline_group = QGroupBox("Timeline")
        timeline_layout = QVBoxLayout(timeline_group)

        timeline_text = QTextEdit()
        timeline_text.setReadOnly(True)
        timeline_text.setMaximumHeight(200)

        events = campaign_data.get("timeline_events", [])
        timeline_content = ""
        for event in sorted(events, key=lambda x: x.get("timestamp", 0)):
            timestamp = datetime.fromtimestamp(event.get("timestamp", 0)).strftime("%H:%M:%S")
            timeline_content += f"{timestamp} - {event.get('event', 'Unknown event')}\n"

        timeline_text.setText(timeline_content)
        timeline_layout.addWidget(timeline_text)

        layout.addWidget(timeline_group)
        layout.addStretch()

        return widget

    def _create_campaign_findings_widget(self, campaign_data: dict) -> QWidget:
        """Create findings widget for campaign details."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Summary
        summary_group = QGroupBox("Findings Summary")
        summary_layout = QGridLayout(summary_group)

        findings = campaign_data.get("findings", {})

        summary_layout.addWidget(QLabel("Critical:"), 0, 0)
        summary_layout.addWidget(QLabel(str(findings.get("critical", 0))), 0, 1)

        summary_layout.addWidget(QLabel("High:"), 1, 0)
        summary_layout.addWidget(QLabel(str(findings.get("high", 0))), 1, 1)

        summary_layout.addWidget(QLabel("Medium:"), 2, 0)
        summary_layout.addWidget(QLabel(str(findings.get("medium", 0))), 2, 1)

        summary_layout.addWidget(QLabel("Low:"), 3, 0)
        summary_layout.addWidget(QLabel(str(findings.get("low", 0))), 3, 1)

        layout.addWidget(summary_group)

        # Detailed findings table
        findings_table = QTableWidget()
        findings_table.setColumnCount(5)
        findings_table.setHorizontalHeaderLabels(["Type", "Severity", "Location", "Confidence", "Description"])

        vulnerabilities = campaign_data.get("vulnerabilities", [])
        findings_table.setRowCount(len(vulnerabilities))

        for row, vuln in enumerate(vulnerabilities):
            findings_table.setItem(row, 0, QTableWidgetItem(vuln.get("type", "Unknown")))
            findings_table.setItem(row, 1, QTableWidgetItem(vuln.get("severity", "Unknown")))
            findings_table.setItem(row, 2, QTableWidgetItem(vuln.get("location", "Unknown")))
            findings_table.setItem(row, 3, QTableWidgetItem(f"{vuln.get('confidence', 0):.1f}%"))
            findings_table.setItem(row, 4, QTableWidgetItem(vuln.get("description", "")))

        findings_table.resizeColumnsToContents()
        layout.addWidget(findings_table)

        return widget

    def _create_campaign_logs_widget(self, campaign_id: str) -> QWidget:
        """Create logs widget for campaign details."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Log viewer
        log_text = QTextEdit()
        log_text.setReadOnly(True)
        log_text.setFont(self._get_monospace_font())

        # Load logs
        log_content = self._load_campaign_logs(campaign_id)
        log_text.setText(log_content)

        # Controls
        controls_layout = QHBoxLayout()

        refresh_btn = QPushButton("Refresh Logs")
        refresh_btn.clicked.connect(lambda: log_text.setText(self._load_campaign_logs(campaign_id)))
        controls_layout.addWidget(refresh_btn)

        clear_btn = QPushButton("Clear Display")
        clear_btn.clicked.connect(log_text.clear)
        controls_layout.addWidget(clear_btn)

        controls_layout.addStretch()

        # Log level filter
        controls_layout.addWidget(QLabel("Filter:"))
        level_combo = QComboBox()
        level_combo.addItems(["All", "ERROR", "WARNING", "INFO", "DEBUG"])
        level_combo.currentTextChanged.connect(
            lambda level: self._filter_campaign_logs(campaign_id, level, log_text),
        )
        controls_layout.addWidget(level_combo)

        layout.addLayout(controls_layout)
        layout.addWidget(log_text)

        return widget

    def _load_campaign_logs(self, campaign_id: str) -> str:
        """Load campaign logs from file."""
        try:
            import os

            log_file = os.path.join(self.storage_dir_edit.text(), campaign_id, "campaign.log")
            if os.path.exists(log_file):
                with open(log_file, encoding="utf-8") as f:
                    return f.read()
            else:
                return "No logs available for this campaign."
        except Exception as e:
            return f"Failed to load logs: {e!s}"

    def _filter_campaign_logs(self, campaign_id: str, level: str, log_widget: QTextEdit):
        """Filter campaign logs by level."""
        full_logs = self._load_campaign_logs(campaign_id)
        if level == "All":
            log_widget.setText(full_logs)
        else:
            filtered_lines = []
            for line in full_logs.split("\n"):
                if level in line:
                    filtered_lines.append(line)
            log_widget.setText("\n".join(filtered_lines))

    def _format_duration(self, seconds: float) -> str:
        """Format duration in human-readable format."""
        if seconds < 60:
            return f"{seconds:.0f} seconds"
        if seconds < 3600:
            return f"{seconds/60:.1f} minutes"
        return f"{seconds/3600:.1f} hours"

    def _refresh_campaign_details(self, campaign_id: str, tabs: QTabWidget):
        """Refresh campaign details in dialog."""
        if self.research_manager:
            result = self.research_manager.get_campaign_details(campaign_id)
            if result.get("success"):
                campaign_data = result.get("campaign", {})

                # Update Overview Tab (index 0)
                overview_widget = tabs.widget(0)
                if overview_widget:
                    # Find and update overview labels
                    for child in overview_widget.findChildren(QLabel):
                        object_name = child.objectName()
                        if object_name == "name_label":
                            child.setText(f"Name: {campaign_data.get('name', 'Unknown')}")
                        elif object_name == "type_label":
                            child.setText(f"Type: {campaign_data.get('type', 'Unknown')}")
                        elif object_name == "status_label":
                            child.setText(f"Status: {campaign_data.get('status', 'Unknown')}")
                        elif object_name == "progress_label":
                            child.setText(f"Progress: {campaign_data.get('progress', 0):.1%}")
                        elif object_name == "created_label":
                            created = campaign_data.get("created_at", 0)
                            child.setText(f"Created: {datetime.fromtimestamp(created).strftime('%Y-%m-%d %H:%M:%S')}")
                        elif object_name == "duration_label":
                            duration = campaign_data.get("duration", 0)
                            child.setText(f"Duration: {self._format_duration(duration)}")

                # Update Targets Tab (index 1)
                targets_widget = tabs.widget(1)
                if targets_widget:
                    targets_list = targets_widget.findChild(QListWidget)
                    if targets_list:
                        targets_list.clear()
                        for target in campaign_data.get("targets", []):
                            targets_list.addItem(target)

                # Update Results Tab (index 2)
                results_widget = tabs.widget(2)
                if results_widget:
                    results_table = results_widget.findChild(QTableWidget)
                    if results_table:
                        results_table.setRowCount(0)
                        results = campaign_data.get("results", {})
                        vulns = results.get("vulnerabilities", [])

                        for vuln in vulns:
                            row = results_table.rowCount()
                            results_table.insertRow(row)
                            results_table.setItem(row, 0, QTableWidgetItem(vuln.get("type", "")))
                            results_table.setItem(row, 1, QTableWidgetItem(vuln.get("severity", "")))
                            results_table.setItem(row, 2, QTableWidgetItem(vuln.get("location", "")))
                            results_table.setItem(row, 3, QTableWidgetItem(vuln.get("description", "")))

                # Update Configuration Tab (index 3)
                config_widget = tabs.widget(3)
                if config_widget:
                    config_text = config_widget.findChild(QTextEdit)
                    if config_text:
                        config = campaign_data.get("configuration", {})
                        config_text.setText(json.dumps(config, indent=2))

                QMessageBox.information(tabs.parent(), "Success", "Campaign details refreshed.")

    def _export_campaign_details(self, campaign_id: str, campaign_data: dict):
        """Export campaign details to file."""
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Export Campaign Details",
            f"campaign_{campaign_id[:8]}_details.json",
            "JSON Files (*.json);;All Files (*)",
        )

        if file_path:
            try:
                import json
                with open(file_path, "w") as f:
                    json.dump(campaign_data, f, indent=2, default=str)
                QMessageBox.information(self, "Success", f"Campaign details exported to {file_path}")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Failed to export details: {e!s}")

    def _show_result_details(self):
        """Show result details."""
        selected_items = self.results_tree.selectedItems()
        if not selected_items:
            # Check if summary or other tabs have data to show
            if hasattr(self, "_last_selected_result"):
                self._display_result_in_tabs(self._last_selected_result)
            return

        item = selected_items[0]
        campaign_id = item.data(0, Qt.UserRole)

        if not campaign_id or campaign_id not in self.campaign_results:
            QMessageBox.warning(self, "Warning", "Result details not available.")
            return

        result_data = self.campaign_results[campaign_id]
        self._last_selected_result = result_data

        # Display in tabs
        self._display_result_in_tabs(result_data)

    def _display_result_in_tabs(self, result_data: dict):
        """Display result data in the various tabs."""
        # Update summary tab
        self._update_summary_tab(result_data)

        # Update vulnerabilities tab
        self._update_vulnerabilities_tab(result_data)

        # Update correlation tab
        self._update_correlation_tab(result_data)

        # Update raw data tab
        self._update_raw_data_tab(result_data)

    def _update_summary_tab(self, result_data: dict):
        """Update summary tab with result overview."""
        summary_text = f"""
Campaign Type: {result_data.get('campaign_type', 'Unknown')}
Status: {result_data.get('status', 'Unknown')}
Completed: {datetime.fromtimestamp(result_data.get('completed_at', time.time())).strftime('%Y-%m-%d %H:%M:%S')}

=== Summary ===
Total Vulnerabilities: {len(result_data.get('vulnerabilities', []))}
Total Crashes: {result_data.get('crash_count', 0)}
Unique Crashes: {len(result_data.get('unique_crashes', []))}
Coverage Achieved: {result_data.get('coverage', {}).get('percentage', 0):.1f}%

=== Severity Breakdown ===
Critical: {self._count_by_severity(result_data.get('vulnerabilities', []), 'critical')}
High: {self._count_by_severity(result_data.get('vulnerabilities', []), 'high')}
Medium: {self._count_by_severity(result_data.get('vulnerabilities', []), 'medium')}
Low: {self._count_by_severity(result_data.get('vulnerabilities', []), 'low')}

=== Exploit Potential ===
Exploitable Crashes: {result_data.get('exploitable_crashes', 0)}
Remote Code Execution: {self._count_by_type(result_data.get('vulnerabilities', []), 'RCE')}
Memory Corruption: {self._count_by_type(result_data.get('vulnerabilities', []), 'memory_corruption')}
Information Disclosure: {self._count_by_type(result_data.get('vulnerabilities', []), 'info_disclosure')}

=== Performance Metrics ===
Test Cases Executed: {result_data.get('test_cases', 0)}
Execution Time: {self._format_duration(result_data.get('duration', 0))}
Executions/Second: {result_data.get('exec_per_sec', 0):.1f}
        """

        self.summary_edit.setText(summary_text.strip())

    def _update_vulnerabilities_tab(self, result_data: dict):
        """Update vulnerabilities table with detailed findings."""
        vulnerabilities = result_data.get("vulnerabilities", [])
        self.vulnerabilities_table.setRowCount(len(vulnerabilities))

        for row, vuln in enumerate(vulnerabilities):
            # Type
            type_item = QTableWidgetItem(vuln.get("type", "Unknown"))
            self.vulnerabilities_table.setItem(row, 0, type_item)

            # Severity with color coding
            severity = vuln.get("severity", "Unknown")
            severity_item = QTableWidgetItem(severity)
            if severity == "critical":
                severity_item.setBackground(Qt.GlobalColor.red)
                severity_item.setForeground(Qt.GlobalColor.white)
            elif severity == "high":
                severity_item.setBackground(Qt.GlobalColor.darkRed)
                severity_item.setForeground(Qt.GlobalColor.white)
            elif severity == "medium":
                severity_item.setBackground(Qt.GlobalColor.darkYellow)
            elif severity == "low":
                severity_item.setBackground(Qt.GlobalColor.yellow)
            self.vulnerabilities_table.setItem(row, 1, severity_item)

            # Location
            location = vuln.get("location", vuln.get("position", "Unknown"))
            if isinstance(location, (list, tuple)):
                location = ", ".join(str(loc) for loc in location[:3])
            self.vulnerabilities_table.setItem(row, 2, QTableWidgetItem(str(location)))

            # Exploitable
            exploitable = vuln.get("exploitable", vuln.get("exploit_potential", "Unknown"))
            exploit_item = QTableWidgetItem(str(exploitable))
            if exploitable in ["high", "critical", "yes", True]:
                exploit_item.setBackground(Qt.GlobalColor.darkGreen)
                exploit_item.setForeground(Qt.GlobalColor.white)
            self.vulnerabilities_table.setItem(row, 3, exploit_item)

            # Description
            desc = vuln.get("description", "")
            if len(desc) > 100:
                desc = desc[:97] + "..."
            self.vulnerabilities_table.setItem(row, 4, QTableWidgetItem(desc))

        self.vulnerabilities_table.resizeColumnsToContents()

    def _update_correlation_tab(self, result_data: dict):
        """Update correlation tab with cross-reference analysis."""
        correlation_text = "=== Vulnerability Correlation Analysis ===\n\n"

        # Group vulnerabilities by type
        vuln_groups = {}
        for vuln in result_data.get("vulnerabilities", []):
            vuln_type = vuln.get("type", "Unknown")
            if vuln_type not in vuln_groups:
                vuln_groups[vuln_type] = []
            vuln_groups[vuln_type].append(vuln)

        # Analyze patterns
        for vuln_type, vulns in vuln_groups.items():
            correlation_text += f"Type: {vuln_type}\n"
            correlation_text += f"Count: {len(vulns)}\n"

            # Find common patterns
            if len(vulns) > 1:
                # Check for common functions
                functions = [v.get("function", "") for v in vulns if v.get("function")]
                if functions:
                    from collections import Counter
                    common_funcs = Counter(functions).most_common(3)
                    correlation_text += "Common Functions: " + ", ".join(f[0] for f in common_funcs) + "\n"

                # Check for proximity
                positions = [v.get("position", 0) for v in vulns if isinstance(v.get("position"), (int, float))]
                if len(positions) > 1:
                    positions.sort()
                    avg_distance = sum(positions[i+1] - positions[i] for i in range(len(positions)-1)) / (len(positions)-1)
                    correlation_text += f"Average Distance: {avg_distance:.0f} bytes\n"

            correlation_text += "\n"

        # Crash correlation
        if result_data.get("crashes"):
            correlation_text += "=== Crash Correlation ===\n"
            crashes = result_data.get("crashes", [])

            # Group by crash type
            crash_types = {}
            for crash in crashes:
                crash_type = crash.get("crash_type", "Unknown")
                if crash_type not in crash_types:
                    crash_types[crash_type] = 0
                crash_types[crash_type] += 1

            for crash_type, count in crash_types.items():
                correlation_text += f"{crash_type}: {count} crashes\n"

            # Exploitability correlation
            exploitable = [c for c in crashes if c.get("exploitability") in ["high", "critical"]]
            if exploitable:
                correlation_text += f"\nHighly Exploitable Crashes: {len(exploitable)}\n"
                for crash in exploitable[:5]:  # Show top 5
                    correlation_text += f"  - Hash: {crash.get('hash', 'Unknown')[:8]}, Type: {crash.get('crash_type')}\n"

        self.correlation_edit.setText(correlation_text)

    def _update_raw_data_tab(self, result_data: dict):
        """Update raw data tab with JSON representation."""
        import json

        # Create a copy to avoid modifying original
        display_data = result_data.copy()

        # Truncate large lists for display
        if "vulnerabilities" in display_data and len(display_data["vulnerabilities"]) > 10:
            display_data["vulnerabilities"] = display_data["vulnerabilities"][:10]
            display_data["vulnerabilities_truncated"] = True
            display_data["total_vulnerabilities"] = len(result_data["vulnerabilities"])

        if "crashes" in display_data and len(display_data["crashes"]) > 10:
            display_data["crashes"] = display_data["crashes"][:10]
            display_data["crashes_truncated"] = True
            display_data["total_crashes"] = len(result_data["crashes"])

        # Pretty print JSON
        raw_json = json.dumps(display_data, indent=2, sort_keys=True, default=str)
        self.raw_data_edit.setText(raw_json)

    def _count_by_severity(self, vulnerabilities: list[dict], severity: str) -> int:
        """Count vulnerabilities by severity level."""
        return sum(1 for v in vulnerabilities if v.get("severity", "").lower() == severity.lower())

    def _count_by_type(self, vulnerabilities: list[dict], vuln_type: str) -> int:
        """Count vulnerabilities by type."""
        return sum(1 for v in vulnerabilities if vuln_type.lower() in v.get("type", "").lower())

    def _generate_report(self):
        """Generate analysis report."""
        selected_items = self.results_tree.selectedItems()
        if not selected_items:
            QMessageBox.warning(self, "Warning", "Please select results to generate report.")
            return

        # Get report options
        options_dialog = ReportOptionsDialog(self)
        if options_dialog.exec() != QDialog.Accepted:
            return

        report_format = options_dialog.format_combo.currentText()
        include_raw_data = options_dialog.raw_data_check.isChecked()
        include_recommendations = options_dialog.recommendations_check.isChecked()

        # Collect results for report
        results_to_report = []
        for item in selected_items:
            campaign_id = item.data(0, Qt.UserRole)
            if campaign_id in self.campaign_results:
                results_to_report.append({
                    "campaign_id": campaign_id,
                    "campaign_name": item.text(0),
                    "results": self.campaign_results[campaign_id],
                })

        if not results_to_report:
            QMessageBox.warning(self, "Warning", "No valid results to report.")
            return

        # Generate report
        try:
            if report_format == "PDF":
                report_path = self._generate_pdf_report(results_to_report, include_raw_data, include_recommendations)
            elif report_format == "JSON":
                report_path = self._generate_json_report(results_to_report, include_raw_data)
            elif report_format == "HTML":
                report_path = self._generate_html_report(results_to_report, include_raw_data, include_recommendations)
            else:
                QMessageBox.warning(self, "Warning", f"Unsupported report format: {report_format}")
                return

            if report_path:
                reply = QMessageBox.question(
                    self,
                    "Report Generated",
                    f"Report saved to:\n{report_path}\n\nDo you want to open it?",
                    QMessageBox.Yes | QMessageBox.No,
                )

                if reply == QMessageBox.Yes:
                    import os
                    os.startfile(report_path) if os.name == "nt" else os.system(f'open "{report_path}"')

        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            QMessageBox.critical(self, "Error", f"Failed to generate report: {e!s}")

    def _generate_pdf_report(self, results: list[dict], include_raw_data: bool, include_recommendations: bool) -> str:
        """Generate PDF report with vulnerability findings."""
        from PyQt6.QtGui import QTextCursor, QTextDocument
        from PyQt6.QtPrintSupport import QPrinter

        # Get output path
        default_name = f"vulnerability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save PDF Report", default_name, "PDF Files (*.pdf)",
        )

        if not file_path:
            return None

        # Create PDF document
        document = QTextDocument()
        cursor = QTextCursor(document)

        # Title page
        cursor.insertHtml(f"""
        <h1 style='text-align: center; color: #2c3e50;'>Vulnerability Research Report</h1>
        <h3 style='text-align: center; color: #7f8c8d;'>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</h3>
        <hr>
        """)

        # Executive summary
        cursor.insertHtml("<h2>Executive Summary</h2>")

        total_vulns = sum(len(r["results"].get("vulnerabilities", [])) for r in results)
        total_critical = sum(
            self._count_by_severity(r["results"].get("vulnerabilities", []), "critical")
            for r in results
        )
        total_high = sum(
            self._count_by_severity(r["results"].get("vulnerabilities", []), "high")
            for r in results
        )

        cursor.insertHtml(f"""
        <p>This report contains the analysis results from {len(results)} campaign(s).</p>
        <ul>
            <li>Total Vulnerabilities Found: <b>{total_vulns}</b></li>
            <li>Critical Severity: <b style='color: red;'>{total_critical}</b></li>
            <li>High Severity: <b style='color: darkred;'>{total_high}</b></li>
        </ul>
        """)

        # Campaign results
        for result_data in results:
            cursor.insertHtml(f"<h2>Campaign: {result_data['campaign_name']}</h2>")
            campaign_results = result_data["results"]

            # Summary statistics
            cursor.insertHtml("<h3>Summary</h3>")
            cursor.insertHtml(f"""
            <table border='1' cellpadding='5' style='border-collapse: collapse;'>
                <tr><td><b>Campaign Type</b></td><td>{campaign_results.get('campaign_type', 'Unknown')}</td></tr>
                <tr><td><b>Status</b></td><td>{campaign_results.get('status', 'Unknown')}</td></tr>
                <tr><td><b>Duration</b></td><td>{self._format_duration(campaign_results.get('duration', 0))}</td></tr>
                <tr><td><b>Test Cases</b></td><td>{campaign_results.get('test_cases', 0)}</td></tr>
                <tr><td><b>Coverage</b></td><td>{campaign_results.get('coverage', {}).get('percentage', 0):.1f}%</td></tr>
            </table>
            """)

            # Vulnerabilities
            vulnerabilities = campaign_results.get("vulnerabilities", [])
            if vulnerabilities:
                cursor.insertHtml("<h3>Vulnerabilities Found</h3>")
                cursor.insertHtml("""
                <table border='1' cellpadding='5' style='border-collapse: collapse; width: 100%;'>
                    <tr style='background-color: #ecf0f1;'>
                        <th>Type</th>
                        <th>Severity</th>
                        <th>Location</th>
                        <th>Exploitable</th>
                        <th>Description</th>
                    </tr>
                """)

                for vuln in vulnerabilities[:20]:  # Limit to 20 per campaign
                    severity_color = {
                        "critical": "red",
                        "high": "darkred",
                        "medium": "orange",
                        "low": "yellow",
                    }.get(vuln.get("severity", "").lower(), "black")

                    cursor.insertHtml(f"""
                    <tr>
                        <td>{vuln.get('type', 'Unknown')}</td>
                        <td style='color: {severity_color};'><b>{vuln.get('severity', 'Unknown')}</b></td>
                        <td>{str(vuln.get('location', 'Unknown'))[:50]}</td>
                        <td>{vuln.get('exploitable', 'Unknown')}</td>
                        <td>{vuln.get('description', '')[:100]}</td>
                    </tr>
                    """)

                cursor.insertHtml("</table>")

                if len(vulnerabilities) > 20:
                    cursor.insertHtml(f"<p><i>... and {len(vulnerabilities) - 20} more vulnerabilities</i></p>")

            # Page break between campaigns
            cursor.insertHtml("<div style='page-break-after: always;'></div>")

        # Recommendations
        if include_recommendations:
            cursor.insertHtml("<h2>Recommendations</h2>")
            recommendations = self._generate_recommendations_from_results(results)
            cursor.insertHtml("<ul>")
            for rec in recommendations:
                cursor.insertHtml(f"<li>{rec}</li>")
            cursor.insertHtml("</ul>")

        # Raw data appendix
        if include_raw_data:
            cursor.insertHtml("<h2>Appendix: Raw Data</h2>")
            cursor.insertHtml("<p><i>See attached JSON file for complete raw data.</i></p>")

            # Also save JSON file
            json_path = file_path.replace(".pdf", "_raw_data.json")
            import json
            with open(json_path, "w") as f:
                json.dump([r["results"] for r in results], f, indent=2, default=str)

        # Save PDF
        printer = QPrinter(QPrinter.PrinterMode.HighResolution)
        printer.setOutputFormat(QPrinter.OutputFormat.PdfFormat)
        printer.setOutputFileName(file_path)
        printer.setPageSize(QPrinter.PageSize.A4)

        document.print(printer)

        logger.info(f"PDF report generated: {file_path}")
        return file_path

    def _generate_json_report(self, results: list[dict], include_raw_data: bool) -> str:
        """Generate JSON report."""
        import json

        default_name = f"vulnerability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save JSON Report", default_name, "JSON Files (*.json)",
        )

        if not file_path:
            return None

        report_data = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "generator": "Intellicrack Vulnerability Research",
                "version": "1.0",
                "campaign_count": len(results),
            },
            "summary": {
                "total_vulnerabilities": sum(len(r["results"].get("vulnerabilities", [])) for r in results),
                "total_crashes": sum(r["results"].get("crash_count", 0) for r in results),
                "severity_breakdown": {
                    "critical": sum(self._count_by_severity(r["results"].get("vulnerabilities", []), "critical") for r in results),
                    "high": sum(self._count_by_severity(r["results"].get("vulnerabilities", []), "high") for r in results),
                    "medium": sum(self._count_by_severity(r["results"].get("vulnerabilities", []), "medium") for r in results),
                    "low": sum(self._count_by_severity(r["results"].get("vulnerabilities", []), "low") for r in results),
                },
            },
            "campaigns": [],
        }

        for result_data in results:
            campaign_report = {
                "campaign_id": result_data["campaign_id"],
                "campaign_name": result_data["campaign_name"],
                "summary": {
                    "type": result_data["results"].get("campaign_type"),
                    "status": result_data["results"].get("status"),
                    "duration": result_data["results"].get("duration"),
                    "vulnerabilities_count": len(result_data["results"].get("vulnerabilities", [])),
                },
            }

            if include_raw_data:
                campaign_report["raw_results"] = result_data["results"]
            else:
                # Include only essential data
                campaign_report["vulnerabilities"] = result_data["results"].get("vulnerabilities", [])[:50]
                campaign_report["statistics"] = result_data["results"].get("statistics", {})

            report_data["campaigns"].append(campaign_report)

        with open(file_path, "w") as f:
            json.dump(report_data, f, indent=2, default=str)

        logger.info(f"JSON report generated: {file_path}")
        return file_path

    def _generate_html_report(self, results: list[dict], include_raw_data: bool, include_recommendations: bool) -> str:
        """Generate HTML report."""
        default_name = f"vulnerability_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Save HTML Report", default_name, "HTML Files (*.html)",
        )

        if not file_path:
            return None

        html_content = self._create_html_report_content(results, include_raw_data, include_recommendations)

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(html_content)

        logger.info(f"HTML report generated: {file_path}")
        return file_path

    def _create_html_report_content(self, results: list[dict], include_raw_data: bool, include_recommendations: bool) -> str:
        """Create HTML content for report."""
        # Calculate statistics
        total_vulns = sum(len(r["results"].get("vulnerabilities", [])) for r in results)
        severity_counts = {"CRITICAL": 0, "HIGH": 0, "MEDIUM": 0, "LOW": 0}
        vuln_types = {}

        for result in results:
            for vuln in result["results"].get("vulnerabilities", []):
                severity = vuln.get("severity", "LOW")
                severity_counts[severity] = severity_counts.get(severity, 0) + 1

                vuln_type = vuln.get("type", "Unknown")
                vuln_types[vuln_type] = vuln_types.get(vuln_type, 0) + 1

        html = f"""<!DOCTYPE html>
<html>
<head>
    <title>Vulnerability Research Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background-color: #f8f9fa; }}
        .container {{ max-width: 1200px; margin: 0 auto; background-color: white; padding: 20px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
        h1, h2, h3 {{ color: #2c3e50; }}
        h1 {{ border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        h2 {{ border-bottom: 1px solid #ecf0f1; padding-bottom: 5px; margin-top: 30px; }}
        table {{ border-collapse: collapse; width: 100%; margin: 10px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #ecf0f1; font-weight: bold; }}
        tr:nth-child(even) {{ background-color: #f9f9f9; }}
        .critical {{ color: #e74c3c; font-weight: bold; }}
        .high {{ color: #c0392b; font-weight: bold; }}
        .medium {{ color: #e67e22; }}
        .low {{ color: #f39c12; }}
        .info {{ color: #3498db; }}
        .summary-box {{ background-color: #ecf0f1; padding: 15px; border-radius: 5px; margin: 10px 0; }}
        .stat-card {{ display: inline-block; margin: 10px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; min-width: 150px; text-align: center; }}
        .stat-number {{ font-size: 24px; font-weight: bold; color: #2c3e50; }}
        .stat-label {{ color: #7f8c8d; font-size: 12px; }}
        .recommendation {{ background-color: #fff3cd; border: 1px solid #ffeaa7; padding: 10px; border-radius: 5px; margin: 10px 0; }}
        .code-block {{ background-color: #f4f4f4; padding: 10px; border-left: 3px solid #3498db; font-family: monospace; overflow-x: auto; }}
        .vulnerability-chart {{ margin: 20px 0; }}
        @media print {{
            .container {{ box-shadow: none; }}
            body {{ background-color: white; }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>Vulnerability Research Report</h1>
        <div class="summary-box">
            <p><strong>Report Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p><strong>Total Campaigns Analyzed:</strong> {len(results)}</p>
            <p><strong>Total Vulnerabilities Found:</strong> {total_vulns}</p>
        </div>

        <h2>Executive Summary</h2>
        <div style="display: flex; flex-wrap: wrap;">
            <div class="stat-card">
                <div class="stat-number critical">{severity_counts.get('CRITICAL', 0)}</div>
                <div class="stat-label">Critical</div>
            </div>
            <div class="stat-card">
                <div class="stat-number high">{severity_counts.get('HIGH', 0)}</div>
                <div class="stat-label">High</div>
            </div>
            <div class="stat-card">
                <div class="stat-number medium">{severity_counts.get('MEDIUM', 0)}</div>
                <div class="stat-label">Medium</div>
            </div>
            <div class="stat-card">
                <div class="stat-number low">{severity_counts.get('LOW', 0)}</div>
                <div class="stat-label">Low</div>
            </div>
        </div>

        <h2>Vulnerability Type Distribution</h2>
        <table>
            <tr>
                <th>Vulnerability Type</th>
                <th>Count</th>
                <th>Percentage</th>
            </tr>
            {''.join(f"<tr><td>{vtype}</td><td>{count}</td><td>{(count/total_vulns*100):.1f}%</td></tr>" for vtype, count in sorted(vuln_types.items(), key=lambda x: x[1], reverse=True)[:10])}
        </table>

        <h2>Campaign Details</h2>
        {''.join(self._create_campaign_html(r) for r in results)}

        {self._create_recommendations_html(results) if include_recommendations else ''}

        {self._create_raw_data_html(results) if include_raw_data else ''}

        <div style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #ddd; text-align: center; color: #7f8c8d;">
            <p>Generated by Intellicrack Vulnerability Research System</p>
            <p> 2025 Zachary Flint - All Rights Reserved</p>
        </div>
    </div>
</body>
</html>"""
        return html

    def _create_campaign_html(self, result_data: dict) -> str:
        """Create HTML for single campaign results."""
        campaign = result_data["results"]
        vulns = campaign.get("vulnerabilities", [])

        return f"""
        <h2>Campaign: {result_data['campaign_name']}</h2>
        <table>
            <tr><th>Type</th><td>{campaign.get('campaign_type', 'Unknown')}</td></tr>
            <tr><th>Vulnerabilities</th><td>{len(vulns)}</td></tr>
            <tr><th>Coverage</th><td>{campaign.get('coverage', {}).get('percentage', 0):.1f}%</td></tr>
        </table>

        <h3>Vulnerabilities</h3>
        <table>
            <tr>
                <th>Type</th>
                <th>Severity</th>
                <th>Location</th>
                <th>Description</th>
            </tr>
            {''.join(self._create_vuln_row_html(v) for v in vulns[:20])}
        </table>
        """

    def _create_vuln_row_html(self, vuln: dict) -> str:
        """Create HTML row for vulnerability."""
        severity = vuln.get("severity", "").lower()
        return f"""
        <tr>
            <td>{vuln.get('type', 'Unknown')}</td>
            <td class="{severity}">{vuln.get('severity', 'Unknown')}</td>
            <td>{str(vuln.get('location', 'Unknown'))[:50]}</td>
            <td>{vuln.get('description', '')[:100]}</td>
        </tr>
        """

    def _create_recommendations_html(self, results: list[dict]) -> str:
        """Create recommendations HTML section."""
        recommendations = self._generate_recommendations_from_results(results)
        return f"""
        <h2>Recommendations</h2>
        <ul>
            {''.join(f'<li>{rec}</li>' for rec in recommendations)}
        </ul>
        """

    def _generate_recommendations_from_results(self, results: list[dict]) -> list[str]:
        """Generate recommendations based on analysis results."""
        recommendations = []

        # Analyze all vulnerabilities
        all_vulns = []
        for r in results:
            all_vulns.extend(r["results"].get("vulnerabilities", []))

        # Critical vulnerabilities
        critical_count = self._count_by_severity(all_vulns, "critical")
        if critical_count > 0:
            recommendations.append(
                f"URGENT: Address {critical_count} critical vulnerabilities immediately. "
                "These pose immediate risk to system security.",
            )

        # Memory safety issues
        memory_issues = [v for v in all_vulns if any(
            term in v.get("type", "").lower()
            for term in ["buffer", "overflow", "memory", "heap", "stack", "use-after-free"]
        )]
        if memory_issues:
            recommendations.append(
                f"Implement memory safety measures to address {len(memory_issues)} memory-related vulnerabilities. "
                "Consider using safer memory management practices and bounds checking.",
            )

        # Input validation
        input_issues = [v for v in all_vulns if any(
            term in v.get("type", "").lower()
            for term in ["injection", "format", "validation", "sanitization"]
        )]
        if input_issues:
            recommendations.append(
                f"Strengthen input validation to prevent {len(input_issues)} input-related vulnerabilities. "
                "Implement strict input sanitization and validation routines.",
            )

        # Cryptographic issues
        crypto_issues = [v for v in all_vulns if any(
            term in v.get("type", "").lower()
            for term in ["crypto", "encryption", "hash", "random", "key"]
        )]
        if crypto_issues:
            recommendations.append(
                "Update cryptographic implementations to use modern, secure algorithms. "
                "Replace weak cryptographic functions with industry-standard alternatives.",
            )

        # General recommendations
        if len(all_vulns) > 20:
            recommendations.append(
                "Implement a comprehensive security review process. "
                "The high number of vulnerabilities suggests systemic security issues.",
            )

        # Coverage recommendations
        low_coverage = any(
            r["results"].get("coverage", {}).get("percentage", 0) < 50
            for r in results
        )
        if low_coverage:
            recommendations.append(
                "Increase test coverage to improve vulnerability detection. "
                "Current coverage levels may be missing significant security issues.",
            )

        return recommendations

    def _create_raw_data_html(self, results: list[dict]) -> str:
        """Create raw data section for HTML report."""
        html = """
        <h2>Raw Data</h2>
        <div style="background-color: #f8f9fa; padding: 15px; border-radius: 5px;">
            <p><strong>Note:</strong> This section contains detailed technical data for further analysis.</p>
        </div>
        """

        for i, result in enumerate(results):
            campaign_id = result.get("campaign_id", f"Campaign_{i+1}")
            campaign_data = result.get("results", {})

            html += f"""
            <h3>Campaign: {result.get('campaign_name', campaign_id)}</h3>
            <div class="code-block">
                <h4>Configuration:</h4>
                <pre>{json.dumps(campaign_data.get('configuration', {}), indent=2)}</pre>

                <h4>Coverage Data:</h4>
                <pre>{json.dumps(campaign_data.get('coverage', {}), indent=2)}</pre>

                <h4>Crash Analysis:</h4>
                <pre>{json.dumps(campaign_data.get('crashes', [])[:5], indent=2)}</pre>

                <h4>Full Vulnerability Details:</h4>
                <pre>{json.dumps(campaign_data.get('vulnerabilities', [])[:10], indent=2)}</pre>
            </div>
            """

        return html


class ReportOptionsDialog(QDialog):
    """Dialog for report generation options."""

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Report Options")
        self.setModal(True)

        layout = QVBoxLayout(self)

        # Format selection
        format_layout = QHBoxLayout()
        format_layout.addWidget(QLabel("Report Format:"))
        self.format_combo = QComboBox()
        self.format_combo.addItems(["PDF", "JSON", "HTML"])
        format_layout.addWidget(self.format_combo)
        layout.addLayout(format_layout)

        # Options
        self.raw_data_check = QCheckBox("Include Raw Data")
        self.raw_data_check.setChecked(False)
        layout.addWidget(self.raw_data_check)

        self.recommendations_check = QCheckBox("Include Recommendations")
        self.recommendations_check.setChecked(True)
        layout.addWidget(self.recommendations_check)

        # Buttons
        button_layout = QHBoxLayout()

        ok_btn = QPushButton("Generate")
        ok_btn.clicked.connect(self.accept)
        button_layout.addWidget(ok_btn)

        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        button_layout.addWidget(cancel_btn)

        layout.addLayout(button_layout)

    def _correlate_results(self):
        """Correlate results across multiple campaigns."""
        # Check if auto-correlation is enabled
        if self.auto_correlation_check.isChecked() and len(self.campaign_results) > 1:
            # Automatically correlate all results
            self._perform_correlation_analysis(list(self.campaign_results.values()))
            return

        # Manual correlation - let user select campaigns
        if len(self.campaign_results) < 2:
            QMessageBox.warning(
                self,
                "Warning",
                "At least 2 campaign results are needed for correlation analysis.",
            )
            return

        # Create selection dialog
        selection_dialog = CampaignSelectionDialog(self.campaign_results, self)
        if selection_dialog.exec() != QDialog.Accepted:
            return

        selected_campaigns = selection_dialog.get_selected_campaigns()
        if len(selected_campaigns) < 2:
            QMessageBox.warning(self, "Warning", "Please select at least 2 campaigns for correlation.")
            return

        # Perform correlation analysis
        self._perform_correlation_analysis(selected_campaigns)

    def _perform_correlation_analysis(self, campaigns: list[dict]):
        """Perform correlation analysis on selected campaigns."""
        try:
            # Create correlation analyzer
            correlator = VulnerabilityCorrelator()

            # Analyze correlations
            correlation_results = correlator.analyze_campaigns(campaigns)

            # Display results in a new dialog
            results_dialog = CorrelationResultsDialog(correlation_results, self)
            results_dialog.exec()

            # Update correlation tab with results
            self._update_correlation_tab_with_analysis(correlation_results)

            # Save correlation results
            if hasattr(self, "_last_correlation_results"):
                self._last_correlation_results = correlation_results

        except Exception as e:
            logger.error(f"Correlation analysis failed: {e}")
            QMessageBox.critical(self, "Error", f"Failed to correlate results: {e!s}")

    def _update_correlation_tab_with_analysis(self, correlation_results: dict):
        """Update correlation tab with analysis results."""
        correlation_text = "=== Cross-Campaign Correlation Analysis ===\n\n"

        # Common vulnerabilities
        if "common_vulnerabilities" in correlation_results:
            correlation_text += "Common Vulnerabilities Across Campaigns:\n"
            for vuln_type, data in correlation_results["common_vulnerabilities"].items():
                correlation_text += f"\n{vuln_type}:\n"
                correlation_text += f"  - Found in {data['campaign_count']} campaigns\n"
                correlation_text += f"  - Total occurrences: {data['total_count']}\n"
                correlation_text += f"  - Average severity: {data['avg_severity']}\n"
                if data.get("common_locations"):
                    correlation_text += f"  - Common locations: {', '.join(data['common_locations'][:3])}\n"

        # Pattern analysis
        if "patterns" in correlation_results:
            correlation_text += "\n\nVulnerability Patterns:\n"
            for pattern in correlation_results["patterns"]:
                correlation_text += f"\n- {pattern['description']}\n"
                correlation_text += f"  Confidence: {pattern['confidence']:.1f}%\n"
                correlation_text += f"  Affected campaigns: {pattern['affected_campaigns']}\n"

        # Risk assessment
        if "risk_assessment" in correlation_results:
            correlation_text += "\n\nRisk Assessment:\n"
            risk = correlation_results["risk_assessment"]
            correlation_text += f"Overall Risk Score: {risk['overall_score']:.1f}/100\n"
            correlation_text += f"Critical Issues: {risk['critical_count']}\n"
            correlation_text += f"Systemic Vulnerabilities: {risk['systemic_count']}\n"

            if risk.get("recommendations"):
                correlation_text += "\nPriority Recommendations:\n"
                for i, rec in enumerate(risk["recommendations"][:5], 1):
                    correlation_text += f"{i}. {rec}\n"

        # Statistical summary
        if "statistics" in correlation_results:
            stats = correlation_results["statistics"]
            correlation_text += "\n\nStatistical Summary:\n"
            correlation_text += f"Total vulnerabilities analyzed: {stats['total_vulnerabilities']}\n"
            correlation_text += f"Unique vulnerability types: {stats['unique_types']}\n"
            correlation_text += f"Cross-campaign correlation coefficient: {stats['correlation_coefficient']:.3f}\n"

        self.correlation_edit.setText(correlation_text)


class CampaignSelectionDialog(QDialog):
    """Dialog for selecting campaigns for correlation."""

    def __init__(self, campaign_results: dict, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Select Campaigns for Correlation")
        self.setMinimumSize(400, 300)
        self.campaign_results = campaign_results

        layout = QVBoxLayout(self)

        # Instructions
        layout.addWidget(QLabel("Select campaigns to correlate:"))

        # Campaign list
        self.campaign_list = QListWidget()
        self.campaign_list.setSelectionMode(QListWidget.SelectionMode.MultiSelection)

        for campaign_id, results in campaign_results.items():
            item_text = f"{results.get('campaign_type', 'Unknown')} - {campaign_id[:8]}"
            self.campaign_list.addItem(item_text)
            self.campaign_list.item(self.campaign_list.count() - 1).setData(Qt.UserRole, campaign_id)

        layout.addWidget(self.campaign_list)

        # Buttons
        button_layout = QHBoxLayout()

        select_all_btn = QPushButton("Select All")
        select_all_btn.clicked.connect(self._select_all)
        button_layout.addWidget(select_all_btn)

        button_layout.addStretch()

        ok_btn = QPushButton("Correlate")
        ok_btn.clicked.connect(self.accept)
        button_layout.addWidget(ok_btn)

        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        button_layout.addWidget(cancel_btn)

        layout.addLayout(button_layout)

    def _select_all(self):
        """Select all campaigns."""
        for i in range(self.campaign_list.count()):
            self.campaign_list.item(i).setSelected(True)

    def get_selected_campaigns(self) -> list[dict]:
        """Get selected campaign results."""
        selected = []
        for item in self.campaign_list.selectedItems():
            campaign_id = item.data(Qt.UserRole)
            if campaign_id in self.campaign_results:
                selected.append(self.campaign_results[campaign_id])
        return selected


class CorrelationResultsDialog(QDialog):
    """Dialog for displaying correlation analysis results."""

    def __init__(self, correlation_results: dict, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Correlation Analysis Results")
        self.setMinimumSize(800, 600)
        self.correlation_results = correlation_results

        layout = QVBoxLayout(self)

        # Create tabs for different views
        tabs = QTabWidget()

        # Overview tab
        overview_widget = self._create_overview_widget()
        tabs.addTab(overview_widget, "Overview")

        # Common vulnerabilities tab
        common_widget = self._create_common_vulnerabilities_widget()
        tabs.addTab(common_widget, "Common Vulnerabilities")

        # Patterns tab
        patterns_widget = self._create_patterns_widget()
        tabs.addTab(patterns_widget, "Patterns")

        # Visualization tab
        viz_widget = self._create_visualization_widget()
        tabs.addTab(viz_widget, "Visualization")

        layout.addWidget(tabs)

        # Buttons
        button_layout = QHBoxLayout()

        export_btn = QPushButton("Export Analysis")
        export_btn.clicked.connect(self._export_analysis)
        button_layout.addWidget(export_btn)

        button_layout.addStretch()

        close_btn = QPushButton("Close")
        close_btn.clicked.connect(self.close)
        button_layout.addWidget(close_btn)

        layout.addLayout(button_layout)

    def _create_overview_widget(self) -> QWidget:
        """Create overview widget."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Summary text
        summary = QTextEdit()
        summary.setReadOnly(True)

        summary_text = "Correlation Analysis Overview\n\n"

        if "summary" in self.correlation_results:
            s = self.correlation_results["summary"]
            summary_text += f"Campaigns Analyzed: {s.get('campaign_count', 0)}\n"
            summary_text += f"Total Vulnerabilities: {s.get('total_vulnerabilities', 0)}\n"
            summary_text += f"Common Vulnerability Types: {s.get('common_types', 0)}\n"
            summary_text += f"Correlation Strength: {s.get('correlation_strength', 'Unknown')}\n"

        if "risk_assessment" in self.correlation_results:
            risk = self.correlation_results["risk_assessment"]
            summary_text += f"\nOverall Risk Score: {risk.get('overall_score', 0):.1f}/100\n"
            summary_text += f"Critical Issues: {risk.get('critical_count', 0)}\n"

        summary.setText(summary_text)
        layout.addWidget(summary)

        return widget

    def _create_common_vulnerabilities_widget(self) -> QWidget:
        """Create common vulnerabilities widget."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Table of common vulnerabilities
        table = QTableWidget()
        table.setColumnCount(5)
        table.setHorizontalHeaderLabels([
            "Vulnerability Type", "Campaigns", "Occurrences", "Avg Severity", "Common Locations",
        ])

        if "common_vulnerabilities" in self.correlation_results:
            vulns = self.correlation_results["common_vulnerabilities"]
            table.setRowCount(len(vulns))

            for row, (vuln_type, data) in enumerate(vulns.items()):
                table.setItem(row, 0, QTableWidgetItem(vuln_type))
                table.setItem(row, 1, QTableWidgetItem(str(data.get("campaign_count", 0))))
                table.setItem(row, 2, QTableWidgetItem(str(data.get("total_count", 0))))
                table.setItem(row, 3, QTableWidgetItem(data.get("avg_severity", "Unknown")))
                locations = ", ".join(data.get("common_locations", [])[:3])
                table.setItem(row, 4, QTableWidgetItem(locations))

        table.resizeColumnsToContents()
        layout.addWidget(table)

        return widget

    def _create_patterns_widget(self) -> QWidget:
        """Create patterns widget."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Pattern list
        pattern_text = QTextEdit()
        pattern_text.setReadOnly(True)

        if "patterns" in self.correlation_results:
            for pattern in self.correlation_results["patterns"]:
                pattern_text.append(f"Pattern: {pattern.get('description', 'Unknown')}")
                pattern_text.append(f"Type: {pattern.get('type', 'Unknown')}")
                pattern_text.append(f"Confidence: {pattern.get('confidence', 0):.1f}%")
                pattern_text.append(f"Affected Campaigns: {pattern.get('affected_campaigns', 0)}")
                pattern_text.append(f"Evidence: {pattern.get('evidence', 'N/A')}")
                pattern_text.append("\n" + "-"*50 + "\n")

        layout.addWidget(pattern_text)

        return widget

    def _create_visualization_widget(self) -> QWidget:
        """Create visualization widget."""
        widget = QWidget()
        layout = QVBoxLayout(widget)

        # Create tabs for different visualizations
        viz_tabs = QTabWidget()

        # Distribution Chart
        dist_widget = QWidget()
        dist_layout = QVBoxLayout(dist_widget)

        dist_text = QTextEdit()
        dist_text.setReadOnly(True)
        dist_text.setFont(QFont("Courier", 10))

        # Generate ASCII chart for vulnerability distribution
        chart_text = self._generate_distribution_chart()
        dist_text.setText(chart_text)
        dist_layout.addWidget(dist_text)

        viz_tabs.addTab(dist_widget, "Distribution Chart")

        # Correlation Matrix
        corr_widget = QWidget()
        corr_layout = QVBoxLayout(corr_widget)

        corr_text = QTextEdit()
        corr_text.setReadOnly(True)
        corr_text.setFont(QFont("Courier", 10))

        matrix_text = self._generate_correlation_matrix()
        corr_text.setText(matrix_text)
        corr_layout.addWidget(corr_text)

        viz_tabs.addTab(corr_widget, "Correlation Matrix")

        # Timeline Analysis
        timeline_widget = QWidget()
        timeline_layout = QVBoxLayout(timeline_widget)

        timeline_text = QTextEdit()
        timeline_text.setReadOnly(True)
        timeline_text.setFont(QFont("Courier", 10))

        timeline_data = self._generate_timeline_analysis()
        timeline_text.setText(timeline_data)
        timeline_layout.addWidget(timeline_text)

        viz_tabs.addTab(timeline_widget, "Timeline Analysis")

        # Risk Summary
        risk_widget = QWidget()
        risk_layout = QVBoxLayout(risk_widget)

        risk_text = QTextEdit()
        risk_text.setReadOnly(True)

        risk_summary = self._generate_risk_summary()
        risk_text.setHtml(risk_summary)
        risk_layout.addWidget(risk_text)

        viz_tabs.addTab(risk_widget, "Risk Summary")

        layout.addWidget(viz_tabs)

        # Export visualization button
        export_viz_btn = QPushButton("Export Visualizations as Images")
        export_viz_btn.clicked.connect(self._export_visualizations)
        layout.addWidget(export_viz_btn)

        return widget

    def _generate_distribution_chart(self) -> str:
        """Generate ASCII distribution chart."""
        if not hasattr(self, "analysis_results"):
            return "No analysis data available for visualization."

        # Count vulnerabilities by type
        vuln_counts = {}
        max_count = 0

        for campaign in self.analysis_results.get("campaigns", []):
            for pattern in campaign.get("patterns", []):
                vuln_type = pattern.get("type", "Unknown")
                count = pattern.get("occurrences", 0)
                vuln_counts[vuln_type] = vuln_counts.get(vuln_type, 0) + count
                max_count = max(max_count, vuln_counts[vuln_type])

        if not vuln_counts:
            return "No vulnerability data to visualize."

        # Generate ASCII bar chart
        chart = "Vulnerability Distribution Chart\n"
        chart += "="*60 + "\n\n"

        bar_width = 40
        for vuln_type, count in sorted(vuln_counts.items(), key=lambda x: x[1], reverse=True):
            bar_length = int((count / max_count) * bar_width) if max_count > 0 else 0
            bar = "" * bar_length
            chart += f"{vuln_type:20} |{bar:<40} {count:>5}\n"

        chart += "\n" + "="*60 + "\n"
        chart += f"Total Vulnerabilities: {sum(vuln_counts.values())}\n"
        chart += f"Unique Types: {len(vuln_counts)}\n"

        return chart

    def _generate_correlation_matrix(self) -> str:
        """Generate correlation matrix visualization."""
        if not hasattr(self, "analysis_results"):
            return "No analysis data available for correlation matrix."

        correlations = self.analysis_results.get("cross_campaign_patterns", {}).get("correlations", {})

        if not correlations:
            return "No correlation data available."

        # Build matrix text
        matrix = "Vulnerability Type Correlation Matrix\n"
        matrix += "="*80 + "\n\n"
        matrix += "Values show correlation strength (0.0 - 1.0)\n\n"

        # Get unique types
        types = set()
        for corr in correlations:
            types.add(corr.get("type1", ""))
            types.add(corr.get("type2", ""))

        types = sorted(list(types))[:10]  # Limit to 10 for display

        # Header
        matrix += "             "
        for t in types:
            matrix += f"{t[:8]:>10}"
        matrix += "\n"

        # Rows
        for t1 in types:
            matrix += f"{t1[:12]:12}"
            for t2 in types:
                # Find correlation value
                corr_val = 0.0
                for corr in correlations:
                    if ((corr["type1"] == t1 and corr["type2"] == t2) or
                        (corr["type1"] == t2 and corr["type2"] == t1)):
                        corr_val = corr.get("correlation", 0.0)
                        break

                if t1 == t2:
                    matrix += "      1.00"
                else:
                    matrix += f"{corr_val:10.2f}"
            matrix += "\n"

        return matrix

    def _generate_timeline_analysis(self) -> str:
        """Generate timeline analysis visualization."""
        if not hasattr(self, "analysis_results"):
            return "No analysis data available for timeline."

        timeline = "Vulnerability Discovery Timeline\n"
        timeline += "="*60 + "\n\n"

        # Get temporal patterns
        temporal = self.analysis_results.get("cross_campaign_patterns", {}).get("temporal_patterns", [])

        if not temporal:
            # Generate sample timeline
            campaigns = self.analysis_results.get("campaigns", [])
            timeline += "Campaign Timeline:\n\n"

            for i, campaign in enumerate(campaigns):
                vulns = len(campaign.get("patterns", []))
                timeline += f"Campaign {i+1}: {'' * min(vulns, 40)} ({vulns} vulnerabilities)\n"
        else:
            # Show temporal patterns
            timeline += "Temporal Patterns Detected:\n\n"
            for pattern in temporal:
                timeline += f"- {pattern.get('pattern', 'Unknown pattern')}\n"
                timeline += f"  Timeframe: {pattern.get('timeframe', 'N/A')}\n"
                timeline += f"  Confidence: {pattern.get('confidence', 0):.1%}\n\n"

        return timeline

    def _generate_risk_summary(self) -> str:
        """Generate risk summary visualization."""
        if not hasattr(self, "analysis_results"):
            return "<p>No analysis data available for risk summary.</p>"

        risk_assessment = self.analysis_results.get("risk_assessment", {})

        html = """
        <h3>Risk Assessment Summary</h3>
        <hr>
        """

        # Overall risk score
        overall_risk = risk_assessment.get("overall_risk_score", 0)
        risk_level = "Low"
        risk_color = "green"

        if overall_risk > 7:
            risk_level = "Critical"
            risk_color = "red"
        elif overall_risk > 5:
            risk_level = "High"
            risk_color = "orange"
        elif overall_risk > 3:
            risk_level = "Medium"
            risk_color = "yellow"

        html += f"""
        <div style='background-color: #f0f0f0; padding: 10px; margin: 10px 0;'>
            <h4>Overall Risk Score: <span style='color: {risk_color}'>{overall_risk:.1f}/10 ({risk_level})</span></h4>
        </div>
        """

        # Risk factors
        html += "<h4>Risk Factors:</h4><ul>"
        factors = risk_assessment.get("factors", [])
        for factor in factors[:10]:
            impact = factor.get("impact", "Unknown")
            html += f"<li><strong>{factor.get('factor', 'Unknown')}:</strong> {impact}</li>"
        html += "</ul>"

        # Attack surface
        html += "<h4>Attack Surface Analysis:</h4>"
        attack_surface = risk_assessment.get("attack_surface", {})
        html += f"<p>Estimated Attack Surface: <strong>{attack_surface.get('size', 'Unknown')}</strong></p>"
        html += f"<p>Critical Entry Points: <strong>{attack_surface.get('critical_points', 0)}</strong></p>"

        # Mitigation priority
        html += "<h4>Mitigation Priorities:</h4><ol>"
        priorities = risk_assessment.get("mitigation_priorities", [])
        for priority in priorities[:5]:
            html += f"<li>{priority}</li>"
        html += "</ol>"

        return html

    def _export_visualizations(self):
        """Export visualizations as images."""
        # This would typically use matplotlib or similar to generate actual images
        # For now, export as text files

        dir_path = QFileDialog.getExistingDirectory(
            self, "Select Export Directory", "",
        )

        if not dir_path:
            return

        try:
            # Export distribution chart
            with open(os.path.join(dir_path, "distribution_chart.txt"), "w") as f:
                f.write(self._generate_distribution_chart())

            # Export correlation matrix
            with open(os.path.join(dir_path, "correlation_matrix.txt"), "w") as f:
                f.write(self._generate_correlation_matrix())

            # Export timeline
            with open(os.path.join(dir_path, "timeline_analysis.txt"), "w") as f:
                f.write(self._generate_timeline_analysis())

            # Export risk summary as HTML
            with open(os.path.join(dir_path, "risk_summary.html"), "w") as f:
                f.write(f"<html><body>{self._generate_risk_summary()}</body></html>")

            QMessageBox.information(
                self, "Success",
                f"Visualizations exported to:\n{dir_path}",
            )

        except Exception as e:
            logger.error(f"Failed to export visualizations: {e}")
            QMessageBox.critical(self, "Error", f"Export failed: {e!s}")

    def _export_analysis(self):
        """Export correlation analysis."""
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Export Correlation Analysis",
            f"correlation_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
            "JSON Files (*.json);;All Files (*)",
        )

        if file_path:
            try:
                import json
                with open(file_path, "w") as f:
                    json.dump(self.correlation_results, f, indent=2, default=str)
                QMessageBox.information(self, "Success", f"Analysis exported to {file_path}")
            except Exception as e:
                QMessageBox.critical(self, "Error", f"Export failed: {e!s}")


class VulnerabilityCorrelator:
    """Engine for correlating vulnerabilities across campaigns."""

    def analyze_campaigns(self, campaigns: list[dict]) -> dict:
        """Analyze and correlate vulnerabilities across campaigns."""
        results = {
            "summary": {
                "campaign_count": len(campaigns),
                "total_vulnerabilities": 0,
                "common_types": 0,
                "correlation_strength": "Unknown",
            },
            "common_vulnerabilities": {},
            "patterns": [],
            "risk_assessment": {},
            "statistics": {},
        }

        # Collect all vulnerabilities
        all_vulns = []
        vuln_by_campaign = {}

        for i, campaign in enumerate(campaigns):
            campaign_vulns = campaign.get("vulnerabilities", [])
            all_vulns.extend(campaign_vulns)
            vuln_by_campaign[i] = campaign_vulns

        results["summary"]["total_vulnerabilities"] = len(all_vulns)

        # Find common vulnerability types
        self._analyze_common_vulnerabilities(all_vulns, vuln_by_campaign, results)

        # Detect patterns
        self._detect_patterns(all_vulns, vuln_by_campaign, results)

        # Risk assessment
        self._assess_risk(all_vulns, results)

        # Calculate statistics
        self._calculate_statistics(all_vulns, vuln_by_campaign, results)

        return results

    def _analyze_common_vulnerabilities(self, all_vulns: list[dict], vuln_by_campaign: dict, results: dict):
        """Analyze common vulnerabilities across campaigns."""
        from collections import Counter, defaultdict

        # Group by type
        type_groups = defaultdict(list)
        for vuln in all_vulns:
            vuln_type = vuln.get("type", "Unknown")
            type_groups[vuln_type].append(vuln)

        # Analyze each type
        common_vulns = {}
        for vuln_type, vulns in type_groups.items():
            # Count campaigns with this vulnerability type
            campaigns_with_type = set()
            for campaign_id, campaign_vulns in vuln_by_campaign.items():
                if any(v.get("type") == vuln_type for v in campaign_vulns):
                    campaigns_with_type.add(campaign_id)

            if len(campaigns_with_type) > 1:  # Found in multiple campaigns
                # Calculate average severity
                severities = [v.get("severity", "low") for v in vulns]
                severity_map = {"critical": 4, "high": 3, "medium": 2, "low": 1}
                avg_severity_num = sum(severity_map.get(s.lower(), 1) for s in severities) / len(severities)
                avg_severity = {4: "critical", 3: "high", 2: "medium", 1: "low"}.get(
                    round(avg_severity_num), "medium",
                )

                # Find common locations
                locations = [str(v.get("location", "Unknown")) for v in vulns]
                location_counts = Counter(locations)
                common_locations = [loc for loc, count in location_counts.most_common(5) if count > 1]

                common_vulns[vuln_type] = {
                    "campaign_count": len(campaigns_with_type),
                    "total_count": len(vulns),
                    "avg_severity": avg_severity,
                    "common_locations": common_locations,
                }

        results["common_vulnerabilities"] = common_vulns
        results["summary"]["common_types"] = len(common_vulns)

    def _detect_patterns(self, all_vulns: list[dict], vuln_by_campaign: dict, results: dict):
        """Detect vulnerability patterns."""
        patterns = []

        # Pattern 1: Sequential vulnerabilities
        for campaign_vulns in vuln_by_campaign.values():
            if len(campaign_vulns) > 3:
                # Check for vulnerabilities in close proximity
                positions = []
                for v in campaign_vulns:
                    if isinstance(v.get("position"), (int, float)):
                        positions.append(v.get("position"))

                if len(positions) > 3:
                    positions.sort()
                    # Check for clustering
                    clusters = []
                    current_cluster = [positions[0]]

                    for i in range(1, len(positions)):
                        if positions[i] - positions[i-1] < 1000:  # Within 1KB
                            current_cluster.append(positions[i])
                        else:
                            if len(current_cluster) > 2:
                                clusters.append(current_cluster)
                            current_cluster = [positions[i]]

                    if len(current_cluster) > 2:
                        clusters.append(current_cluster)

                    if clusters:
                        patterns.append({
                            "type": "clustering",
                            "description": f"Vulnerabilities clustered in {len(clusters)} areas",
                            "confidence": min(95, len(clusters) * 30),
                            "affected_campaigns": 1,
                            "evidence": f"Found {len(clusters)} vulnerability clusters",
                        })

        # Pattern 2: Common attack vectors
        attack_vectors = defaultdict(int)
        for vuln in all_vulns:
            vuln_type = vuln.get("type", "").lower()
            if "buffer" in vuln_type or "overflow" in vuln_type:
                attack_vectors["memory_corruption"] += 1
            elif "injection" in vuln_type:
                attack_vectors["injection"] += 1
            elif "crypto" in vuln_type or "random" in vuln_type:
                attack_vectors["cryptographic"] += 1

        for vector, count in attack_vectors.items():
            if count > 5:
                patterns.append({
                    "type": "attack_vector",
                    "description": f"Prevalent {vector} attack vector",
                    "confidence": min(90, count * 10),
                    "affected_campaigns": len(vuln_by_campaign),
                    "evidence": f"{count} vulnerabilities of this type",
                })

        results["patterns"] = patterns

    def _assess_risk(self, all_vulns: list[dict], results: dict):
        """Assess overall risk based on vulnerabilities."""
        risk = {
            "overall_score": 0,
            "critical_count": 0,
            "systemic_count": 0,
            "recommendations": [],
        }

        # Count by severity
        severity_counts = defaultdict(int)
        for vuln in all_vulns:
            severity = vuln.get("severity", "low").lower()
            severity_counts[severity] += 1
            if severity == "critical":
                risk["critical_count"] += 1

        # Calculate risk score
        weights = {"critical": 10, "high": 5, "medium": 2, "low": 0.5}
        total_score = sum(weights.get(sev, 0) * count for sev, count in severity_counts.items())
        max_score = len(all_vulns) * 10  # If all were critical
        risk["overall_score"] = (total_score / max_score * 100) if max_score > 0 else 0

        # Identify systemic issues
        if len(results.get("common_vulnerabilities", {})) > 3:
            risk["systemic_count"] = len(results["common_vulnerabilities"])
            risk["recommendations"].append(
                "Multiple vulnerability types found across campaigns indicate systemic security issues.",
            )

        # Generate recommendations
        if risk["critical_count"] > 0:
            risk["recommendations"].append(
                f"Immediately address {risk['critical_count']} critical vulnerabilities.",
            )

        if risk["overall_score"] > 70:
            risk["recommendations"].append(
                "High risk score indicates significant security concerns. Comprehensive security review recommended.",
            )

        results["risk_assessment"] = risk

    def _calculate_statistics(self, all_vulns: list[dict], vuln_by_campaign: dict, results: dict):
        """Calculate correlation statistics."""
        stats = {
            "total_vulnerabilities": len(all_vulns),
            "unique_types": len(set(v.get("type", "Unknown") for v in all_vulns)),
            "campaigns_analyzed": len(vuln_by_campaign),
            "correlation_coefficient": 0.0,
        }

        # Calculate correlation coefficient (simplified)
        if len(vuln_by_campaign) > 1:
            # Check how many vulnerability types appear in multiple campaigns
            type_appearances = defaultdict(set)
            for campaign_id, vulns in vuln_by_campaign.items():
                for vuln in vulns:
                    vuln_type = vuln.get("type", "Unknown")
                    type_appearances[vuln_type].add(campaign_id)

            # Correlation based on shared vulnerability types
            shared_types = sum(1 for campaigns in type_appearances.values() if len(campaigns) > 1)
            total_types = len(type_appearances)

            if total_types > 0:
                stats["correlation_coefficient"] = shared_types / total_types

        results["statistics"] = stats

        # Update correlation strength
        if stats["correlation_coefficient"] > 0.7:
            results["summary"]["correlation_strength"] = "Strong"
        elif stats["correlation_coefficient"] > 0.4:
            results["summary"]["correlation_strength"] = "Moderate"
        elif stats["correlation_coefficient"] > 0.1:
            results["summary"]["correlation_strength"] = "Weak"
        else:
            results["summary"]["correlation_strength"] = "None"

    def _export_results(self):
        """Export results in various formats."""
        # Check if there are results to export
        if not self.campaign_results:
            QMessageBox.warning(self, "Warning", "No results available to export.")
            return

        # Create export dialog
        export_dialog = ExportResultsDialog(self.campaign_results, self)
        if export_dialog.exec() != QDialog.Accepted:
            return

        # Get export options
        export_format = export_dialog.format_combo.currentText()
        selected_campaigns = export_dialog.get_selected_campaigns()
        include_metadata = export_dialog.metadata_check.isChecked()
        include_raw_data = export_dialog.raw_data_check.isChecked()
        compress_output = export_dialog.compress_check.isChecked()

        if not selected_campaigns:
            QMessageBox.warning(self, "Warning", "No campaigns selected for export.")
            return

        try:
            # Perform export based on format
            if export_format == "JSON":
                output_path = self._export_to_json(selected_campaigns, include_metadata, include_raw_data)
            elif export_format == "CSV":
                output_path = self._export_to_csv(selected_campaigns, include_metadata)
            elif export_format == "XML":
                output_path = self._export_to_xml(selected_campaigns, include_metadata)
            elif export_format == "SQLite":
                output_path = self._export_to_sqlite(selected_campaigns, include_metadata)
            elif export_format == "Archive (ZIP)":
                output_path = self._export_to_archive(selected_campaigns, include_metadata, include_raw_data)
            else:
                QMessageBox.warning(self, "Warning", f"Unsupported export format: {export_format}")
                return

            # Compress if requested
            if compress_output and export_format != "Archive (ZIP)":
                output_path = self._compress_export(output_path)

            # Show success message
            reply = QMessageBox.question(
                self,
                "Export Complete",
                f"Results exported to:\n{output_path}\n\nOpen containing folder?",
                QMessageBox.Yes | QMessageBox.No,
            )

            if reply == QMessageBox.Yes:
                import os
                folder = os.path.dirname(output_path)
                if os.name == "nt":
                    os.startfile(folder)
                else:
                    os.system(f'open "{folder}"')

        except Exception as e:
            logger.error(f"Export failed: {e}")
            QMessageBox.critical(self, "Error", f"Export failed: {e!s}")

    def _export_to_json(self, campaigns: dict[str, dict], include_metadata: bool, include_raw_data: bool) -> str:
        """Export results to JSON format."""
        import json

        default_name = f"vulnerability_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export to JSON", default_name, "JSON Files (*.json)",
        )

        if not file_path:
            raise ValueError("No file path selected")

        export_data = {
            "export_info": {
                "timestamp": datetime.now().isoformat(),
                "tool": "Intellicrack Vulnerability Research",
                "version": "1.0",
                "campaign_count": len(campaigns),
            },
            "campaigns": {},
        }

        for campaign_id, results in campaigns.items():
            campaign_export = {
                "campaign_id": campaign_id,
                "type": results.get("campaign_type", "Unknown"),
                "status": results.get("status", "Unknown"),
                "summary": {
                    "vulnerabilities": len(results.get("vulnerabilities", [])),
                    "crashes": results.get("crash_count", 0),
                    "coverage": results.get("coverage", {}).get("percentage", 0),
                },
            }

            if include_metadata:
                campaign_export["metadata"] = {
                    "created_at": results.get("created_at", 0),
                    "completed_at": results.get("completed_at", 0),
                    "duration": results.get("duration", 0),
                    "configuration": results.get("configuration", {}),
                }

            if include_raw_data:
                campaign_export["raw_data"] = results
            else:
                # Include essential data only
                campaign_export["vulnerabilities"] = results.get("vulnerabilities", [])
                campaign_export["statistics"] = results.get("statistics", {})

            export_data["campaigns"][campaign_id] = campaign_export

        # Write JSON file
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(export_data, f, indent=2, default=str)

        logger.info(f"Exported {len(campaigns)} campaigns to JSON: {file_path}")
        return file_path

    def _export_to_csv(self, campaigns: dict[str, dict], include_metadata: bool) -> str:
        """Export results to CSV format."""
        import csv

        default_name = f"vulnerability_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export to CSV", default_name, "CSV Files (*.csv)",
        )

        if not file_path:
            raise ValueError("No file path selected")

        # Prepare CSV data
        rows = []
        headers = [
            "Campaign ID", "Campaign Type", "Status", "Vulnerability Type",
            "Severity", "Location", "Exploitable", "Description",
        ]

        if include_metadata:
            headers.extend(["Created At", "Duration", "Test Cases"])

        for campaign_id, results in campaigns.items():
            base_row = [
                campaign_id[:8],
                results.get("campaign_type", "Unknown"),
                results.get("status", "Unknown"),
            ]

            # Add vulnerability rows
            for vuln in results.get("vulnerabilities", []):
                row = base_row + [
                    vuln.get("type", "Unknown"),
                    vuln.get("severity", "Unknown"),
                    str(vuln.get("location", "Unknown"))[:50],
                    str(vuln.get("exploitable", "Unknown")),
                    vuln.get("description", "")[:100],
                ]

                if include_metadata:
                    row.extend([
                        datetime.fromtimestamp(results.get("created_at", 0)).strftime("%Y-%m-%d %H:%M:%S"),
                        f"{results.get('duration', 0):.1f}s",
                        str(results.get("test_cases", 0)),
                    ])

                rows.append(row)

            # Add empty row if no vulnerabilities
            if not results.get("vulnerabilities"):
                row = base_row + ["None", "", "", "", "No vulnerabilities found"]
                if include_metadata:
                    row.extend(["", "", ""])
                rows.append(row)

        # Write CSV file
        with open(file_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(headers)
            writer.writerows(rows)

        logger.info(f"Exported {len(campaigns)} campaigns to CSV: {file_path}")
        return file_path

    def _export_to_xml(self, campaigns: dict[str, dict], include_metadata: bool) -> str:
        """Export results to XML format."""
        import xml.etree.ElementTree as ET
        from xml.dom import minidom

        default_name = f"vulnerability_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xml"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export to XML", default_name, "XML Files (*.xml)",
        )

        if not file_path:
            raise ValueError("No file path selected")

        # Create XML structure
        root = ET.Element("VulnerabilityResults")
        root.set("timestamp", datetime.now().isoformat())
        root.set("tool", "Intellicrack")

        for campaign_id, results in campaigns.items():
            campaign_elem = ET.SubElement(root, "Campaign")
            campaign_elem.set("id", campaign_id)
            campaign_elem.set("type", results.get("campaign_type", "Unknown"))
            campaign_elem.set("status", results.get("status", "Unknown"))

            # Summary
            summary_elem = ET.SubElement(campaign_elem, "Summary")
            ET.SubElement(summary_elem, "Vulnerabilities").text = str(len(results.get("vulnerabilities", [])))
            ET.SubElement(summary_elem, "Crashes").text = str(results.get("crash_count", 0))
            ET.SubElement(summary_elem, "Coverage").text = f"{results.get('coverage', {}).get('percentage', 0):.1f}"

            # Metadata
            if include_metadata:
                metadata_elem = ET.SubElement(campaign_elem, "Metadata")
                ET.SubElement(metadata_elem, "CreatedAt").text = str(results.get("created_at", 0))
                ET.SubElement(metadata_elem, "Duration").text = str(results.get("duration", 0))
                ET.SubElement(metadata_elem, "TestCases").text = str(results.get("test_cases", 0))

            # Vulnerabilities
            vulns_elem = ET.SubElement(campaign_elem, "Vulnerabilities")
            for vuln in results.get("vulnerabilities", []):
                vuln_elem = ET.SubElement(vulns_elem, "Vulnerability")
                vuln_elem.set("type", vuln.get("type", "Unknown"))
                vuln_elem.set("severity", vuln.get("severity", "Unknown"))

                ET.SubElement(vuln_elem, "Location").text = str(vuln.get("location", "Unknown"))
                ET.SubElement(vuln_elem, "Exploitable").text = str(vuln.get("exploitable", "Unknown"))
                ET.SubElement(vuln_elem, "Description").text = vuln.get("description", "")

        # Pretty print XML
        xml_str = minidom.parseString(ET.tostring(root)).toprettyxml(indent="  ")

        with open(file_path, "w", encoding="utf-8") as f:
            f.write(xml_str)

        logger.info(f"Exported {len(campaigns)} campaigns to XML: {file_path}")
        return file_path

    def _export_to_sqlite(self, campaigns: dict[str, dict], include_metadata: bool) -> str:
        """Export results to SQLite database."""
        import sqlite3

        default_name = f"vulnerability_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export to SQLite", default_name, "SQLite Database (*.db)",
        )

        if not file_path:
            raise ValueError("No file path selected")

        # Create database
        conn = sqlite3.connect(file_path)
        cursor = conn.cursor()

        # Create tables
        cursor.execute("""
            CREATE TABLE campaigns (
                campaign_id TEXT PRIMARY KEY,
                campaign_type TEXT,
                status TEXT,
                vulnerabilities_count INTEGER,
                crash_count INTEGER,
                coverage_percentage REAL,
                created_at INTEGER,
                duration REAL,
                test_cases INTEGER
            )
        """)

        cursor.execute("""
            CREATE TABLE vulnerabilities (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                campaign_id TEXT,
                type TEXT,
                severity TEXT,
                location TEXT,
                exploitable TEXT,
                description TEXT,
                FOREIGN KEY (campaign_id) REFERENCES campaigns (campaign_id)
            )
        """)

        # Insert data
        for campaign_id, results in campaigns.items():
            # Insert campaign
            cursor.execute("""
                INSERT INTO campaigns VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                campaign_id,
                results.get("campaign_type", "Unknown"),
                results.get("status", "Unknown"),
                len(results.get("vulnerabilities", [])),
                results.get("crash_count", 0),
                results.get("coverage", {}).get("percentage", 0),
                results.get("created_at", 0) if include_metadata else 0,
                results.get("duration", 0) if include_metadata else 0,
                results.get("test_cases", 0) if include_metadata else 0,
            ))

            # Insert vulnerabilities
            for vuln in results.get("vulnerabilities", []):
                cursor.execute("""
                    INSERT INTO vulnerabilities
                    (campaign_id, type, severity, location, exploitable, description)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    campaign_id,
                    vuln.get("type", "Unknown"),
                    vuln.get("severity", "Unknown"),
                    str(vuln.get("location", "Unknown"))[:255],
                    str(vuln.get("exploitable", "Unknown")),
                    vuln.get("description", "")[:500],
                ))

        # Create indexes
        cursor.execute("CREATE INDEX idx_campaign_type ON campaigns(campaign_type)")
        cursor.execute("CREATE INDEX idx_vuln_severity ON vulnerabilities(severity)")
        cursor.execute("CREATE INDEX idx_vuln_type ON vulnerabilities(type)")

        conn.commit()
        conn.close()

        logger.info(f"Exported {len(campaigns)} campaigns to SQLite: {file_path}")
        return file_path

    def _export_to_archive(self, campaigns: dict[str, dict], include_metadata: bool, include_raw_data: bool) -> str:
        """Export results to ZIP archive with multiple formats."""
        import tempfile
        import zipfile

        default_name = f"vulnerability_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        file_path, _ = QFileDialog.getSaveFileName(
            self, "Export to Archive", default_name, "ZIP Archive (*.zip)",
        )

        if not file_path:
            raise ValueError("No file path selected")

        # Create temporary directory
        with tempfile.TemporaryDirectory() as temp_dir:
            # Export to multiple formats
            json_path = os.path.join(temp_dir, "results.json")
            self._export_json_to_file(json_path, campaigns, include_metadata, include_raw_data)

            csv_path = os.path.join(temp_dir, "results.csv")
            self._export_csv_to_file(csv_path, campaigns, include_metadata)

            # Create summary report
            summary_path = os.path.join(temp_dir, "summary.txt")
            self._create_summary_report(summary_path, campaigns)

            # Add any crash files
            crashes_dir = os.path.join(temp_dir, "crashes")
            os.makedirs(crashes_dir, exist_ok=True)
            self._export_crash_files(crashes_dir, campaigns)

            # Create ZIP archive
            with zipfile.ZipFile(file_path, "w", zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        file_path_in_zip = os.path.relpath(
                            os.path.join(root, file), temp_dir,
                        )
                        zipf.write(os.path.join(root, file), file_path_in_zip)

        logger.info(f"Exported {len(campaigns)} campaigns to archive: {file_path}")
        return file_path

    def _compress_export(self, file_path: str) -> str:
        """Compress exported file."""
        import gzip
        import shutil

        compressed_path = file_path + ".gz"

        with open(file_path, "rb") as f_in:
            with gzip.open(compressed_path, "wb") as f_out:
                shutil.copyfileobj(f_in, f_out)

        # Remove original file
        os.remove(file_path)

        logger.info(f"Compressed export to: {compressed_path}")
        return compressed_path

    def _export_json_to_file(self, file_path: str, campaigns: dict, include_metadata: bool, include_raw_data: bool):
        """Helper to export JSON to specific file."""
        import json

        export_data = {
            "campaigns": campaigns if include_raw_data else {
                cid: {
                    "summary": {
                        "type": r.get("campaign_type"),
                        "vulnerabilities": len(r.get("vulnerabilities", [])),
                        "crashes": r.get("crash_count", 0),
                    },
                    "vulnerabilities": r.get("vulnerabilities", [])[:50],
                }
                for cid, r in campaigns.items()
            },
        }

        if include_metadata:
            export_data["metadata"] = {
                "exported_at": datetime.now().isoformat(),
                "campaign_count": len(campaigns),
            }

        with open(file_path, "w") as f:
            json.dump(export_data, f, indent=2, default=str)

    def _export_csv_to_file(self, file_path: str, campaigns: dict, include_metadata: bool):
        """Helper to export CSV to specific file."""
        import csv

        with open(file_path, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["Campaign", "Type", "Vulnerabilities", "Severity Breakdown"])

            for cid, results in campaigns.items():
                vulns = results.get("vulnerabilities", [])
                severity_counts = {}
                for v in vulns:
                    sev = v.get("severity", "unknown").lower()
                    severity_counts[sev] = severity_counts.get(sev, 0) + 1

                severity_str = ", ".join(f"{k}:{v}" for k, v in severity_counts.items())

                writer.writerow([
                    cid[:8],
                    results.get("campaign_type", "Unknown"),
                    len(vulns),
                    severity_str,
                ])

    def _create_summary_report(self, file_path: str, campaigns: dict):
        """Create text summary report."""
        with open(file_path, "w") as f:
            f.write("Vulnerability Research Export Summary\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Campaigns: {len(campaigns)}\n\n")

            total_vulns = sum(len(r.get("vulnerabilities", [])) for r in campaigns.values())
            f.write(f"Total Vulnerabilities: {total_vulns}\n\n")

            for cid, results in campaigns.items():
                f.write(f"Campaign: {cid[:8]}\n")
                f.write(f"  Type: {results.get('campaign_type', 'Unknown')}\n")
                f.write(f"  Vulnerabilities: {len(results.get('vulnerabilities', []))}\n")
                f.write(f"  Crashes: {results.get('crash_count', 0)}\n")
                f.write("\n")

    def _export_crash_files(self, crashes_dir: str, campaigns: dict):
        """Export crash files if available."""
        for cid, results in campaigns.items():
            crashes = results.get("crashes", [])
            if crashes:
                campaign_crash_dir = os.path.join(crashes_dir, cid[:8])
                os.makedirs(campaign_crash_dir, exist_ok=True)

                for i, crash in enumerate(crashes[:10]):  # Limit to 10 crashes
                    crash_file = os.path.join(campaign_crash_dir, f"crash_{i:03d}.json")
                    import json
                    with open(crash_file, "w") as f:
                        json.dump(crash, f, indent=2, default=str)


class ExportResultsDialog(QDialog):
    """Dialog for selecting export options."""

    def __init__(self, campaign_results: dict, parent=None):
        super().__init__(parent)
        self.setWindowTitle("Export Results")
        self.setMinimumSize(500, 400)
        self.campaign_results = campaign_results

        layout = QVBoxLayout(self)

        # Format selection
        format_group = QGroupBox("Export Format")
        format_layout = QVBoxLayout(format_group)

        self.format_combo = QComboBox()
        self.format_combo.addItems(["JSON", "CSV", "XML", "SQLite", "Archive (ZIP)"])
        format_layout.addWidget(self.format_combo)

        layout.addWidget(format_group)

        # Campaign selection
        campaign_group = QGroupBox("Select Campaigns")
        campaign_layout = QVBoxLayout(campaign_group)

        self.campaign_list = QListWidget()
        self.campaign_list.setSelectionMode(QListWidget.SelectionMode.MultiSelection)

        for campaign_id, results in campaign_results.items():
            item_text = f"{results.get('campaign_type', 'Unknown')} - {campaign_id[:8]} ({len(results.get('vulnerabilities', []))} vulns)"
            self.campaign_list.addItem(item_text)
            self.campaign_list.item(self.campaign_list.count() - 1).setData(Qt.UserRole, campaign_id)

        campaign_layout.addWidget(self.campaign_list)

        # Select all button
        select_all_btn = QPushButton("Select All")
        select_all_btn.clicked.connect(self._select_all)
        campaign_layout.addWidget(select_all_btn)

        layout.addWidget(campaign_group)

        # Options
        options_group = QGroupBox("Export Options")
        options_layout = QVBoxLayout(options_group)

        self.metadata_check = QCheckBox("Include Metadata")
        self.metadata_check.setChecked(True)
        options_layout.addWidget(self.metadata_check)

        self.raw_data_check = QCheckBox("Include Raw Data")
        self.raw_data_check.setChecked(False)
        options_layout.addWidget(self.raw_data_check)

        self.compress_check = QCheckBox("Compress Output")
        self.compress_check.setChecked(False)
        options_layout.addWidget(self.compress_check)

        layout.addWidget(options_group)

        # Buttons
        button_layout = QHBoxLayout()

        export_btn = QPushButton("Export")
        export_btn.clicked.connect(self.accept)
        button_layout.addWidget(export_btn)

        cancel_btn = QPushButton("Cancel")
        cancel_btn.clicked.connect(self.reject)
        button_layout.addWidget(cancel_btn)

        layout.addLayout(button_layout)

    def _select_all(self):
        """Select all campaigns."""
        for i in range(self.campaign_list.count()):
            self.campaign_list.item(i).setSelected(True)

    def get_selected_campaigns(self) -> dict[str, dict]:
        """Get selected campaign results."""
        selected = {}
        for item in self.campaign_list.selectedItems():
            campaign_id = item.data(Qt.UserRole)
            if campaign_id in self.campaign_results:
                selected[campaign_id] = self.campaign_results[campaign_id]
        return selected

    def _save_configuration(self):
        """Save configuration to file."""
        # Get current configuration
        config = self._get_current_configuration()

        # Get save path
        default_name = f"vuln_research_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        file_path, _ = QFileDialog.getSaveFileName(
            self,
            "Save Configuration",
            default_name,
            "JSON Files (*.json);;All Files (*)",
        )

        if not file_path:
            return

        try:
            import json

            # Add metadata
            config["metadata"] = {
                "saved_at": datetime.now().isoformat(),
                "version": "1.0",
                "application": "Intellicrack Vulnerability Research",
            }

            # Save configuration
            with open(file_path, "w", encoding="utf-8") as f:
                json.dump(config, f, indent=2)

            # Also save to default location
            self._save_default_config(config)

            logger.info(f"Configuration saved to: {file_path}")
            QMessageBox.information(
                self,
                "Success",
                f"Configuration saved successfully to:\n{file_path}",
            )

        except Exception as e:
            logger.error(f"Failed to save configuration: {e}")
            QMessageBox.critical(
                self,
                "Error",
                f"Failed to save configuration: {e!s}",
            )

    def _load_configuration(self):
        """Load configuration from file."""
        # Get load path
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "Load Configuration",
            "",
            "JSON Files (*.json);;All Files (*)",
        )

        if not file_path:
            # Try to load default config
            default_config = self._load_default_config()
            if default_config:
                reply = QMessageBox.question(
                    self,
                    "Load Default",
                    "No file selected. Load default configuration?",
                    QMessageBox.Yes | QMessageBox.No,
                )

                if reply == QMessageBox.Yes:
                    self._apply_configuration(default_config)
            return

        try:
            import json

            # Load configuration
            with open(file_path, encoding="utf-8") as f:
                config = json.load(f)

            # Validate configuration
            if not self._validate_configuration(config):
                QMessageBox.warning(
                    self,
                    "Warning",
                    "Invalid configuration file format.",
                )
                return

            # Apply configuration
            self._apply_configuration(config)

            logger.info(f"Configuration loaded from: {file_path}")
            QMessageBox.information(
                self,
                "Success",
                "Configuration loaded successfully.",
            )

        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in configuration file: {e}")
            QMessageBox.critical(
                self,
                "Error",
                "Invalid configuration file format.",
            )
        except Exception as e:
            logger.error(f"Failed to load configuration: {e}")
            QMessageBox.critical(
                self,
                "Error",
                f"Failed to load configuration: {e!s}",
            )

    def _reset_configuration(self):
        """Reset configuration to defaults."""
        reply = QMessageBox.question(
            self,
            "Confirm Reset",
            "Are you sure you want to reset all settings to defaults?\n\n"
            "This action cannot be undone.",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No,
        )

        if reply != QMessageBox.Yes:
            return

        try:
            # Define default values
            defaults = {
                "research": {
                    "max_concurrent_campaigns": 5,
                    "default_timeout": 3600,
                    "storage_directory": "/tmp/intellicrack_research",
                    "auto_correlation": True,
                },
                "ml": {
                    "min_training_samples": 50,
                    "retrain_threshold": 100,
                    "confidence_threshold": 70,
                },
                "integration": {
                    "ai_integration": True,
                    "automated_exploitation": False,
                    "realtime_adaptation": True,
                },
            }

            # Apply defaults
            self._apply_configuration(defaults)

            # Clear any saved default config
            self._clear_default_config()

            # Clear campaign results and active campaigns
            if hasattr(self, "active_campaigns"):
                self.active_campaigns.clear()
            if hasattr(self, "campaign_results"):
                self.campaign_results.clear()

            # Refresh displays
            self._refresh_campaigns()
            self._refresh_results()

            logger.info("Configuration reset to defaults")
            QMessageBox.information(
                self,
                "Success",
                "Configuration has been reset to defaults.",
            )

        except Exception as e:
            logger.error(f"Failed to reset configuration: {e}")
            QMessageBox.critical(
                self,
                "Error",
                f"Failed to reset configuration: {e!s}",
            )

    def _get_current_configuration(self) -> dict:
        """Get current configuration from UI."""
        return {
            "research": {
                "max_concurrent_campaigns": self.max_campaigns_spin.value(),
                "default_timeout": self.timeout_spin.value(),
                "storage_directory": self.storage_dir_edit.text(),
                "auto_correlation": self.auto_correlation_check.isChecked(),
            },
            "ml": {
                "min_training_samples": self.min_samples_spin.value(),
                "retrain_threshold": self.retrain_threshold_spin.value(),
                "confidence_threshold": self.confidence_spin.value(),
            },
            "integration": {
                "ai_integration": self.ai_integration_check.isChecked(),
                "automated_exploitation": self.auto_exploitation_check.isChecked(),
                "realtime_adaptation": self.realtime_adaptation_check.isChecked(),
            },
            "ui_state": {
                "active_tab": self.tab_widget.currentIndex(),
                "window_geometry": {
                    "x": self.x(),
                    "y": self.y(),
                    "width": self.width(),
                    "height": self.height(),
                },
            },
        }

    def _apply_configuration(self, config: dict):
        """Apply configuration to UI."""
        try:
            # Research settings
            if "research" in config:
                research = config["research"]
                if "max_concurrent_campaigns" in research:
                    self.max_campaigns_spin.setValue(research["max_concurrent_campaigns"])
                if "default_timeout" in research:
                    self.timeout_spin.setValue(research["default_timeout"])
                if "storage_directory" in research:
                    self.storage_dir_edit.setText(research["storage_directory"])
                if "auto_correlation" in research:
                    self.auto_correlation_check.setChecked(research["auto_correlation"])

            # ML settings
            if "ml" in config:
                ml = config["ml"]
                if "min_training_samples" in ml:
                    self.min_samples_spin.setValue(ml["min_training_samples"])
                if "retrain_threshold" in ml:
                    self.retrain_threshold_spin.setValue(ml["retrain_threshold"])
                if "confidence_threshold" in ml:
                    self.confidence_spin.setValue(ml["confidence_threshold"])

            # Integration settings
            if "integration" in config:
                integration = config["integration"]
                if "ai_integration" in integration:
                    self.ai_integration_check.setChecked(integration["ai_integration"])
                if "automated_exploitation" in integration:
                    self.auto_exploitation_check.setChecked(integration["automated_exploitation"])
                if "realtime_adaptation" in integration:
                    self.realtime_adaptation_check.setChecked(integration["realtime_adaptation"])

            # UI state (optional)
            if "ui_state" in config:
                ui_state = config["ui_state"]
                if "active_tab" in ui_state:
                    self.tab_widget.setCurrentIndex(ui_state["active_tab"])
                if "window_geometry" in ui_state:
                    geo = ui_state["window_geometry"]
                    self.setGeometry(
                        geo.get("x", self.x()),
                        geo.get("y", self.y()),
                        geo.get("width", self.width()),
                        geo.get("height", self.height()),
                    )

            # Apply to research manager if available
            if self.research_manager:
                self._apply_config_to_manager(config)

        except Exception as e:
            logger.error(f"Failed to apply configuration: {e}")
            raise

    def _validate_configuration(self, config: dict) -> bool:
        """Validate configuration structure."""
        try:
            # Check required sections
            required_sections = ["research", "ml", "integration"]
            for section in required_sections:
                if section not in config:
                    logger.warning(f"Missing configuration section: {section}")
                    return False

            # Validate value ranges
            research = config.get("research", {})
            if "max_concurrent_campaigns" in research:
                if not 1 <= research["max_concurrent_campaigns"] <= 20:
                    return False

            ml = config.get("ml", {})
            if "confidence_threshold" in ml:
                if not 0 <= ml["confidence_threshold"] <= 100:
                    return False

            return True

        except Exception as e:
            logger.error(f"Configuration validation error: {e}")
            return False

    def _save_default_config(self, config: dict):
        """Save configuration to default location."""
        try:
            import os

            config_dir = os.path.expanduser("~/.intellicrack")
            os.makedirs(config_dir, exist_ok=True)

            config_file = os.path.join(config_dir, "vuln_research_config.json")

            import json
            with open(config_file, "w") as f:
                json.dump(config, f, indent=2)

            logger.info(f"Default configuration saved to: {config_file}")

        except Exception as e:
            logger.error(f"Failed to save default configuration: {e}")

    def _load_default_config(self) -> dict | None:
        """Load configuration from default location."""
        try:
            import os

            config_file = os.path.expanduser("~/.intellicrack/vuln_research_config.json")

            if not os.path.exists(config_file):
                return None

            import json
            with open(config_file) as f:
                return json.load(f)

        except Exception as e:
            logger.error(f"Failed to load default configuration: {e}")
            return None

    def _clear_default_config(self):
        """Clear default configuration file."""
        try:
            import os

            config_file = os.path.expanduser("~/.intellicrack/vuln_research_config.json")

            if os.path.exists(config_file):
                os.remove(config_file)
                logger.info("Default configuration cleared")

        except Exception as e:
            logger.error(f"Failed to clear default configuration: {e}")

    def _apply_config_to_manager(self, config: dict):
        """Apply configuration to research manager."""
        try:
            if not self.research_manager:
                return

            # Create manager config
            manager_config = {
                "max_concurrent_campaigns": config.get("research", {}).get("max_concurrent_campaigns", 5),
                "default_timeout": config.get("research", {}).get("default_timeout", 3600),
                "storage_directory": config.get("research", {}).get("storage_directory", "/tmp/intellicrack_research"),
                "ml_config": {
                    "min_samples": config.get("ml", {}).get("min_training_samples", 50),
                    "confidence_threshold": config.get("ml", {}).get("confidence_threshold", 70) / 100.0,
                },
            }

            # Apply to research manager
            self.research_manager.update_configuration(manager_config)

        except Exception as e:
            logger.error(f"Failed to apply config to manager: {e}")
