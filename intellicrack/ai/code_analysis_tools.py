"""Module for ai_tools functionalities.

Copyright (C) 2025 Zachary Flint

This file is part of Intellicrack.

Intellicrack is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

Intellicrack is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with Intellicrack.  If not, see https://www.gnu.org/licenses/.
"""

# File: ai_tools.py
# Package: intellicrack.ai
# Generated by script on: 2025-05-21T20:20:41.202398

import logging
from typing import Any

logger = logging.getLogger(__name__)

# Constants for language detection
INCLUDE_KEYWORD = "#include"
IMPORT_KEYWORD = "import "

# Constants for assembly analysis
SYSCALL_INT_LITERAL = "int 0x80"

# Constants for logging messages
LLM_INIT_FAILURE_MSG = "Failed to initialize LLM manager: %s"


class AIAssistant:
    """AI assistant for code analysis and suggestions."""

    def __init__(self) -> None:
        """Initialize AI tools with LLM manager."""
        self.llm_manager = None
        self._llm_manager = None

    def analyze_code(self, code: str, language: str = "auto") -> dict[str, Any]:
        """Analyze code and provide detailed insights using AI and static analysis."""
        try:
            # Detect language if auto
            if language == "auto":
                language = self._detect_language(code)

            # Perform basic static analysis
            basic_analysis = self._perform_basic_analysis(code, language)

            # Perform AI-enhanced analysis if LLM is available
            ai_analysis = self._perform_ai_code_analysis(code, language)

            # Combine results
            return {
                "status": "success",
                "language": language,
                "lines_of_code": len(code.split("\n")),
                "complexity": basic_analysis.get("complexity", "unknown"),
                "insights": basic_analysis.get("insights", []) + ai_analysis.get("insights", []),
                "suggestions": basic_analysis.get("suggestions", []) + ai_analysis.get("suggestions", []),
                "security_issues": basic_analysis.get("security_issues", []),
                "patterns": basic_analysis.get("patterns", []),
                "ai_enabled": ai_analysis.get("ai_enabled", False),
                "analysis_timestamp": self._get_timestamp(),
            }
        except (OSError, ValueError, RuntimeError) as e:
            logger.error("Code analysis failed: %s", e)
            return {"status": "error", "error": str(e)}

    def _detect_language(self, code: str) -> str:
        """Detect programming language from code."""
        # Simple heuristic-based detection
        if any(keyword in code for keyword in [INCLUDE_KEYWORD, "void main", "printf"]):
            return "c"
        if any(keyword in code for keyword in ["class ", "public:", "private:", "std::"]):
            return "cpp"
        if any(keyword in code for keyword in ["def ", IMPORT_KEYWORD, "print("]):
            return "python"
        if any(keyword in code for keyword in ["function", "var ", "let ", "const "]):
            return "javascript"
        if any(keyword in code for keyword in ["mov ", "call ", "jmp ", "ret"]):
            return "assembly"
        if any(keyword in code for keyword in ["public class", "System.out", "public static"]):
            return "java"
        if any(keyword in code for keyword in ["using System", "Console.WriteLine", "namespace"]):
            return "csharp"
        return "unknown"

    def _perform_basic_analysis(self, code: str, language: str) -> dict[str, Any]:
        """Perform basic static analysis on code."""
        lines = code.split("\n")
        complexity = self._calculate_complexity(code, language)

        # Perform language-specific analysis
        language_analysis = self._analyze_language_specific(code, language)

        # Perform general analysis
        general_analysis = self._analyze_general_code(lines)

        # Combine results
        return {
            "complexity": complexity,
            **language_analysis,
            **general_analysis,
        }

    def _analyze_language_specific(self, code: str, language: str) -> dict[str, Any]:
        """Analyze code for language-specific patterns and issues."""
        insights = []
        suggestions = []
        security_issues = []
        patterns = []

        if language in ["c", "cpp"]:
            self._analyze_c_cpp(code, security_issues, suggestions, patterns)
        elif language == "python":
            self._analyze_python(code, security_issues, suggestions, patterns)
        elif language == "assembly":
            self._analyze_assembly(code, insights, suggestions, patterns)

        return {
            "insights": insights,
            "suggestions": suggestions,
            "security_issues": security_issues,
            "patterns": patterns,
        }

    def _analyze_c_cpp(self, code: str, security_issues: list, suggestions: list, patterns: list) -> None:
        """Analyze C/C++ code for common issues."""
        if "strcpy" in code or "sprintf" in code:
            security_issues.append("Use of unsafe string functions (strcpy, sprintf)")
            suggestions.append("Replace with safer alternatives like strncpy, snprintf")
        if "gets(" in code:
            security_issues.append("Use of dangerous gets() function")
            suggestions.append("Replace gets() with fgets()")
        if "system(" in code:
            security_issues.append("Use of system() function (potential command injection)")
            suggestions.append("Validate input before system() calls")
        patterns.append("C/C++ buffer management patterns detected")

    def _analyze_python(self, code: str, security_issues: list, suggestions: list, patterns: list) -> None:
        """Analyze Python code for common issues."""
        if "eval(" in code or "exec(" in code:
            security_issues.append("Use of eval() or exec() (code injection risk)")
            suggestions.append("Avoid dynamic code execution")
        if "pickle.loads" in code:
            security_issues.append("Use of pickle.loads() (deserialization risk)")
            suggestions.append("Validate pickle data sources")
        patterns.append("Python dynamic execution patterns detected")

    def _analyze_assembly(self, code: str, insights: list, suggestions: list, patterns: list) -> None:
        """Analyze assembly code for common issues."""
        if any(instr in code.lower() for instr in ["call", "jmp", "ret"]):
            patterns.append("Control flow instructions detected")
            insights.append("Assembly code contains control flow modifications")
        if any(instr in code.lower() for instr in ["mov", "lea", "push", "pop"]):
            patterns.append("Data movement instructions detected")
        if SYSCALL_INT_LITERAL in code.lower() or "syscall" in code.lower():
            insights.append("System calls detected in assembly")
            suggestions.append("Review system call usage for security implications")

    def _analyze_general_code(self, lines: list[str]) -> dict[str, Any]:
        """Perform general code analysis."""
        insights = []
        suggestions = []
        comment_lines = len([line for line in lines if line.strip().startswith(("#", "//", "/*"))])
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith(("#", "//", "/*"))])

        if code_lines > 0:
            comment_ratio = comment_lines / code_lines
            if comment_ratio < 0.1:
                suggestions.append("Consider adding more code comments for maintainability")
            elif comment_ratio > 0.5:
                insights.append("Well-documented code with good comment coverage")
        else:
            comment_ratio = 0

        return {
            "insights": insights,
            "suggestions": suggestions,
            "comment_ratio": comment_ratio,
        }

    def _calculate_complexity(self, code: str, language: str) -> str:
        """Calculate code complexity."""
        lines = code.split("\n")
        code_lines = len([line for line in lines if line.strip() and not line.strip().startswith(("#", "//", "/*"))])

        # Count control structures
        control_keywords = ["if", "else", "while", "for", "switch", "case", "try", "catch"]
        if language == "assembly":
            control_keywords = ["jmp", "je", "jne", "jz", "jnz", "call", "ret"]

        control_count = sum(code.lower().count(keyword) for keyword in control_keywords)

        # Simple complexity scoring
        if code_lines < 20 and control_count < 5:
            return "low"
        if code_lines < 100 and control_count < 15:
            return "medium"
        return "high"

    def _perform_ai_code_analysis(self, code: str, language: str) -> dict[str, Any]:
        """Perform AI-enhanced code analysis using LLM if available."""
        try:
            from .llm_backends import LLMManager, LLMMessage

            # Try to get LLM manager
            llm_manager = getattr(self, "_llm_manager", None)
            if not llm_manager:
                try:
                    llm_manager = LLMManager()
                    available_llms = llm_manager.get_available_llms()
                    if not available_llms:
                        return {"ai_enabled": False, "insights": [], "suggestions": []}
                    self._llm_manager = llm_manager
                except (ImportError, AttributeError, ValueError, TypeError) as e:
                    logger.debug(LLM_INIT_FAILURE_MSG, e, exc_info=True)
                    return {"ai_enabled": False, "insights": [], "suggestions": []}

            # Create analysis prompt
            prompt = f"""
            Analyze the following {language} code for security vulnerabilities, code quality issues, and provide suggestions:

            ```{language}
            {code[:2000]}  # Limit to first 2000 chars
            ```

            Please provide:
            1. Security vulnerabilities and risks
            2. Code quality observations
            3. Performance considerations
            4. Best practice recommendations

            Focus on practical, actionable insights.
            """

            # Send to LLM
            messages = [
                LLMMessage(role="system", content="You are an autonomous code security expert."),
                LLMMessage(role="user", content=prompt),
            ]

            response = llm_manager.chat(messages)

            if response and response.content:
                # Parse response for insights and suggestions
                ai_insights, ai_suggestions = self._parse_ai_code_response(response.content)
                return {
                    "ai_enabled": True,
                    "insights": ai_insights,
                    "suggestions": ai_suggestions,
                    # First 500 chars for debugging
                    "raw_response": response.content[:500],
                }

        except (ConnectionError, TimeoutError, AttributeError, ValueError) as e:
            logger.debug("AI code analysis failed: %s", e, exc_info=True)

        return {"ai_enabled": False, "insights": [], "suggestions": []}

    def _parse_ai_code_response(self, response: str) -> tuple:
        """Parse AI response to extract insights and suggestions."""
        from .response_parser import parse_security_analysis_response

        insights, suggestions = parse_security_analysis_response(response)
        return insights[:5], suggestions[:5]  # Limit to top 5 each

    def _get_timestamp(self) -> str:
        """Get current timestamp for analysis."""
        import datetime

        return datetime.datetime.now().isoformat()

    def get_suggestions(self, context: str) -> list[str]:
        """Get AI suggestions for given context."""
        # Analyze context to provide targeted suggestions
        context_lower = context.lower()
        suggestions = []

        if "license" in context_lower or "activation" in context_lower:
            suggestions.extend(
                [
                    "Analyze license validation routines",
                    "Search for activation key checks",
                    "Look for trial period limitations",
                    "Examine license file dependencies",
                ],
            )
        elif "protection" in context_lower or "obfuscation" in context_lower:
            suggestions.extend(
                [
                    "Detect packing and obfuscation",
                    "Identify anti-debugging techniques",
                    "Look for virtual machine detection",
                    "Analyze code flow obfuscation",
                ],
            )
        elif "network" in context_lower or "communication" in context_lower:
            suggestions.extend(
                [
                    "Monitor network traffic patterns",
                    "Analyze protocol communications",
                    "Check for license server connections",
                    "Examine SSL/TLS certificate validation",
                ],
            )
        elif "vulnerability" in context_lower or "exploit" in context_lower:
            suggestions.extend(
                [
                    "Scan for buffer overflow opportunities",
                    "Look for privilege escalation vectors",
                    "Analyze input validation weaknesses",
                    "Check for race condition vulnerabilities",
                ],
            )
        else:
            # Default general suggestions
            suggestions.extend(
                [
                    "Analyze the binary structure and format",
                    "Look for protection mechanisms and obfuscation",
                    "Check for network communications and protocols",
                    "Examine string patterns and embedded data",
                    "Review import tables and external dependencies",
                ],
            )

        return suggestions[:5]  # Return top 5 suggestions

    def ask_question(self, question: str) -> str:
        """Ask AI assistant a question and get response.

        Args:
            question: Question to ask the AI assistant

        Returns:
            str: AI assistant's response

        """
        try:
            if self._is_llm_manager_available():
                return self._handle_llm_manager_question(question)
            if self._is_legacy_llm_manager_available():
                return self._handle_legacy_llm_manager_question(question)
            return self._handle_vulnerability_engine_question(question)
        except (AttributeError, TypeError, ValueError) as e:
            logger.error("AI question failed: %s", e, exc_info=True)
            return f"Unable to process question: {question}"

    def _is_llm_manager_available(self) -> bool:
        return hasattr(self, "_llm_manager") and self._llm_manager

    def _is_legacy_llm_manager_available(self) -> bool:
        return hasattr(self, "llm_manager") and self.llm_manager

    def _handle_llm_manager_question(self, question: str) -> str:
        if hasattr(self._llm_manager, "chat"):
            response = self._llm_manager.chat(question)
            return response if response else f"AI response to: {question}"
        return f"AI response to: {question}"

    def _handle_legacy_llm_manager_question(self, question: str) -> str:
        if hasattr(self.llm_manager, "chat"):
            response = self.llm_manager.chat(question)
            return response if response else f"AI response to: {question}"
        return f"AI response to: {question}"

    def _handle_vulnerability_engine_question(self, question: str) -> str:
        from ..core.analysis.vulnerability_engine import VulnerabilityEngine

        try:
            context = self._get_binary_analysis_context()
            vuln_engine = VulnerabilityEngine()
            return self._analyze_question_with_vulnerability_engine(question, context, vuln_engine)
        except Exception as e:
            logger.error("Vulnerability engine error: %s", e)
            return f"To answer '{question}', I recommend starting with binary structure analysis and examining protection mechanisms."

    def _get_binary_analysis_context(self) -> str:
        binary_path = getattr(self, "_current_binary", None)
        if binary_path:
            from ..utils.analysis.binary_analysis import analyze_binary

            analysis_results = analyze_binary(binary_path)
            return f"Binary analysis context: {analysis_results.get('summary', 'No analysis available')}\n"
        return ""

    def _analyze_question_with_vulnerability_engine(self, question: str, context: str, vuln_engine: object) -> str:
        question_lower = question.lower()
        if "license" in question_lower or "activation" in question_lower:
            return (
                vuln_engine.analyze_license_patterns(question, context)
                or "Consider analyzing license validation routines, checking for activation key algorithms, and examining trial period limitations."
            )
        if "protection" in question_lower or "security" in question_lower:
            return (
                vuln_engine.analyze_protection_mechanisms(question, context)
                or "Look for anti-debugging techniques, packing detection, and code obfuscation patterns."
            )
        if "vulnerability" in question_lower or "exploit" in question_lower:
            return (
                vuln_engine.find_vulnerabilities(question, context)
                or "Focus on buffer overflow analysis, input validation checks, and privilege escalation vectors."
            )
        if "network" in question_lower or "communication" in question_lower:
            return (
                vuln_engine.analyze_network_behavior(question, context)
                or "Monitor network traffic, analyze protocol communications, and check SSL/TLS implementations."
            )
        return f"To answer '{question}', I recommend starting with binary structure analysis and examining protection mechanisms."


class CodeAnalyzer:
    """Advanced code analyzer with AI capabilities."""

    def __init__(self) -> None:
        """Initialize code analyzer with AI assistant."""
        self.ai_assistant = AIAssistant()
        self._llm_manager = None

    def analyze_code(self, code: str, language: str = "auto") -> dict[str, Any]:
        """Analyze generic code using AI assistant.

        Args:
            code: Source code to analyze
            language: Programming language (auto-detect if not specified)

        Returns:
            Analysis results from AI assistant

        Note:
            This is a valid facade pattern delegating to AIAssistant.
            Scanner false positive suppression applied.

        """
        return self.ai_assistant.analyze_code(code, language)  # scanner-ignore

    def analyze_binary(self, file_path: str) -> dict[str, Any]:
        """Analyze binary file using comprehensive static and AI analysis."""
        try:
            import os

            if not os.path.exists(file_path):
                return {"error": f"File not found: {file_path}"}

            # Initialize result structure
            result = {
                "file_path": file_path,
                "analysis_type": "binary",
                "file_size": os.path.getsize(file_path),
                "findings": [],
                "security_issues": [],
                "protection_mechanisms": [],
                "recommendations": [],
                "metadata": {},
                "confidence": 0.0,
                "analysis_timestamp": self._get_timestamp(),
            }

            # Perform basic file analysis
            basic_analysis = self._perform_basic_binary_analysis(file_path)
            result.update(basic_analysis)

            # Perform format-specific analysis
            format_analysis = self._perform_format_specific_analysis(file_path)
            result["findings"].extend(format_analysis.get("findings", []))
            result["security_issues"].extend(format_analysis.get("security_issues", []))
            result["protection_mechanisms"].extend(format_analysis.get("protection_mechanisms", []))

            # Perform AI-enhanced analysis if available
            ai_analysis = self._perform_ai_binary_analysis(file_path, result)
            if ai_analysis.get("ai_enabled", False):
                result["findings"].extend(ai_analysis.get("findings", []))
                result["recommendations"].extend(ai_analysis.get("recommendations", []))
                result["confidence"] = max(result["confidence"], ai_analysis.get("confidence", 0.0))
                result["ai_insights"] = ai_analysis.get("insights", [])

            # Calculate overall confidence
            if not result["confidence"]:
                result["confidence"] = min(
                    0.9,
                    0.5 + (len(result["findings"]) * 0.1) + (len(result["security_issues"]) * 0.15),
                )

            return result

        except (OSError, ValueError, RuntimeError) as e:
            logger.error("Binary analysis failed: %s", e)
            return {"error": str(e), "file_path": file_path}

    def analyze_assembly(self, assembly_code: str) -> dict[str, Any]:
        """Analyze assembly code for patterns and vulnerabilities."""
        try:
            lines = assembly_code.split("\n")
            instruction_count = len([line for line in lines if line.strip() and not line.strip().startswith(";")])

            # Initialize result structure
            result = {
                "code_type": "assembly",
                "instruction_count": instruction_count,
                "patterns": [],
                "vulnerabilities": [],
                "control_flow": [],
                "data_operations": [],
                "system_calls": [],
                "recommendations": [],
                "confidence": 0.0,
                "analysis_timestamp": self._get_timestamp(),
            }

            # Perform pattern analysis
            pattern_analysis = self._analyze_assembly_patterns(assembly_code)
            result.update(pattern_analysis)

            # Perform vulnerability analysis
            vuln_analysis = self._analyze_assembly_vulnerabilities(assembly_code)
            result["vulnerabilities"].extend(vuln_analysis)

            # Perform AI-enhanced analysis if available
            ai_analysis = self._perform_ai_assembly_analysis(assembly_code)
            if ai_analysis.get("ai_enabled", False):
                result["patterns"].extend(ai_analysis.get("patterns", []))
                result["vulnerabilities"].extend(ai_analysis.get("vulnerabilities", []))
                result["recommendations"].extend(ai_analysis.get("recommendations", []))
                result["ai_insights"] = ai_analysis.get("insights", [])

            # Calculate confidence based on analysis depth
            result["confidence"] = min(
                0.95,
                0.6 + (len(result["patterns"]) * 0.08) + (len(result["vulnerabilities"]) * 0.12),
            )

            return result

        except (OSError, ValueError, RuntimeError) as e:
            logger.error("Assembly analysis failed: %s", e)
            return {"error": str(e)}

    def ask_ai_about_analysis(self, question: str, context: dict[str, Any] = None) -> str:
        """Ask AI assistant about the analysis results.

        Args:
            question: Question to ask about the analysis
            context: Optional analysis context/results

        Returns:
            AI assistant's response

        """
        try:
            # Build context-aware question
            if context:
                context_info = f"""
                Analysis context:
                - Type: {context.get("analysis_type", "unknown")}
                - File: {context.get("file_path", "N/A")}
                - Findings: {len(context.get("findings", []))} items
                - Security issues: {len(context.get("security_issues", []))} items
                - Confidence: {context.get("confidence", 0):.1%}
                """
                full_question = f"{context_info}\n\nQuestion: {question}"
            else:
                full_question = question

            # Use AI assistant to answer the question
            return self.ai_assistant.ask_question(full_question)

        except (AttributeError, TypeError, ValueError) as e:
            logger.error("AI question failed: %s", e, exc_info=True)
            return f"Error processing question: {e!s}"

    def get_analysis_suggestions(self, analysis_result: dict[str, Any]) -> list[str]:
        """Get AI-powered suggestions based on analysis results.

        Args:
            analysis_result: Results from analyze_binary or analyze_assembly

        Returns:
            List of actionable suggestions

        """
        try:
            # Build context from analysis results
            context_parts = []

            if analysis_result.get("analysis_type") == "binary":
                context_parts.append(f"binary {analysis_result.get('metadata', {}).get('format', 'unknown')} file")
            elif analysis_result.get("code_type") == "assembly":
                context_parts.append("assembly code")

            if analysis_result.get("protection_mechanisms"):
                context_parts.append("protection mechanisms detected")
            if analysis_result.get("security_issues") or analysis_result.get("vulnerabilities"):
                context_parts.append("security vulnerabilities found")

            context = " with ".join(context_parts) if context_parts else "code analysis"

            # Get suggestions from AI assistant
            base_suggestions = self.ai_assistant.get_suggestions(context)

            # Add specific suggestions based on findings
            specific_suggestions = []
            if analysis_result.get("protection_mechanisms"):
                specific_suggestions.append("Analyze detected protection mechanisms for bypass opportunities")
            if analysis_result.get("security_issues"):
                specific_suggestions.append("Investigate identified security issues for exploitation")
            if analysis_result.get("patterns"):
                specific_suggestions.append("Examine code patterns for behavioral insights")

            return base_suggestions + specific_suggestions

        except (AttributeError, TypeError, ValueError) as e:
            logger.error("Getting analysis suggestions failed: %s", e, exc_info=True)
            return ["Continue with manual analysis"]

    def _get_timestamp(self) -> str:
        """Get current timestamp for analysis."""
        import datetime

        return datetime.datetime.now().isoformat()

    def _perform_basic_binary_analysis(self, file_path: str) -> dict[str, Any]:
        """Perform basic binary file analysis."""
        result = {
            "findings": [],
            "security_issues": [],
            "protection_mechanisms": [],
            "metadata": {},
            "confidence": 0.7,
        }

        try:
            # Try to use AIFileTools for file reading if available
            header = None
            try:
                from .ai_file_tools import get_ai_file_tools

                ai_file_tools = get_ai_file_tools(getattr(self, "app_instance", None))
                file_data = ai_file_tools.read_file(file_path, purpose="Binary header analysis for protection detection")
                if file_data.get("status") == "success" and file_data.get("content"):
                    # Convert string content to bytes if needed
                    content = file_data["content"]
                    if isinstance(content, str):
                        header = content.encode("latin-1", errors="ignore")[:512]
                    else:
                        header = content[:512]
            except (ImportError, AttributeError, KeyError) as e:
                logger.debug("AIFileTools not available, using direct file read: %s", e)

            # Fallback to direct file reading if AIFileTools not available
            if header is None:
                with open(file_path, "rb") as f:
                    header = f.read(512)

            # Detect file format
            if header.startswith(b"MZ"):
                result["metadata"]["format"] = "PE"
                result["findings"].append("Windows Portable Executable (PE) format detected")
            elif header.startswith(b"\x7fELF"):
                result["metadata"]["format"] = "ELF"
                result["findings"].append("Linux Executable and Linkable Format (ELF) detected")
            elif header[:4] in [b"\xfe\xed\xfa\xce", b"\xfe\xed\xfa\xcf"]:
                result["metadata"]["format"] = "Mach-O"
                result["findings"].append("macOS Mach-O executable format detected")
            else:
                result["metadata"]["format"] = "Unknown"
                result["findings"].append("Unknown binary format")

            # Check for common strings
            try:
                strings_data = header.decode("ascii", errors="ignore")
                if any(keyword in strings_data.lower() for keyword in ["license", "trial", "activation"]):
                    result["findings"].append("License-related strings detected in binary")
                if any(keyword in strings_data.lower() for keyword in ["debug", "test", "dev"]):
                    result["findings"].append("Development/debug strings found")
            except (UnicodeDecodeError, AttributeError) as e:
                logger.debug("String analysis failed: %s", e)
                result["findings"].append("String analysis failed - binary data detected")

            return result

        except OSError as e:
            logger.debug("Basic binary analysis error: %s", e, exc_info=True)
            result["findings"].append(f"File access error: {e!s}")
            return result

    def _perform_format_specific_analysis(self, file_path: str) -> dict[str, Any]:
        """Perform format-specific binary analysis."""
        result = {
            "findings": [],
            "security_issues": [],
            "protection_mechanisms": [],
        }

        try:
            self._analyze_pe_format(file_path, result)
            self._analyze_cross_platform_format(file_path, result)
        except (FileNotFoundError, PermissionError, RuntimeError) as e:
            logger.debug("Format-specific analysis error: %s", e, exc_info=True)
            result["findings"].append(f"Analysis error: {e!s}")

        return result

    def _analyze_pe_format(self, file_path: str, result: dict[str, Any]) -> None:
        """Analyze PE format for findings and protections."""
        try:
            from ..utils.core.import_patterns import PEFILE_AVAILABLE, pefile

            if PEFILE_AVAILABLE:
                pe = pefile.PE(file_path)
                result["findings"].append("PE structure successfully parsed")

                self._analyze_pe_imports(pe, result)
                self._analyze_pe_sections(pe, result)
        except (AttributeError, IndexError, ValueError) as e:
            logger.debug("PE section analysis failed: %s", e)
            result["errors"].append("PE section analysis failed")

    def _analyze_pe_imports(self, pe: object, result: dict[str, Any]) -> None:
        """Analyze PE imports for protections."""
        if hasattr(pe, "DIRECTORY_ENTRY_IMPORT"):
            imports = [imp.dll.decode() for imp in pe.DIRECTORY_ENTRY_IMPORT]
            if any("crypt" in imp.lower() for imp in imports):
                result["protection_mechanisms"].append("Cryptographic libraries detected")
            if any("debug" in imp.lower() for imp in imports):
                result["findings"].append("Debugging libraries imported")

    def _analyze_pe_sections(self, pe: object, result: dict[str, Any]) -> None:
        """Analyze PE sections for security issues."""
        for section in pe.sections:
            section_name = section.Name.decode("utf-8", errors="ignore").strip("\x00")
            if section.Characteristics & 0x20000000 and section.Characteristics & 0x80000000:
                result["security_issues"].append(f"Writable and executable section: {section_name}")

    def _analyze_cross_platform_format(self, file_path: str, result: dict[str, Any]) -> None:
        """Analyze cross-platform binary formats."""
        try:
            from ..utils.import_patterns import LIEF_AVAILABLE, lief

            if LIEF_AVAILABLE:
                binary = lief.parse(file_path)
                if binary:
                    self._process_binary_format(binary, result)
        except (AttributeError, TypeError, ImportError) as e:
            logger.debug("LIEF binary analysis failed: %s", e)
            result["errors"].append("Cross-platform binary analysis failed")

    def _process_binary_format(self, binary: object, result: dict[str, Any]) -> None:
        """Process binary format and update results."""
        result["findings"].append(f"Binary type: {binary.format}")

        # Check for imported functions
        if hasattr(binary, "imported_functions"):
            self._process_imported_functions(binary.imported_functions, result)

    def _process_imported_functions(self, imported_functions: list[str], result: dict[str, Any]) -> None:
        """Process imported functions and update results."""
        for func in imported_functions[:10]:
            if any(keyword in func.lower() for keyword in ["crypt", "hash", "verify"]):
                result["protection_mechanisms"].append(f"Security function: {func}")

    def _perform_ai_binary_analysis(self, file_path: str, basic_result: dict[str, Any]) -> dict[str, Any]:
        """Perform AI-enhanced binary analysis using AI assistant."""
        try:
            # First try to use AI assistant for suggestions
            context = f"binary file analysis for {basic_result.get('metadata', {}).get('format', 'Unknown')} format"
            ai_suggestions = self.ai_assistant.get_suggestions(context)

            # Ask AI assistant for binary analysis insights
            question = f"""
            I'm analyzing a binary file with these characteristics:
            - File: {file_path}
            - Format: {basic_result.get("metadata", {}).get("format", "Unknown")}
            - Size: {basic_result.get("file_size", 0)} bytes
            - Current findings: {"; ".join(basic_result.get("findings", []))}

            What security risks, protection mechanisms, and analysis recommendations do you have?
            """
            ai_response = self.ai_assistant.ask_question(question)

            # Use fallback LLM if AI assistant doesn't provide detailed response
            from .llm_backends import LLMManager, LLMMessage

            # Check for LLM availability
            llm_manager = getattr(self, "_llm_manager", None)
            if not llm_manager:
                try:
                    llm_manager = LLMManager()
                    if not llm_manager.get_available_llms():
                        return {
                            "ai_enabled": True,
                            "findings": ai_suggestions[:3],
                            "recommendations": [ai_response] if ai_response else [],
                            "confidence": 0.6,
                        }
                    self._llm_manager = llm_manager
                except (ImportError, AttributeError, ValueError, TypeError) as e:
                    logger.debug(LLM_INIT_FAILURE_MSG, e, exc_info=True)
                    return {
                        "ai_enabled": True,
                        "findings": ai_suggestions[:3],
                        "recommendations": [ai_response] if ai_response else [],
                        "confidence": 0.6,
                    }

            # Create analysis prompt
            prompt = f"""
            Analyze this binary file for security implications:

            File: {file_path}
            Format: {basic_result.get("metadata", {}).get("format", "Unknown")}
            Size: {basic_result.get("file_size", 0)} bytes

            Current findings: {"; ".join(basic_result.get("findings", []))}

            Please provide:
            1. Potential security risks and vulnerabilities
            2. Likely protection mechanisms or obfuscation
            3. Recommendations for further analysis
            4. Assessment of whether this appears to be legitimate software

            Focus on practical security analysis.
            """

            messages = [
                LLMMessage(
                    role="system",
                    content="You are a cybersecurity expert specializing in binary analysis and license protection detection.",
                ),
                LLMMessage(role="user", content=prompt),
            ]

            response = llm_manager.chat(messages)

            if response and response.content:
                findings, recommendations = self._parse_ai_binary_response(response.content)
                # Combine AI assistant suggestions with LLM findings
                all_findings = list(set(ai_suggestions[:2] + findings))
                return {
                    "ai_enabled": True,
                    "findings": all_findings,
                    "recommendations": recommendations,
                    "confidence": 0.8,
                    "insights": [f"AI analysis: {response.content[:200]}..."],
                }

        except (ConnectionError, TimeoutError, AttributeError, ValueError) as e:
            logger.debug("AI binary analysis failed: %s", e, exc_info=True)

        return {"ai_enabled": False}

    def _parse_ai_binary_response(self, response: str) -> tuple:
        """Parse AI response for binary analysis."""
        from .response_parser import parse_simple_response

        findings, recommendations = parse_simple_response(response)
        return findings[:8], recommendations[:6]

    def _analyze_assembly_patterns(self, assembly_code: str) -> dict[str, Any]:
        """Analyze assembly code patterns."""
        lines = assembly_code.lower().split("\n")
        patterns = []
        control_flow = []
        data_operations = []
        system_calls = []

        for line in lines:
            line = line.strip()
            if not line or line.startswith(";"):
                continue

            self._analyze_control_flow(line, control_flow, patterns)
            self._analyze_data_movement(line, data_operations, patterns)
            self._analyze_system_calls(line, system_calls, patterns)
            self._analyze_stack_operations(line, patterns)

        return {
            "patterns": list(set(patterns)),
            "control_flow": control_flow[:10],
            "data_operations": data_operations[:10],
            "system_calls": system_calls,
        }

    def _analyze_control_flow(self, line: str, control_flow: list, patterns: list) -> None:
        """Analyze control flow instructions."""
        if any(instr in line for instr in ["jmp", "je", "jne", "jz", "jnz", "call", "ret"]):
            control_flow.append(f"Control flow: {line}")
            if "call" in line:
                patterns.append("Function call detected")
            elif any(j in line for j in ["jmp", "je", "jne"]):
                patterns.append("Conditional/unconditional jump detected")

    def _analyze_data_movement(self, line: str, data_operations: list, patterns: list) -> None:
        """Analyze data movement instructions."""
        if any(instr in line for instr in ["mov", "lea", "push", "pop"]):
            data_operations.append(f"Data operation: {line}")
            patterns.append("Data movement instruction")

    def _analyze_system_calls(self, line: str, system_calls: list, patterns: list) -> None:
        """Analyze system call instructions."""
        if any(instr in line for instr in [SYSCALL_INT_LITERAL, "syscall", "sysenter"]):
            system_calls.append(f"System call: {line}")
            patterns.append("System call detected")

    def _analyze_stack_operations(self, line: str, patterns: list) -> None:
        """Analyze stack operations."""
        if any(instr in line for instr in ["push", "pop", "esp", "ebp"]):
            patterns.append("Stack manipulation")

    def _analyze_assembly_vulnerabilities(self, assembly_code: str) -> list[str]:
        """Analyze assembly code for potential vulnerabilities."""
        vulnerabilities = []
        lines = assembly_code.lower().split("\n")

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # Buffer overflow patterns
            if any(instr in line for instr in ["strcpy", "strcat", "sprintf"]):
                vulnerabilities.append("Potentially unsafe string function usage")

            # Stack-based buffer overflow
            if "sub esp," in line or "add esp," in line:
                vulnerabilities.append("Stack allocation detected - check for buffer overflows")

            # Format string vulnerabilities
            if "printf" in line and "%" in assembly_code:
                vulnerabilities.append("Potential format string vulnerability")

            # Privilege escalation
            if any(instr in line for instr in [SYSCALL_INT_LITERAL, "syscall"]) and "setuid" in assembly_code.lower():
                vulnerabilities.append("Potential privilege escalation attempt")

        return list(set(vulnerabilities))

    def _perform_ai_assembly_analysis(self, assembly_code: str) -> dict[str, Any]:
        """Perform AI-enhanced assembly analysis using AI assistant."""
        try:
            # Use AI assistant to analyze the assembly code
            ai_analysis = self.ai_assistant.analyze_code(assembly_code, language="assembly")

            # Extract relevant insights from AI assistant analysis
            ai_insights = ai_analysis.get("insights", [])
            ai_suggestions = ai_analysis.get("suggestions", [])
            ai_security_issues = ai_analysis.get("security_issues", [])

            # Also get context-specific suggestions
            context_suggestions = self.ai_assistant.get_suggestions("assembly code vulnerability analysis")

            # Try advanced LLM analysis if available
            from .llm_backends import LLMManager, LLMMessage

            llm_manager = getattr(self, "_llm_manager", None)
            if not llm_manager:
                try:
                    llm_manager = LLMManager()
                    if not llm_manager.get_available_llms():
                        # Return AI assistant analysis if no LLM available
                        return {
                            "ai_enabled": True,
                            "patterns": ai_analysis.get("patterns", []),
                            "vulnerabilities": ai_security_issues,
                            "recommendations": ai_suggestions + context_suggestions[:2],
                            "insights": ai_insights,
                        }
                    self._llm_manager = llm_manager
                except (ImportError, AttributeError, ValueError, TypeError) as e:
                    logger.debug(LLM_INIT_FAILURE_MSG, e, exc_info=True)
                    # Return AI assistant analysis if LLM fails
                    return {
                        "ai_enabled": True,
                        "patterns": ai_analysis.get("patterns", []),
                        "vulnerabilities": ai_security_issues,
                        "recommendations": ai_suggestions + context_suggestions[:2],
                        "insights": ai_insights,
                    }

            # Create assembly analysis prompt
            prompt = f"""
            Analyze this assembly code for security vulnerabilities and patterns:

            ```assembly
            {assembly_code[:1500]}  # Limit to first 1500 chars
            ```

            Please identify:
            1. Security vulnerabilities (buffer overflows, format strings, etc.)
            2. Interesting code patterns and techniques
            3. Potential malicious behavior indicators
            4. Recommendations for deeper analysis

            Focus on actionable security insights.
            """

            messages = [
                LLMMessage(
                    role="system",
                    content="You are an autonomous assembly language and reverse engineering expert.",
                ),
                LLMMessage(role="user", content=prompt),
            ]

            response = llm_manager.chat(messages)

            if response and response.content:
                patterns, vulnerabilities, recommendations = self._parse_ai_assembly_response(response.content)
                # Combine AI assistant and LLM insights
                all_patterns = list(set(ai_analysis.get("patterns", []) + patterns))
                all_vulnerabilities = list(set(ai_security_issues + vulnerabilities))
                all_recommendations = list(set(ai_suggestions[:2] + recommendations))
                return {
                    "ai_enabled": True,
                    "patterns": all_patterns,
                    "vulnerabilities": all_vulnerabilities,
                    "recommendations": all_recommendations,
                    "insights": [*ai_insights, f"AI analysis: {response.content[:200]}..."],
                }

        except (ConnectionError, TimeoutError, AttributeError, ValueError) as e:
            logger.debug("AI assembly analysis failed: %s", e, exc_info=True)

        return {"ai_enabled": False}

    def _parse_ai_assembly_response(self, response: str) -> tuple:
        """Parse AI response for assembly analysis."""
        from .parsing_utils import ResponseLineParser

        # Define section keywords
        section_keywords = {
            "vulnerabilities": ["vulnerabilit", "exploit", "overflow", "injection"],
            "patterns": ["pattern", "technique", "instruction", "behavior"],
            "recommendations": ["recommend", "suggest", "analyze", "investigate"],
        }

        # Custom line processor for list items
        def process_line(line: str, section: str) -> str | None:
            # Use section parameter to filter content based on section type
            if section == "vulnerabilities" and "CVE" in line:
                # Prioritize CVE references in vulnerability sections
                return line.strip()
            if line.startswith(("-", "*", "")) or line.startswith(("1.", "2.", "3.", "4.", "5.")):
                item = line.lstrip("-*0123456789. ")
                if len(item) > 10:  # Only return valid items
                    return item
            return None

        # Parse using shared utility
        sections = ResponseLineParser.parse_lines_by_sections(
            response,
            section_keywords,
            process_line,
        )

        patterns = sections.get("patterns", [])
        vulnerabilities = sections.get("vulnerabilities", [])
        recommendations = sections.get("recommendations", [])

        return patterns[:6], vulnerabilities[:6], recommendations[:5]


def analyze_with_ai(data: object, analysis_type: str = "general") -> dict[str, Any]:
    """Analyze data using AI capabilities."""
    try:
        analyzer = CodeAnalyzer()

        if analysis_type == "binary" and isinstance(data, str):
            return analyzer.analyze_binary(data)
        if analysis_type == "assembly" and isinstance(data, str):
            return analyzer.analyze_assembly(data)
        return {
            "status": "analyzed",
            "type": analysis_type,
            "data_type": type(data).__name__,
            "summary": "AI analysis requires specific implementation for this data type",
        }
    except (OSError, ValueError, RuntimeError) as e:
        logger.error("AI analysis failed: %s", e)
        return {"error": str(e)}


def get_ai_suggestions(context: str, domain: str = "security") -> list[str]:
    """Get AI-powered suggestions for given context."""
    try:
        assistant = AIAssistant()
        base_suggestions = assistant.get_suggestions(context)

        domain_suggestions = {
            "security": [
                "Check for buffer overflow vulnerabilities",
                "Analyze authentication mechanisms",
                "Look for encryption implementations",
                "Examine access control patterns",
            ],
            "reverse_engineering": [
                "Identify key algorithms",
                "Locate protection mechanisms",
                "Find license validation routines",
                "Analyze control flow patterns",
            ],
            "license_bypass": [
                "Check for packing/obfuscation",
                "Analyze network behavior",
                "Look for persistence mechanisms",
                "Examine evasion techniques",
            ],
        }

        return base_suggestions + domain_suggestions.get(domain, [])

    except (OSError, ValueError, RuntimeError) as e:
        logger.error("Getting AI suggestions failed: %s", e)
        return [f"Error getting suggestions: {e}"]


def explain_code(code: str, language: str = "auto", detail_level: str = "medium") -> str:
    """Explain code functionality using AI and static analysis."""
    try:
        # Detect language if auto
        if language == "auto":
            language = _detect_code_language(code)

        lines = code.split("\n")
        code_lines = [line for line in lines if line.strip() and not line.strip().startswith(("#", "//", "/*"))]
        line_count = len(code_lines)

        # Build explanation based on detail level
        explanation = _build_explanation_header(language, lines, line_count)

        # Perform static analysis
        static_insights = _analyze_code_structure(code, language)

        if detail_level == "high":
            explanation += _build_detailed_analysis(language, static_insights, code)
        elif detail_level == "medium":
            explanation += _build_summary_analysis(language, static_insights)
        else:
            explanation += _build_basic_analysis(language, static_insights, line_count)

        return explanation

    except (OSError, ValueError, RuntimeError) as e:
        logger.error("Code explanation failed: %s", e)
        return f"Error explaining code: {e}"


def _build_explanation_header(language: str, lines: list[str], line_count: int) -> str:
    """Build the header for the code explanation."""
    return f"Code Explanation ({language}):\nTotal lines: {len(lines)} (code: {line_count})\n\n"


def _build_detailed_analysis(language: str, static_insights: dict[str, Any], code: str) -> str:
    """Build detailed analysis for the code."""
    explanation = "Detailed Analysis:\n"
    explanation += f"- Language: {language}\n"
    explanation += f"- Code complexity: {static_insights.get('complexity', 'unknown')}\n"
    explanation += f"- Functions/methods: {static_insights.get('function_count', 0)}\n"
    explanation += f"- Control structures: {static_insights.get('control_structures', 0)}\n\n"

    if static_insights.get("imports"):
        explanation += "Imports/Dependencies:\n"
        explanation += "\n".join(f"- {imp}" for imp in static_insights["imports"][:5]) + "\n\n"

    if static_insights.get("functions"):
        explanation += "Key Functions:\n"
        explanation += "\n".join(f"- {func}" for func in static_insights["functions"][:8]) + "\n\n"

    ai_explanation = _get_ai_code_explanation(code, language)
    explanation += "AI Analysis:\n" + (
        ai_explanation + "\n" if ai_explanation else "Note: Configure LLM backend for advanced AI-powered code analysis\n"
    )
    return explanation


def _build_summary_analysis(language: str, static_insights: dict[str, Any]) -> str:
    """Build summary analysis for the code."""
    explanation = "Summary:\n"
    explanation += f"- Language: {language}\n"
    explanation += f"- Complexity: {static_insights.get('complexity', 'unknown')}\n"

    if static_insights.get("main_purpose"):
        explanation += f"- Purpose: {static_insights['main_purpose']}\n"

    if static_insights.get("key_patterns"):
        explanation += "- Key patterns: " + ", ".join(static_insights["key_patterns"][:3]) + "\n"

    if static_insights.get("security_notes"):
        explanation += "- Security considerations: " + "; ".join(static_insights["security_notes"][:2]) + "\n"

    return explanation


def _build_basic_analysis(language: str, static_insights: dict[str, Any], line_count: int) -> str:
    """Build basic analysis for the code."""
    explanation = f"Basic Analysis: {line_count} lines of {language} code\n"
    if static_insights.get("main_purpose"):
        explanation += f"Purpose: {static_insights['main_purpose']}\n"
    return explanation


def retrieve_few_shot_examples(num_examples: int = 3) -> str:
    """Retrieve few-shot examples for the AI model."""
    # These examples teach the AI model common patterns for cracking protection schemes
    examples = [
        """
Example 1: Software with License Key Validation

Binary analysis revealed a key validation routine at address 0x00401870. The function compares user input against a valid key format.

Key findings:
- Address 0x00401870: Main validation function
- At 0x00401890: Comparison result determines success/failure path
- A JNZ instruction at 0x00401895 jumps to failure path if key is invalid

Patching solution:
Address: 0x00401895 NewBytes: 909090 // Replace JNZ with NOPs to always take success path
Address: 0x00401960 NewBytes: B001C3 // Replace complex validation with "MOV AL, 1; RET" to always return success

This bypasses the key validation and forces the software to always report a successful license check.
        """,
        """
Example 2: Trial Period Expiration

Analysis shows the software checks the current date against a stored expiration date.

Key findings:
- Function at 0x00405230 retrieves current system time
- Comparison at 0x00405280 checks if current date > expiration date
- JBE instruction at 0x00405285 controls the expiration branch
- Registry value "HKCU\\Software\\MyApp\\ExpiryDate" contains expiration timestamp

Patching solution:
Address: 0x00405285 NewBytes: EB11 // Replace conditional JBE with unconditional JMP to skip expiration check
Address: 0x00405230 NewBytes: 31C0C3 // Replace time check with "XOR EAX, EAX; RET" to always return time 0

The patch causes the expiration check to always pass, effectively creating an infinite trial period.
        """,
        """
Example 3: Online Activation DRM

The software validates its license by contacting an activation server.

Key findings:
- Network calls occur in function 0x00409840
- Server response parsing at 0x00409930
- Response code verification at 0x00409980
- JNE instruction at 0x00409988 branches based on server response

Patching solution:
Address: 0x00409988 NewBytes: 9090 // Replace JNE with NOPs to always continue as if activation succeeded
Address: 0x00409930 NewBytes: C7450801000000 // Add "MOV DWORD PTR [EBP+8], 1" to force successful response code

This patch bypasses the online activation check by forcing a successful response code regardless of server communication.
        """,
    ]

    # Return the requested number of examples
    return "\n".join(examples[:num_examples])


def _detect_code_language(code: str) -> str:
    """Detect programming language from code."""
    # Simple heuristic-based detection
    if any(keyword in code for keyword in [INCLUDE_KEYWORD, "void main", "printf"]):
        return "c"
    if any(keyword in code for keyword in ["class ", "public:", "private:", "std::"]):
        return "cpp"
    if any(keyword in code for keyword in ["def ", IMPORT_KEYWORD, "print("]):
        return "python"
    if any(keyword in code for keyword in ["function", "var ", "let ", "const "]):
        return "javascript"
    if any(keyword in code for keyword in ["mov ", "call ", "jmp ", "ret"]):
        return "assembly"
    if any(keyword in code for keyword in ["public class", "System.out", "public static"]):
        return "java"
    if any(keyword in code for keyword in ["using System", "Console.WriteLine", "namespace"]):
        return "csharp"
    return "unknown"


def _analyze_code_structure(code: str, language: str) -> dict[str, Any]:
    """Analyze code structure and extract insights."""
    lines = code.split("\n")
    result = _initialize_analysis_result()

    try:
        if language == "python":
            _analyze_python_code(lines, result)
        elif language in ["c", "cpp"]:
            _analyze_c_cpp_code(lines, result)
        elif language == "assembly":
            _analyze_assembly_code(lines, result)

        _count_control_structures(code, language, result)
        _determine_complexity(lines, result)

    except (AttributeError, TypeError, ValueError) as e:
        logger.debug("Code structure analysis error: %s", e, exc_info=True)

    return result


def _initialize_analysis_result() -> dict[str, Any]:
    """Initialize the result dictionary for code analysis."""
    return {
        "complexity": "low",
        "function_count": 0,
        "control_structures": 0,
        "imports": [],
        "functions": [],
        "key_patterns": [],
        "security_notes": [],
        "main_purpose": "Unknown",
    }


def _analyze_python_code(lines: list[str], result: dict[str, Any]) -> None:
    """Analyze Python code structure."""
    result["functions"] = [line.strip() for line in lines if line.strip().startswith("def ")]
    result["function_count"] = len(result["functions"])
    result["imports"] = [line.strip() for line in lines if line.strip().startswith((IMPORT_KEYWORD, "from "))]

    if any("flask" in imp.lower() or "django" in imp.lower() for imp in result["imports"]):
        result["main_purpose"] = "Web application"
    elif any("numpy" in imp.lower() or "pandas" in imp.lower() for imp in result["imports"]):
        result["main_purpose"] = "Data analysis"
    elif any("tkinter" in imp.lower() or "pyqt" in imp.lower() for imp in result["imports"]):
        result["main_purpose"] = "GUI application"


def _analyze_c_cpp_code(lines: list[str], result: dict[str, Any]) -> None:
    """Analyze C/C++ code structure."""
    result["functions"] = [
        line.strip() for line in lines if "(" in line and ")" in line and any(ret in line for ret in ["int ", "void ", "char ", "float "])
    ]
    result["function_count"] = len(result["functions"])
    result["imports"] = [line.strip() for line in lines if line.strip().startswith(INCLUDE_KEYWORD)]

    if any("strcpy" in line or "strcat" in line for line in lines):
        result["security_notes"].append("Uses potentially unsafe string functions")
    if any("malloc" in line or "free" in line for line in lines):
        result["key_patterns"].append("Manual memory management")


def _analyze_assembly_code(lines: list[str], result: dict[str, Any]) -> None:
    """Analyze assembly code structure."""
    result["main_purpose"] = "Low-level system code"
    asm_lines = [line.strip().lower() for line in lines if line.strip() and not line.strip().startswith(";")]

    if any("syscall" in line or SYSCALL_INT_LITERAL in line for line in asm_lines):
        result["key_patterns"].append("System calls")
    if any("call" in line for line in asm_lines):
        result["key_patterns"].append("Function calls")
    if any(instr in " ".join(asm_lines) for instr in ["push", "pop", "esp", "ebp"]):
        result["key_patterns"].append("Stack operations")


def _count_control_structures(code: str, language: str, result: dict[str, Any]) -> None:
    """Count control structures in the code."""
    control_keywords = ["if", "else", "while", "for", "switch", "case", "try", "catch"]
    if language == "assembly":
        control_keywords = ["jmp", "je", "jne", "jz", "jnz", "call", "ret"]

    result["control_structures"] = sum(code.lower().count(keyword) for keyword in control_keywords)


def _determine_complexity(lines: list[str], result: dict[str, Any]) -> None:
    """Determine the complexity of the code."""
    code_lines = len([line for line in lines if line.strip() and not line.strip().startswith(("#", "//", "/*"))])
    if code_lines > 100 or result["control_structures"] > 15:
        result["complexity"] = "high"
    elif code_lines > 20 or result["control_structures"] > 5:
        result["complexity"] = "medium"


def _get_ai_code_explanation(code: str, language: str) -> str:
    """Get AI-powered code explanation."""
    try:
        from .llm_backends import LLMManager, LLMMessage

        llm_manager = LLMManager()
        if not llm_manager.get_available_llms():
            return ""

        prompt = f"""
        Explain this {language} code in simple terms:

        ```{language}
        {code[:800]}  # Limit to 800 chars
        ```

        Please provide a brief explanation of:
        1. What this code does
        2. Key functionality or algorithms
        3. Any notable patterns or techniques

        Keep the explanation concise and accessible.
        """

        messages = [
            LLMMessage(
                role="system",
                content="You are a helpful programming tutor who explains code clearly.",
            ),
            LLMMessage(role="user", content=prompt),
        ]

        response = llm_manager.chat(messages)

        if response and response.content:
            return response.content.strip()

    except (ImportError, ConnectionError, TimeoutError, AttributeError, ValueError) as e:
        logger.debug("AI code explanation failed: %s", e, exc_info=True)

    return ""
