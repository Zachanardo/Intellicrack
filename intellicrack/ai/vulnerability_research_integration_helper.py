"""Helper methods for VulnerabilityResearchAI class learning system."""

import json
import logging
import os
from typing import Any

logger = logging.getLogger(__name__)


def update_strategy_weights(learning_entry: dict[str, Any]) -> None:
    """Update strategy weights based on learning entry results."""
    # Load or initialize strategy weights
    weights_path = os.path.join(os.path.dirname(__file__), "..", "..", "data", "strategy_weights.json")
    os.makedirs(os.path.dirname(weights_path), exist_ok=True)

    # Load existing weights
    weights = {}
    if os.path.exists(weights_path):
        try:
            with open(weights_path) as f:
                weights = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            weights = {}

    # Initialize weights if needed
    if "exploit_types" not in weights:
        weights["exploit_types"] = {}
    if "evasion_levels" not in weights:
        weights["evasion_levels"] = {}
    if "platforms" not in weights:
        weights["platforms"] = {}

    # Update weights based on success/failure
    success_multiplier = 1.05 if learning_entry["success"] else 0.95

    # Update exploit type weight
    exploit_type = learning_entry.get("exploit_type", "unknown")
    if exploit_type not in weights["exploit_types"]:
        weights["exploit_types"][exploit_type] = 1.0
    weights["exploit_types"][exploit_type] *= success_multiplier

    # Update evasion level weight
    evasion_level = learning_entry.get("evasion_level", "unknown")
    if evasion_level not in weights["evasion_levels"]:
        weights["evasion_levels"][evasion_level] = 1.0
    weights["evasion_levels"][evasion_level] *= success_multiplier

    # Update platform weight
    platform = learning_entry.get("platform", "unknown")
    if platform not in weights["platforms"]:
        weights["platforms"][platform] = 1.0
    weights["platforms"][platform] *= success_multiplier

    # Normalize weights to prevent drift
    for category in ["exploit_types", "evasion_levels", "platforms"]:
        if weights[category]:
            max_weight = max(weights[category].values())
            if max_weight > 2.0:
                # Normalize if weights get too high
                for key in weights[category]:
                    weights[category][key] /= max_weight / 1.5

    # Save updated weights
    with open(weights_path, "w") as f:
        json.dump(weights, f, indent=2)

    logger.debug(f"Updated strategy weights for {exploit_type}/{evasion_level}/{platform}")


def update_pattern_recognition(learning_entry: dict[str, Any]) -> None:
    """Update pattern recognition based on learning entry."""
    # Load or initialize pattern database
    patterns_path = os.path.join(os.path.dirname(__file__), "..", "..", "data", "ai_patterns.json")
    os.makedirs(os.path.dirname(patterns_path), exist_ok=True)

    # Load existing patterns
    patterns = {}
    if os.path.exists(patterns_path):
        try:
            with open(patterns_path) as f:
                patterns = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            patterns = {}

    # Initialize pattern categories if needed
    if "successful_combinations" not in patterns:
        patterns["successful_combinations"] = []
    if "failed_combinations" not in patterns:
        patterns["failed_combinations"] = []
    if "protection_bypasses" not in patterns:
        patterns["protection_bypasses"] = {}

    # Create pattern entry
    pattern = {
        "timestamp": learning_entry["timestamp"],
        "platform": learning_entry.get("platform", "unknown"),
        "protections": learning_entry.get("protections", []),
        "exploit_type": learning_entry.get("exploit_type", "unknown"),
        "evasion_level": learning_entry.get("evasion_level", "unknown"),
        "phases_succeeded": learning_entry.get("phases_succeeded", []),
        "phases_failed": learning_entry.get("phases_failed", []),
        "execution_time": learning_entry.get("execution_time", 0),
    }

    # Add to appropriate pattern list
    if learning_entry["success"]:
        patterns["successful_combinations"].append(pattern)

        # Track successful protection bypasses
        for protection in learning_entry.get("protections", []):
            if protection not in patterns["protection_bypasses"]:
                patterns["protection_bypasses"][protection] = []
            patterns["protection_bypasses"][protection].append(
                {
                    "exploit_type": learning_entry.get("exploit_type"),
                    "evasion_level": learning_entry.get("evasion_level"),
                    "timestamp": learning_entry["timestamp"],
                },
            )
    else:
        patterns["failed_combinations"].append(pattern)

    # Keep only recent patterns (last 5000 each)
    if len(patterns["successful_combinations"]) > 5000:
        patterns["successful_combinations"] = patterns["successful_combinations"][-5000:]
    if len(patterns["failed_combinations"]) > 5000:
        patterns["failed_combinations"] = patterns["failed_combinations"][-5000:]

    # Limit protection bypass history
    for protection in patterns["protection_bypasses"]:
        if len(patterns["protection_bypasses"][protection]) > 100:
            patterns["protection_bypasses"][protection] = patterns["protection_bypasses"][protection][-100:]

    # Save updated patterns
    with open(patterns_path, "w") as f:
        json.dump(patterns, f, indent=2)

    logger.debug(f"Updated pattern recognition with {'successful' if learning_entry['success'] else 'failed'} pattern")
