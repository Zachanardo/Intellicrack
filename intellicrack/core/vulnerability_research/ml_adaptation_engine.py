"""
Machine Learning Adaptation Engine

Implements intelligent adaptation and optimization of exploitation techniques
using machine learning models and feedback loops.
"""

import logging
import os
import time
from enum import Enum
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

# Try to import ML libraries
try:
    import pandas as pd
    from sklearn.cluster import KMeans
    from sklearn.ensemble import GradientBoostingRegressor, RandomForestClassifier
    from sklearn.metrics import accuracy_score, classification_report
    from sklearn.model_selection import cross_val_score, train_test_split
    from sklearn.preprocessing import LabelEncoder, StandardScaler
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False


class AdaptationStrategy(Enum):
    """ML adaptation strategies"""
    EXPLOIT_OPTIMIZATION = "exploit_optimization"
    VULNERABILITY_PREDICTION = "vulnerability_prediction"
    EVASION_ADAPTATION = "evasion_adaptation"
    PAYLOAD_EVOLUTION = "payload_evolution"
    TARGET_PROFILING = "target_profiling"


class ModelType(Enum):
    """Supported ML model types"""
    RANDOM_FOREST = "random_forest"
    GRADIENT_BOOSTING = "gradient_boosting"
    NEURAL_NETWORK = "neural_network"
    CLUSTERING = "clustering"
    REINFORCEMENT = "reinforcement"


class MLAdaptationEngine:
    """
    Machine learning adaptation engine for intelligent exploitation optimization.
    """

    def __init__(self):
        self.logger = logging.getLogger("IntellicrackLogger.MLAdaptationEngine")

        # ML models registry
        self.models = {}
        self.scalers = {}
        self.encoders = {}

        # Training data storage
        self.training_data = {
            'exploit_success': [],
            'vulnerability_features': [],
            'evasion_effectiveness': [],
            'payload_performance': [],
            'target_characteristics': []
        }

        # Adaptation configuration
        self.config = {
            'min_training_samples': 50,
            'model_retrain_threshold': 100,
            'confidence_threshold': 0.7,
            'adaptation_rate': 0.1,
            'feature_importance_threshold': 0.05,
            'model_persistence_dir': '/tmp/intellicrack_ml_models'
        }

        # Feature extractors
        self.feature_extractors = {
            'binary_features': self._extract_binary_features,
            'network_features': self._extract_network_features,
            'system_features': self._extract_system_features,
            'exploit_features': self._extract_exploit_features,
            'temporal_features': self._extract_temporal_features
        }

        # Adaptation strategies
        self.adaptation_strategies = {
            AdaptationStrategy.EXPLOIT_OPTIMIZATION: self._adapt_exploit_strategy,
            AdaptationStrategy.VULNERABILITY_PREDICTION: self._adapt_vulnerability_prediction,
            AdaptationStrategy.EVASION_ADAPTATION: self._adapt_evasion_techniques,
            AdaptationStrategy.PAYLOAD_EVOLUTION: self._adapt_payload_generation,
            AdaptationStrategy.TARGET_PROFILING: self._adapt_target_profiling
        }

        # Performance metrics
        self.metrics = {
            'adaptations_performed': 0,
            'success_rate_improvement': 0.0,
            'model_accuracy': {},
            'feature_importance': {},
            'adaptation_history': []
        }

        # Initialize ML components
        self._initialize_ml_components()

    def adapt_exploitation_strategy(self,
                                  target_info: Dict[str, Any],
                                  previous_attempts: List[Dict[str, Any]],
                                  strategy: AdaptationStrategy = AdaptationStrategy.EXPLOIT_OPTIMIZATION) -> Dict[str, Any]:
        """
        Adapt exploitation strategy based on ML analysis.
        
        Args:
            target_info: Information about target system
            previous_attempts: Historical exploitation attempts
            strategy: Adaptation strategy to use
            
        Returns:
            Adapted exploitation recommendations
        """
        result = {
            'success': False,
            'strategy': strategy.value,
            'adaptations': {},
            'confidence': 0.0,
            'recommendations': [],
            'model_insights': {},
            'error': None
        }

        try:
            self.logger.info(f"Adapting exploitation strategy: {strategy.value}")

            if not ML_AVAILABLE:
                result['error'] = "ML libraries not available"
                return result

            # Extract features from target and attempts
            features = self._extract_comprehensive_features(target_info, previous_attempts)

            # Apply adaptation strategy
            if strategy in self.adaptation_strategies:
                adaptation_func = self.adaptation_strategies[strategy]
                adaptations = adaptation_func(features, target_info, previous_attempts)
                result['adaptations'] = adaptations

                # Calculate confidence based on model predictions
                result['confidence'] = self._calculate_adaptation_confidence(features, adaptations)

                # Generate recommendations
                result['recommendations'] = self._generate_adaptation_recommendations(
                    strategy, adaptations, result['confidence']
                )

                # Get model insights
                result['model_insights'] = self._get_model_insights(features, strategy)

                # Update training data with new attempt
                self._update_training_data(target_info, previous_attempts, adaptations)

                # Check if models need retraining
                if self._should_retrain_models():
                    self._retrain_models()

                result['success'] = True
                self.metrics['adaptations_performed'] += 1

                # Log adaptation
                self._log_adaptation(strategy, adaptations, result['confidence'])

            else:
                result['error'] = f"Unknown adaptation strategy: {strategy.value}"

            self.logger.info(f"Adaptation completed with confidence: {result['confidence']:.2f}")

        except Exception as e:
            self.logger.error(f"Adaptation failed: {e}")
            result['error'] = str(e)

        return result

    def train_adaptation_models(self, training_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Train or retrain ML adaptation models.
        
        Args:
            training_data: Optional external training data
            
        Returns:
            Training results and model performance
        """
        result = {
            'success': False,
            'models_trained': [],
            'performance_metrics': {},
            'feature_importance': {},
            'training_samples': 0,
            'error': None
        }

        try:
            self.logger.info("Training adaptation models")

            if not ML_AVAILABLE:
                result['error'] = "ML libraries not available"
                return result

            # Use provided data or internal training data
            data = training_data if training_data else self.training_data

            # Check minimum training samples
            total_samples = sum(len(samples) for samples in data.values())
            if total_samples < self.config['min_training_samples']:
                result['error'] = f"Insufficient training data: {total_samples} < {self.config['min_training_samples']}"
                return result

            result['training_samples'] = total_samples

            # Train exploit success prediction model
            if len(data['exploit_success']) > 0:
                exploit_model_result = self._train_exploit_success_model(data['exploit_success'])
                if exploit_model_result['success']:
                    result['models_trained'].append('exploit_success')
                    result['performance_metrics']['exploit_success'] = exploit_model_result['metrics']
                    result['feature_importance']['exploit_success'] = exploit_model_result['feature_importance']

            # Train vulnerability prediction model
            if len(data['vulnerability_features']) > 0:
                vuln_model_result = self._train_vulnerability_model(data['vulnerability_features'])
                if vuln_model_result['success']:
                    result['models_trained'].append('vulnerability_prediction')
                    result['performance_metrics']['vulnerability_prediction'] = vuln_model_result['metrics']
                    result['feature_importance']['vulnerability_prediction'] = vuln_model_result['feature_importance']

            # Train evasion effectiveness model
            if len(data['evasion_effectiveness']) > 0:
                evasion_model_result = self._train_evasion_model(data['evasion_effectiveness'])
                if evasion_model_result['success']:
                    result['models_trained'].append('evasion_effectiveness')
                    result['performance_metrics']['evasion_effectiveness'] = evasion_model_result['metrics']
                    result['feature_importance']['evasion_effectiveness'] = evasion_model_result['feature_importance']

            # Train payload performance model
            if len(data['payload_performance']) > 0:
                payload_model_result = self._train_payload_model(data['payload_performance'])
                if payload_model_result['success']:
                    result['models_trained'].append('payload_performance')
                    result['performance_metrics']['payload_performance'] = payload_model_result['metrics']
                    result['feature_importance']['payload_performance'] = payload_model_result['feature_importance']

            # Train target clustering model
            if len(data['target_characteristics']) > 0:
                cluster_model_result = self._train_clustering_model(data['target_characteristics'])
                if cluster_model_result['success']:
                    result['models_trained'].append('target_clustering')
                    result['performance_metrics']['target_clustering'] = cluster_model_result['metrics']

            # Save trained models
            self._save_models()

            # Update metrics
            self.metrics['model_accuracy'] = result['performance_metrics']
            self.metrics['feature_importance'] = result['feature_importance']

            result['success'] = len(result['models_trained']) > 0

            self.logger.info(f"Model training completed: {len(result['models_trained'])} models trained")

        except Exception as e:
            self.logger.error(f"Model training failed: {e}")
            result['error'] = str(e)

        return result

    def predict_exploitation_success(self,
                                   target_info: Dict[str, Any],
                                   exploit_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Predict likelihood of exploitation success.
        
        Args:
            target_info: Target system information
            exploit_config: Exploit configuration
            
        Returns:
            Success prediction and confidence
        """
        prediction = {
            'success_probability': 0.0,
            'confidence': 0.0,
            'risk_factors': [],
            'recommendations': [],
            'model_used': None,
            'feature_analysis': {},
            'error': None
        }

        try:
            if not ML_AVAILABLE or 'exploit_success' not in self.models:
                prediction['error'] = "Exploit success model not available"
                return prediction

            # Extract features
            features = self._extract_exploit_prediction_features(target_info, exploit_config)

            # Make prediction
            model = self.models['exploit_success']
            scaler = self.scalers.get('exploit_success')

            if scaler:
                features_scaled = scaler.transform([features])
            else:
                features_scaled = [features]

            # Get probability prediction
            proba = model.predict_proba(features_scaled)[0]
            prediction['success_probability'] = float(proba[1]) if len(proba) > 1 else float(proba[0])

            # Calculate prediction confidence
            prediction['confidence'] = max(proba) - min(proba) if len(proba) > 1 else abs(proba[0] - 0.5) * 2

            # Analyze feature importance
            if hasattr(model, 'feature_importances_'):
                prediction['feature_analysis'] = self._analyze_feature_importance(
                    features, model.feature_importances_
                )

            # Identify risk factors
            prediction['risk_factors'] = self._identify_risk_factors(features, target_info)

            # Generate recommendations
            prediction['recommendations'] = self._generate_success_recommendations(
                prediction['success_probability'], prediction['risk_factors']
            )

            prediction['model_used'] = 'exploit_success'

        except Exception as e:
            self.logger.error(f"Success prediction failed: {e}")
            prediction['error'] = str(e)

        return prediction

    def optimize_payload_parameters(self,
                                  payload_type: str,
                                  target_info: Dict[str, Any],
                                  performance_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Optimize payload parameters using ML insights.
        
        Args:
            payload_type: Type of payload to optimize
            target_info: Target system information
            performance_history: Historical payload performance
            
        Returns:
            Optimized parameters and recommendations
        """
        optimization = {
            'optimized_parameters': {},
            'expected_improvement': 0.0,
            'confidence': 0.0,
            'parameter_analysis': {},
            'recommendations': [],
            'error': None
        }

        try:
            if not ML_AVAILABLE or 'payload_performance' not in self.models:
                optimization['error'] = "Payload performance model not available"
                return optimization

            # Extract current payload features
            current_features = self._extract_payload_features(payload_type, target_info)

            # Analyze performance history
            performance_analysis = self._analyze_payload_performance_history(performance_history)

            # Use model to predict optimal parameters
            model = self.models['payload_performance']

            # Generate parameter variations
            parameter_variations = self._generate_parameter_variations(current_features)

            # Predict performance for each variation
            best_performance = 0.0
            best_parameters = current_features

            for variation in parameter_variations:
                predicted_performance = self._predict_payload_performance(model, variation)
                if predicted_performance > best_performance:
                    best_performance = predicted_performance
                    best_parameters = variation

            # Calculate improvement
            baseline_performance = self._predict_payload_performance(model, current_features)
            optimization['expected_improvement'] = best_performance - baseline_performance

            # Extract optimized parameters
            optimization['optimized_parameters'] = self._extract_parameter_differences(
                current_features, best_parameters
            )

            # Calculate confidence
            optimization['confidence'] = self._calculate_optimization_confidence(
                current_features, best_parameters, model
            )

            # Analyze parameter importance
            optimization['parameter_analysis'] = self._analyze_parameter_importance(
                current_features, best_parameters
            )

            # Generate recommendations
            optimization['recommendations'] = self._generate_optimization_recommendations(
                optimization['optimized_parameters'], optimization['expected_improvement']
            )

        except Exception as e:
            self.logger.error(f"Payload optimization failed: {e}")
            optimization['error'] = str(e)

        return optimization

    def cluster_targets(self, target_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Cluster targets based on characteristics for strategic grouping.
        
        Args:
            target_data: List of target information
            
        Returns:
            Clustering results and target groups
        """
        clustering = {
            'clusters': {},
            'cluster_characteristics': {},
            'target_assignments': {},
            'optimization_strategies': {},
            'error': None
        }

        try:
            if not ML_AVAILABLE:
                clustering['error'] = "ML libraries not available"
                return clustering

            if len(target_data) < 3:
                clustering['error'] = "Insufficient targets for clustering"
                return clustering

            # Extract features from all targets
            feature_matrix = []
            target_ids = []

            for i, target in enumerate(target_data):
                features = self._extract_target_clustering_features(target)
                feature_matrix.append(features)
                target_ids.append(target.get('id', f'target_{i}'))

            # Standardize features
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(feature_matrix)

            # Determine optimal number of clusters
            n_clusters = min(len(target_data) // 2, 10)
            n_clusters = max(n_clusters, 2)

            # Perform clustering
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            cluster_labels = kmeans.fit_predict(features_scaled)

            # Store clustering model
            self.models['target_clustering'] = kmeans
            self.scalers['target_clustering'] = scaler

            # Organize results by cluster
            for i, (target_id, cluster_id) in enumerate(zip(target_ids, cluster_labels)):
                cluster_id = int(cluster_id)

                if cluster_id not in clustering['clusters']:
                    clustering['clusters'][cluster_id] = []

                clustering['clusters'][cluster_id].append({
                    'target_id': target_id,
                    'target_data': target_data[i],
                    'features': feature_matrix[i]
                })

                clustering['target_assignments'][target_id] = cluster_id

            # Analyze cluster characteristics
            for cluster_id, targets in clustering['clusters'].items():
                characteristics = self._analyze_cluster_characteristics(targets)
                clustering['cluster_characteristics'][cluster_id] = characteristics

                # Generate optimization strategies for each cluster
                optimization_strategy = self._generate_cluster_optimization_strategy(
                    characteristics, targets
                )
                clustering['optimization_strategies'][cluster_id] = optimization_strategy

        except Exception as e:
            self.logger.error(f"Target clustering failed: {e}")
            clustering['error'] = str(e)

        return clustering

    def get_adaptation_insights(self) -> Dict[str, Any]:
        """Get insights from ML adaptation engine."""
        insights = {
            'model_status': {},
            'performance_metrics': self.metrics.copy(),
            'feature_importance': {},
            'adaptation_trends': [],
            'recommendations': []
        }

        try:
            # Model status
            for model_name in self.models:
                insights['model_status'][model_name] = {
                    'trained': True,
                    'last_updated': getattr(self.models[model_name], 'last_updated', 'unknown'),
                    'training_samples': getattr(self.models[model_name], 'n_samples', 'unknown')
                }

            # Feature importance analysis
            for model_name, model in self.models.items():
                if hasattr(model, 'feature_importances_'):
                    insights['feature_importance'][model_name] = {
                        'top_features': self._get_top_features(model.feature_importances_),
                        'importance_distribution': model.feature_importances_.tolist()
                    }

            # Adaptation trends
            insights['adaptation_trends'] = self._analyze_adaptation_trends()

            # Generate strategic recommendations
            insights['recommendations'] = self._generate_strategic_recommendations(insights)

        except Exception as e:
            self.logger.error(f"Failed to get adaptation insights: {e}")
            insights['error'] = str(e)

        return insights

    def _initialize_ml_components(self):
        """Initialize ML components and load existing models."""
        try:
            # Create model persistence directory
            os.makedirs(self.config['model_persistence_dir'], exist_ok=True)

            # Try to load existing models
            self._load_models()

            self.logger.info("ML adaptation engine initialized")

        except Exception as e:
            self.logger.warning(f"ML initialization failed: {e}")

    def _load_models(self):
        """Load pre-trained ML models from disk."""
        try:
            import os
            import pickle

            model_dir = self.config['model_persistence_dir']

            # Load exploit success predictor
            exploit_model_path = os.path.join(model_dir, 'exploit_success_model.pkl')
            if os.path.exists(exploit_model_path):
                with open(exploit_model_path, 'rb') as f:
                    self.models['exploit_success'] = pickle.load(f)
                self.logger.info("Loaded exploit success prediction model")

            # Load vulnerability predictor
            vuln_model_path = os.path.join(model_dir, 'vulnerability_predictor.pkl')
            if os.path.exists(vuln_model_path):
                with open(vuln_model_path, 'rb') as f:
                    self.models['vulnerability_predictor'] = pickle.load(f)
                self.logger.info("Loaded vulnerability prediction model")

            # Load evasion effectiveness model
            evasion_model_path = os.path.join(model_dir, 'evasion_effectiveness.pkl')
            if os.path.exists(evasion_model_path):
                with open(evasion_model_path, 'rb') as f:
                    self.models['evasion_effectiveness'] = pickle.load(f)
                self.logger.info("Loaded evasion effectiveness model")

            # Load scalers and encoders
            scaler_path = os.path.join(model_dir, 'feature_scalers.pkl')
            if os.path.exists(scaler_path):
                with open(scaler_path, 'rb') as f:
                    self.scalers = pickle.load(f)
                self.logger.info("Loaded feature scalers")

            encoder_path = os.path.join(model_dir, 'label_encoders.pkl')
            if os.path.exists(encoder_path):
                with open(encoder_path, 'rb') as f:
                    self.encoders = pickle.load(f)
                self.logger.info("Loaded label encoders")

        except Exception as e:
            self.logger.debug(f"Model loading skipped (expected on first run): {e}")
            # Initialize default models if loading fails
            self._initialize_default_models()

    def _initialize_default_models(self):
        """Initialize default ML models when no pre-trained models exist."""
        try:
            # Create simple default models
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.preprocessing import StandardScaler

            # Default exploit success predictor
            self.models['exploit_success'] = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )

            # Default vulnerability predictor
            self.models['vulnerability_predictor'] = RandomForestClassifier(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )

            # Default evasion effectiveness model
            self.models['evasion_effectiveness'] = RandomForestClassifier(
                n_estimators=50,
                max_depth=8,
                random_state=42
            )

            # Initialize scalers
            self.scalers['feature_scaler'] = StandardScaler()

            self.logger.info("Initialized default ML models")

        except ImportError:
            self.logger.warning("scikit-learn not available - ML features disabled")
        except Exception as e:
            self.logger.error(f"Failed to initialize default models: {e}")

    def _extract_comprehensive_features(self, target_info: Dict[str, Any],
                                      previous_attempts: List[Dict[str, Any]]) -> List[float]:
        """Extract comprehensive feature set for ML analysis."""
        features = []

        # Binary features
        features.extend(self.feature_extractors['binary_features'](target_info))

        # Network features
        features.extend(self.feature_extractors['network_features'](target_info))

        # System features
        features.extend(self.feature_extractors['system_features'](target_info))

        # Exploit features from previous attempts
        features.extend(self.feature_extractors['exploit_features'](previous_attempts))

        # Temporal features
        features.extend(self.feature_extractors['temporal_features'](previous_attempts))

        return features

    def _extract_binary_features(self, target_info: Dict[str, Any]) -> List[float]:
        """Extract binary-related features."""
        features = []

        # Architecture features
        arch = target_info.get('architecture', 'unknown')
        features.append(1.0 if arch == 'x64' else 0.0)
        features.append(1.0 if arch == 'x86' else 0.0)
        features.append(1.0 if arch == 'arm' else 0.0)

        # Protection features
        protections = target_info.get('protections', [])
        features.append(1.0 if 'aslr' in protections else 0.0)
        features.append(1.0 if 'dep' in protections else 0.0)
        features.append(1.0 if 'canary' in protections else 0.0)
        features.append(1.0 if 'cfi' in protections else 0.0)
        features.append(1.0 if 'pie' in protections else 0.0)

        # Binary size (normalized)
        binary_size = target_info.get('binary_size', 0)
        features.append(min(binary_size / 1000000.0, 1.0))  # Normalize to MB

        # Function count (normalized)
        function_count = target_info.get('function_count', 0)
        features.append(min(function_count / 1000.0, 1.0))

        return features

    def _extract_network_features(self, target_info: Dict[str, Any]) -> List[float]:
        """Extract network-related features."""
        features = []

        # Service features
        services = target_info.get('services', [])
        features.append(len(services) / 10.0)  # Normalized service count

        # Common service indicators
        features.append(1.0 if any('http' in s.lower() for s in services) else 0.0)
        features.append(1.0 if any('ssh' in s.lower() for s in services) else 0.0)
        features.append(1.0 if any('ftp' in s.lower() for s in services) else 0.0)
        features.append(1.0 if any('smb' in s.lower() for s in services) else 0.0)

        # Network configuration
        network_config = target_info.get('network_config', {})
        features.append(1.0 if network_config.get('firewall_enabled') else 0.0)
        features.append(1.0 if network_config.get('nat_traversal_required') else 0.0)

        return features

    def _extract_system_features(self, target_info: Dict[str, Any]) -> List[float]:
        """Extract system-level features."""
        features = []

        # OS features
        os_type = target_info.get('os_type', 'unknown')
        features.append(1.0 if 'windows' in os_type.lower() else 0.0)
        features.append(1.0 if 'linux' in os_type.lower() else 0.0)
        features.append(1.0 if 'macos' in os_type.lower() else 0.0)

        # Version information (simplified)
        os_version = target_info.get('os_version', '')
        features.append(1.0 if 'server' in os_version.lower() else 0.0)
        features.append(1.0 if any(str(i) in os_version for i in range(2020, 2025)) else 0.0)  # Recent version

        # System resources
        features.append(min(target_info.get('cpu_cores', 1) / 16.0, 1.0))
        features.append(min(target_info.get('memory_gb', 1) / 64.0, 1.0))

        # Security features
        av_products = target_info.get('av_products', [])
        features.append(len(av_products) / 5.0)  # Normalized AV count
        features.append(1.0 if any('defender' in av.lower() for av in av_products) else 0.0)

        return features

    def _extract_exploit_features(self, previous_attempts: List[Dict[str, Any]]) -> List[float]:
        """Extract exploit-related features from previous attempts."""
        features = []

        if not previous_attempts:
            return [0.0] * 10  # Return zeros if no attempts

        # Success rate
        successful_attempts = sum(1 for attempt in previous_attempts if attempt.get('success', False))
        features.append(successful_attempts / len(previous_attempts))

        # Attempt diversity
        exploit_types = set(attempt.get('exploit_type', 'unknown') for attempt in previous_attempts)
        features.append(len(exploit_types) / 10.0)  # Normalized diversity

        # Average attempt duration
        durations = [attempt.get('duration', 0) for attempt in previous_attempts]
        avg_duration = sum(durations) / len(durations) if durations else 0
        features.append(min(avg_duration / 3600.0, 1.0))  # Normalized to hours

        # Payload complexity (simplified)
        payload_sizes = [attempt.get('payload_size', 0) for attempt in previous_attempts]
        avg_payload_size = sum(payload_sizes) / len(payload_sizes) if payload_sizes else 0
        features.append(min(avg_payload_size / 10000.0, 1.0))  # Normalized

        # Evasion techniques used
        evasion_techniques = set()
        for attempt in previous_attempts:
            evasion_techniques.update(attempt.get('evasion_techniques', []))
        features.append(len(evasion_techniques) / 20.0)  # Normalized

        # Recent success indicator
        recent_attempts = previous_attempts[-5:] if len(previous_attempts) >= 5 else previous_attempts
        recent_success = sum(1 for attempt in recent_attempts if attempt.get('success', False))
        features.append(recent_success / len(recent_attempts) if recent_attempts else 0.0)

        # Error patterns
        error_types = set(attempt.get('error_type', 'none') for attempt in previous_attempts if not attempt.get('success', False))
        features.append(len(error_types) / 10.0)  # Normalized error diversity

        # Protection bypass success
        bypass_attempts = [attempt for attempt in previous_attempts if attempt.get('protection_bypass_attempted', False)]
        bypass_success = sum(1 for attempt in bypass_attempts if attempt.get('protection_bypass_success', False))
        features.append(bypass_success / len(bypass_attempts) if bypass_attempts else 0.0)

        # Timing analysis
        timestamps = [attempt.get('timestamp', time.time()) for attempt in previous_attempts]
        if len(timestamps) > 1:
            time_span = max(timestamps) - min(timestamps)
            features.append(min(time_span / 86400.0, 1.0))  # Normalized to days
        else:
            features.append(0.0)

        # Escalation success
        escalation_attempts = [attempt for attempt in previous_attempts if attempt.get('escalation_attempted', False)]
        escalation_success = sum(1 for attempt in escalation_attempts if attempt.get('escalation_success', False))
        features.append(escalation_success / len(escalation_attempts) if escalation_attempts else 0.0)

        return features

    def _extract_temporal_features(self, previous_attempts: List[Dict[str, Any]]) -> List[float]:
        """Extract temporal patterns from attempts."""
        features = []

        if not previous_attempts:
            return [0.0] * 5

        # Time-based patterns
        timestamps = [attempt.get('timestamp', time.time()) for attempt in previous_attempts]

        # Attempt frequency
        if len(timestamps) > 1:
            time_span = max(timestamps) - min(timestamps)
            frequency = len(timestamps) / max(time_span / 3600.0, 1.0)  # Attempts per hour
            features.append(min(frequency / 10.0, 1.0))  # Normalized
        else:
            features.append(0.0)

        # Time since last attempt
        if timestamps:
            time_since_last = time.time() - max(timestamps)
            features.append(min(time_since_last / 86400.0, 1.0))  # Normalized to days
        else:
            features.append(1.0)

        # Success trend (recent vs older)
        if len(previous_attempts) >= 4:
            half_point = len(previous_attempts) // 2
            older_success = sum(1 for attempt in previous_attempts[:half_point] if attempt.get('success', False))
            recent_success = sum(1 for attempt in previous_attempts[half_point:] if attempt.get('success', False))

            older_rate = older_success / half_point
            recent_rate = recent_success / (len(previous_attempts) - half_point)
            features.append(recent_rate - older_rate)  # Trend indicator
        else:
            features.append(0.0)

        # Complexity trend
        complexities = [attempt.get('complexity_score', 0.5) for attempt in previous_attempts]
        if len(complexities) >= 2:
            complexity_trend = complexities[-1] - complexities[0]
            features.append(complexity_trend)
        else:
            features.append(0.0)

        # Persistence of approach
        exploit_types = [attempt.get('exploit_type', 'unknown') for attempt in previous_attempts]
        if exploit_types:
            most_common_type = max(set(exploit_types), key=exploit_types.count)
            persistence = exploit_types.count(most_common_type) / len(exploit_types)
            features.append(persistence)
        else:
            features.append(0.0)

        return features

    # Adaptation strategy implementations

    def _adapt_exploit_strategy(self, features: List[float], target_info: Dict[str, Any],
                               previous_attempts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Adapt exploit strategy based on ML analysis."""
        adaptations = {
            'exploit_type_recommendation': 'buffer_overflow',
            'payload_modifications': {},
            'evasion_adjustments': {},
            'timing_recommendations': {},
            'success_probability': 0.0
        }

        # Log target info for debugging
        self.logger.debug(f"Adapting exploit strategy for target: {target_info.get('binary_name', 'unknown')}")
        
        # Use target_info to adjust recommendations
        if target_info.get('architecture') == 'x64':
            adaptations['exploit_type_recommendation'] = 'rop_chain'  # Better for x64
        elif target_info.get('architecture') == 'arm':
            adaptations['exploit_type_recommendation'] = 'ret2libc'  # Common on ARM
            
        # Check for specific protections in target_info
        if target_info.get('has_canary', False):
            adaptations['evasion_adjustments']['bypass_canary'] = True
        if target_info.get('has_pie', False):
            adaptations['payload_modifications']['info_leak_required'] = True

        try:
            if 'exploit_success' in self.models:
                model = self.models['exploit_success']
                scaler = self.scalers.get('exploit_success')

                # Predict success probability
                if scaler:
                    features_scaled = scaler.transform([features])
                else:
                    features_scaled = [features]

                success_prob = model.predict_proba(features_scaled)[0]
                adaptations['success_probability'] = float(success_prob[1]) if len(success_prob) > 1 else float(success_prob[0])

                # Analyze failed attempts for patterns
                failed_attempts = [attempt for attempt in previous_attempts if not attempt.get('success', False)]

                if failed_attempts:
                    # Identify common failure patterns
                    failure_analysis = self._analyze_failure_patterns(failed_attempts)

                    # Recommend alternative exploit types
                    if failure_analysis['common_failure'] == 'protection_bypass':
                        adaptations['exploit_type_recommendation'] = 'rop_chain'
                        adaptations['evasion_adjustments']['bypass_dep'] = True
                        adaptations['evasion_adjustments']['bypass_aslr'] = True
                    elif failure_analysis['common_failure'] == 'payload_detection':
                        adaptations['payload_modifications']['encoding'] = 'polymorphic'
                        adaptations['payload_modifications']['obfuscation'] = 'advanced'
                    elif failure_analysis['common_failure'] == 'timing':
                        adaptations['timing_recommendations']['delay_execution'] = True
                        adaptations['timing_recommendations']['randomize_timing'] = True

        except Exception as e:
            self.logger.debug(f"Exploit strategy adaptation failed: {e}")

        return adaptations

    def _adapt_vulnerability_prediction(self, features: List[float], target_info: Dict[str, Any],
                                      previous_attempts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Adapt vulnerability prediction approach."""
        adaptations = {
            'vulnerability_types_to_focus': [],
            'analysis_depth_adjustment': 'medium',
            'search_strategy': 'comprehensive',
            'priority_functions': []
        }

        try:
            # Analyze target characteristics to predict likely vulnerability types
            protections = target_info.get('protections', [])

            # Recommend vulnerability types based on protections
            if 'aslr' not in protections:
                adaptations['vulnerability_types_to_focus'].append('buffer_overflow')
            if 'dep' not in protections:
                adaptations['vulnerability_types_to_focus'].append('stack_overflow')
            if 'canary' not in protections:
                adaptations['vulnerability_types_to_focus'].append('stack_smashing')

            # Adjust analysis depth based on previous success
            successful_attempts = [attempt for attempt in previous_attempts if attempt.get('success', False)]
            if len(successful_attempts) / max(len(previous_attempts), 1) < 0.3:
                adaptations['analysis_depth_adjustment'] = 'deep'
            elif len(successful_attempts) / max(len(previous_attempts), 1) > 0.7:
                adaptations['analysis_depth_adjustment'] = 'light'

            # Recommend search strategy
            if target_info.get('binary_size', 0) > 10000000:  # Large binary
                adaptations['search_strategy'] = 'targeted'
                # Focus on high-risk functions
                adaptations['priority_functions'] = ['strcpy', 'sprintf', 'gets', 'memcpy']
            else:
                adaptations['search_strategy'] = 'comprehensive'

        except Exception as e:
            self.logger.debug(f"Vulnerability prediction adaptation failed: {e}")

        return adaptations

    def _adapt_evasion_techniques(self, features: List[float], target_info: Dict[str, Any],
                                previous_attempts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Adapt evasion techniques based on detection patterns."""
        adaptations = {
            'recommended_evasions': [],
            'avoid_techniques': [],
            'detection_risk_level': 'medium',
            'stealth_adjustments': {}
        }

        # Use features to assess detection risk level
        if features and len(features) > 0:
            # Use first few features as indicators of complexity/risk
            avg_feature_value = sum(features[:5]) / min(len(features), 5)
            if avg_feature_value > 0.7:
                adaptations['detection_risk_level'] = 'high'
                self.logger.debug(f"High detection risk based on feature analysis: {avg_feature_value:.2f}")
            elif avg_feature_value < 0.3:
                adaptations['detection_risk_level'] = 'low'
                self.logger.debug(f"Low detection risk based on feature analysis: {avg_feature_value:.2f}")

        try:
            # Analyze AV products and adjust evasions
            av_products = target_info.get('av_products', [])

            if any('defender' in av.lower() for av in av_products):
                adaptations['recommended_evasions'].extend(['amsi_bypass', 'etw_bypass'])
                adaptations['avoid_techniques'].append('powershell_execution')

            if any('symantec' in av.lower() for av in av_products):
                adaptations['recommended_evasions'].append('behavioral_evasion')
                adaptations['stealth_adjustments']['execution_delay'] = True

            # Analyze previous detection patterns
            detected_attempts = [attempt for attempt in previous_attempts if attempt.get('detected', False)]

            if len(detected_attempts) / max(len(previous_attempts), 1) > 0.5:
                adaptations['detection_risk_level'] = 'high'
                adaptations['recommended_evasions'].extend(['process_hollowing', 'dll_sideloading'])
                adaptations['stealth_adjustments']['anti_analysis'] = True
            elif len(detected_attempts) / max(len(previous_attempts), 1) < 0.2:
                adaptations['detection_risk_level'] = 'low'
                adaptations['stealth_adjustments']['minimal_evasion'] = True

        except Exception as e:
            self.logger.debug(f"Evasion adaptation failed: {e}")

        return adaptations

    def _adapt_payload_generation(self, features: List[float], target_info: Dict[str, Any],
                                previous_attempts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Adapt payload generation parameters."""
        adaptations = {
            'encoding_recommendation': 'polymorphic',
            'size_optimization': False,
            'architecture_specific': {},
            'obfuscation_level': 'medium'
        }

        # Use features to determine obfuscation level
        if features and len(features) > 0:
            # Higher feature values suggest more complex environment
            complexity_score = sum(features) / len(features)
            if complexity_score > 0.7:
                adaptations['obfuscation_level'] = 'high'
                adaptations['encoding_recommendation'] = 'metamorphic'
                self.logger.debug(f"High complexity environment detected: {complexity_score:.2f}")
            elif complexity_score < 0.3:
                adaptations['obfuscation_level'] = 'low'
                adaptations['encoding_recommendation'] = 'xor'
                self.logger.debug(f"Low complexity environment detected: {complexity_score:.2f}")

        try:
            # Analyze payload performance history
            payload_attempts = [attempt for attempt in previous_attempts if 'payload_size' in attempt]

            if payload_attempts:
                # Analyze size vs success correlation
                successful_payloads = [attempt for attempt in payload_attempts if attempt.get('success', False)]
                failed_payloads = [attempt for attempt in payload_attempts if not attempt.get('success', False)]

                if successful_payloads and failed_payloads:
                    avg_successful_size = sum(p['payload_size'] for p in successful_payloads) / len(successful_payloads)
                    avg_failed_size = sum(p['payload_size'] for p in failed_payloads) / len(failed_payloads)

                    if avg_successful_size < avg_failed_size:
                        adaptations['size_optimization'] = True

            # Architecture-specific adaptations
            arch = target_info.get('architecture', 'x86')
            if arch == 'x64':
                adaptations['architecture_specific']['use_64bit_addresses'] = True
                adaptations['architecture_specific']['register_usage'] = 'extended'
            elif arch == 'arm':
                adaptations['architecture_specific']['thumb_mode'] = True
                adaptations['architecture_specific']['cache_management'] = True

            # Adjust obfuscation based on detection history
            detected_count = sum(1 for attempt in previous_attempts if attempt.get('detected', False))
            detection_rate = detected_count / max(len(previous_attempts), 1)

            if detection_rate > 0.6:
                adaptations['obfuscation_level'] = 'maximum'
                adaptations['encoding_recommendation'] = 'metamorphic'
            elif detection_rate < 0.2:
                adaptations['obfuscation_level'] = 'minimal'
                adaptations['encoding_recommendation'] = 'xor'

        except Exception as e:
            self.logger.debug(f"Payload adaptation failed: {e}")

        return adaptations

    def _adapt_target_profiling(self, features: List[float], target_info: Dict[str, Any],
                              previous_attempts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Adapt target profiling and reconnaissance approach."""
        adaptations = {
            'profiling_depth': 'standard',
            'focus_areas': [],
            'reconnaissance_techniques': [],
            'stealth_level': 'medium'
        }

        # Use features to assess target complexity and adjust profiling approach
        if features and len(features) > 0:
            # Feature-based complexity assessment
            feature_complexity = sum(features) / len(features)
            self.logger.debug(f"Target profiling complexity score from features: {feature_complexity:.2f}")
            
            # Adjust reconnaissance techniques based on features
            if feature_complexity > 0.6:
                adaptations['reconnaissance_techniques'].append('advanced_fingerprinting')
                adaptations['profiling_depth'] = 'deep'

        try:
            # Determine profiling depth based on target complexity
            services = target_info.get('services', [])
            protections = target_info.get('protections', [])

            complexity_score = len(services) + len(protections) * 2

            if complexity_score > 15:
                adaptations['profiling_depth'] = 'deep'
                adaptations['focus_areas'].extend(['service_enumeration', 'protection_analysis'])
            elif complexity_score < 5:
                adaptations['profiling_depth'] = 'light'
                adaptations['focus_areas'].append('basic_enumeration')
            else:
                adaptations['profiling_depth'] = 'standard'
                adaptations['focus_areas'].extend(['service_analysis', 'vulnerability_scanning'])

            # Adjust stealth based on detection history
            if any(attempt.get('detected', False) for attempt in previous_attempts):
                adaptations['stealth_level'] = 'high'
                adaptations['reconnaissance_techniques'].extend(['passive_scanning', 'osint_gathering'])
            else:
                adaptations['stealth_level'] = 'medium'
                adaptations['reconnaissance_techniques'].extend(['active_scanning', 'version_detection'])

        except Exception as e:
            self.logger.debug(f"Target profiling adaptation failed: {e}")

        return adaptations

    # Additional helper methods for analysis and prediction

    def _analyze_failure_patterns(self, failed_attempts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze patterns in failed exploitation attempts."""
        analysis = {
            'common_failure': 'unknown',
            'failure_frequency': {},
            'patterns': []
        }

        # Count failure types
        failure_types = [attempt.get('failure_type', 'unknown') for attempt in failed_attempts]
        for failure_type in failure_types:
            analysis['failure_frequency'][failure_type] = analysis['failure_frequency'].get(failure_type, 0) + 1

        # Identify most common failure
        if analysis['failure_frequency']:
            analysis['common_failure'] = max(analysis['failure_frequency'], key=analysis['failure_frequency'].get)

        return analysis

    def _calculate_adaptation_confidence(self, features: List[float], adaptations: Dict[str, Any]) -> float:
        """Calculate confidence in adaptation recommendations."""
        base_confidence = 0.5

        # Increase confidence based on model availability
        if 'exploit_success' in self.models:
            base_confidence += 0.2
        if 'vulnerability_prediction' in self.models:
            base_confidence += 0.1
        if 'evasion_effectiveness' in self.models:
            base_confidence += 0.1

        # Adjust based on feature completeness
        feature_completeness = len([f for f in features if f > 0]) / len(features)
        confidence_adjustment = feature_completeness * 0.2

        return min(1.0, base_confidence + confidence_adjustment)

    def _generate_adaptation_recommendations(self, strategy: AdaptationStrategy,
                                           adaptations: Dict[str, Any],
                                           confidence: float) -> List[str]:
        """Generate actionable recommendations based on adaptations."""
        recommendations = []

        if strategy == AdaptationStrategy.EXPLOIT_OPTIMIZATION:
            if adaptations.get('success_probability', 0) < 0.3:
                recommendations.append("Low success probability - consider alternative exploitation approach")
            if adaptations.get('exploit_type_recommendation') != 'buffer_overflow':
                recommendations.append(f"Switch to {adaptations['exploit_type_recommendation']} exploitation technique")

        elif strategy == AdaptationStrategy.EVASION_ADAPTATION:
            evasions = adaptations.get('recommended_evasions', [])
            if evasions:
                recommendations.append(f"Implement evasion techniques: {', '.join(evasions)}")
            if adaptations.get('detection_risk_level') == 'high':
                recommendations.append("High detection risk - use maximum stealth approach")

        elif strategy == AdaptationStrategy.PAYLOAD_EVOLUTION:
            if adaptations.get('size_optimization'):
                recommendations.append("Optimize payload size for better success rate")
            if adaptations.get('obfuscation_level') == 'maximum':
                recommendations.append("Apply maximum obfuscation to avoid detection")

        # Add confidence-based qualifier
        if confidence < 0.5:
            recommendations.insert(0, "Low confidence predictions - manual review recommended")
        elif confidence > 0.8:
            recommendations.insert(0, "High confidence predictions - safe to proceed")

        return recommendations

    def _get_model_insights(self, features: List[float], strategy: AdaptationStrategy) -> Dict[str, Any]:
        """Get insights from ML models for the given strategy."""
        insights = {
            'feature_importance': {},
            'prediction_confidence': 0.0,
            'model_recommendations': []
        }

        try:
            if strategy == AdaptationStrategy.EXPLOIT_OPTIMIZATION and 'exploit_success' in self.models:
                model = self.models['exploit_success']
                if hasattr(model, 'feature_importances_'):
                    insights['feature_importance'] = self._analyze_feature_importance(features, model.feature_importances_)

            elif strategy == AdaptationStrategy.VULNERABILITY_PREDICTION and 'vulnerability_prediction' in self.models:
                model = self.models['vulnerability_prediction']
                if hasattr(model, 'feature_importances_'):
                    insights['feature_importance'] = self._analyze_feature_importance(features, model.feature_importances_)

        except Exception as e:
            self.logger.debug(f"Model insights extraction failed: {e}")

        return insights

    def _update_training_data(self, target_info: Dict[str, Any],
                            previous_attempts: List[Dict[str, Any]],
                            adaptations: Dict[str, Any]):
        """Update training data with new adaptation results."""
        try:
            # Extract features
            features = self._extract_comprehensive_features(target_info, previous_attempts)

            # Add to exploit success training data
            if previous_attempts:
                last_attempt = previous_attempts[-1]
                self.training_data['exploit_success'].append({
                    'features': features,
                    'success': last_attempt.get('success', False),
                    'timestamp': time.time()
                })

            # Add vulnerability features if available
            if target_info.get('vulnerabilities'):
                for vuln in target_info['vulnerabilities']:
                    self.training_data['vulnerability_features'].append({
                        'features': self._extract_binary_features(target_info),
                        'vulnerability_type': vuln.get('type', 'unknown'),
                        'timestamp': time.time()
                    })

            # Limit training data size
            max_samples = self.config.get('max_training_samples', 10000)
            for data_type in self.training_data:
                if len(self.training_data[data_type]) > max_samples:
                    self.training_data[data_type] = self.training_data[data_type][-max_samples:]

        except Exception as e:
            self.logger.debug(f"Training data update failed: {e}")

    def _should_retrain_models(self) -> bool:
        """Check if models should be retrained based on new data."""
        total_new_samples = sum(len(samples) for samples in self.training_data.values())
        return total_new_samples >= self.config['model_retrain_threshold']

    def _retrain_models(self):
        """Retrain models with accumulated data."""
        try:
            self.logger.info("Retraining models with new data")
            training_result = self.train_adaptation_models()

            if training_result['success']:
                self.logger.info(f"Models retrained successfully: {training_result['models_trained']}")
                # Clear training data after successful training
                for data_type in self.training_data:
                    self.training_data[data_type] = self.training_data[data_type][-100:]  # Keep recent samples
            else:
                self.logger.warning(f"Model retraining failed: {training_result.get('error')}")

        except Exception as e:
            self.logger.error(f"Model retraining failed: {e}")

    def _log_adaptation(self, strategy: AdaptationStrategy, adaptations: Dict[str, Any], confidence: float):
        """Log adaptation for analysis and improvement."""
        adaptation_log = {
            'timestamp': time.time(),
            'strategy': strategy.value,
            'adaptations': adaptations,
            'confidence': confidence
        }

        self.metrics['adaptation_history'].append(adaptation_log)

        # Limit history size
        if len(self.metrics['adaptation_history']) > 1000:
            self.metrics['adaptation_history'] = self.metrics['adaptation_history'][-1000:]
