"""
Fuzzing Engine

Intelligent fuzzing framework for vulnerability discovery with multiple
fuzzing strategies, coverage-guided fuzzing, and crash analysis.
"""

import logging
import multiprocessing
import os
import random
import re
import struct
import subprocess
import tempfile
import time
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from ...models import VulnerabilityLevel

logger = logging.getLogger(__name__)


class FuzzingStrategy(Enum):
    """Fuzzing strategies"""
    RANDOM = "random"
    MUTATION = "mutation"
    GENERATION = "generation"
    GRAMMAR_BASED = "grammar_based"
    COVERAGE_GUIDED = "coverage_guided"
    HYBRID = "hybrid"


# Use VulnerabilityLevel as CrashSeverity for consistency
CrashSeverity = VulnerabilityLevel


class FuzzingEngine:
    """
    Advanced fuzzing engine with multiple strategies and crash analysis.
    """

    def __init__(self):
        self.logger = logging.getLogger("IntellicrackLogger.FuzzingEngine")

        # Fuzzing configuration
        self.config = {
            'max_iterations': 10000,
            'max_file_size': 1024 * 1024,  # 1MB
            'timeout': 30,  # seconds
            'parallel_workers': multiprocessing.cpu_count(),
            'crash_detection': True,
            'coverage_collection': False,
            'mutation_rate': 0.1,
            'crossover_rate': 0.3
        }

        # Mutation strategies
        self.mutation_strategies = {
            'bit_flip': self._mutate_bit_flip,
            'byte_flip': self._mutate_byte_flip,
            'arithmetic': self._mutate_arithmetic,
            'insert': self._mutate_insert,
            'delete': self._mutate_delete,
            'duplicate': self._mutate_duplicate,
            'splice': self._mutate_splice,
            'magic_values': self._mutate_magic_values,
            'string_replace': self._mutate_string_replace,
            'format_aware': self._mutate_format_aware
        }

        # Magic values for mutations
        self.magic_values = {
            'integers': [0, 1, -1, 255, 256, 65535, 65536, 2147483647, -2147483648],
            'strings': [b'A' * 1000, b'\x00' * 100, b'\xff' * 100, b'%s%s%s%s'],
            'format_strings': [b'%n', b'%x', b'%s', b'%d', b'%p'],
            'special_chars': [b'\x00', b'\xff', b'\x7f', b'\x80', b'\x0a', b'\x0d']
        }

        # File format grammars
        self.file_grammars = {
            'text': self._generate_text_grammar,
            'xml': self._generate_xml_grammar,
            'json': self._generate_json_grammar,
            'http': self._generate_http_grammar,
            'binary': self._generate_binary_grammar
        }

        # Coverage data
        self.coverage_data = {}
        self.interesting_inputs = []

        # Crash analysis
        self.crashes = {}
        self.unique_crashes = {}

        # Statistics
        self.stats = {
            'total_executions': 0,
            'crashes_found': 0,
            'unique_crashes': 0,
            'hangs_found': 0,
            'coverage_paths': 0,
            'execution_speed': 0.0,
            'start_time': 0,
            'elapsed_time': 0
        }

    def start_fuzzing(self,
                     target_command: str,
                     seed_inputs: Optional[List[str]] = None,
                     strategy: FuzzingStrategy = FuzzingStrategy.HYBRID,
                     max_iterations: Optional[int] = None) -> Dict[str, Any]:
        """
        Start fuzzing campaign against target.

        Args:
            target_command: Command to execute target (use @@@ for input file placeholder)
            seed_inputs: List of seed input files
            strategy: Fuzzing strategy to use
            max_iterations: Maximum number of iterations

        Returns:
            Fuzzing campaign results
        """
        result = {
            'success': False,
            'strategy': strategy.value,
            'target_command': target_command,
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': [],
            'statistics': {},
            'campaign_id': self._generate_campaign_id(),
            'error': None
        }

        try:
            self.logger.info(f"Starting fuzzing campaign: {strategy.value}")

            # Initialize campaign
            self.stats['start_time'] = time.time()
            self.stats['total_executions'] = 0

            # Set configuration
            if max_iterations:
                self.config['max_iterations'] = max_iterations

            # Prepare seed inputs
            if not seed_inputs:
                seed_inputs = self._generate_default_seeds()

            # Validate target command
            if '@@@' not in target_command:
                result['error'] = "Target command must contain @@@ placeholder for input file"
                return result

            # Create output directories
            output_dir = self._create_output_directories(result['campaign_id'])

            # Execute fuzzing strategy
            if strategy == FuzzingStrategy.RANDOM:
                campaign_result = self._random_fuzzing(target_command, seed_inputs, output_dir)
            elif strategy == FuzzingStrategy.MUTATION:
                campaign_result = self._mutation_fuzzing(target_command, seed_inputs, output_dir)
            elif strategy == FuzzingStrategy.GENERATION:
                campaign_result = self._generation_fuzzing(target_command, output_dir)
            elif strategy == FuzzingStrategy.GRAMMAR_BASED:
                campaign_result = self._grammar_based_fuzzing(target_command, seed_inputs, output_dir)
            elif strategy == FuzzingStrategy.COVERAGE_GUIDED:
                campaign_result = self._coverage_guided_fuzzing(target_command, seed_inputs, output_dir)
            elif strategy == FuzzingStrategy.HYBRID:
                campaign_result = self._hybrid_fuzzing(target_command, seed_inputs, output_dir)
            else:
                result['error'] = f"Unknown fuzzing strategy: {strategy.value}"
                return result

            # Finalize results
            self.stats['elapsed_time'] = time.time() - self.stats['start_time']

            result.update(campaign_result)
            result['statistics'] = self.stats.copy()
            result['success'] = True

            self.logger.info(f"Fuzzing campaign completed: {result['iterations_completed']} iterations")
            return result

        except Exception as e:
            self.logger.error(f"Fuzzing campaign failed: {e}")
            result['error'] = str(e)
            return result

    def analyze_crash(self,
                     crash_file: str,
                     target_command: str) -> Dict[str, Any]:
        """
        Analyze crash for exploitability and root cause.

        Args:
            crash_file: Path to input that caused crash
            target_command: Target command used

        Returns:
            Crash analysis results
        """
        result = {
            'success': False,
            'crash_file': crash_file,
            'crash_type': None,
            'severity': CrashSeverity.INFO.value,
            'exploitability': 'unknown',
            'root_cause': None,
            'stack_trace': None,
            'registers': {},
            'memory_info': {},
            'recommendations': [],
            'error': None
        }

        try:
            self.logger.info(f"Analyzing crash: {crash_file}")

            if not os.path.exists(crash_file):
                result['error'] = f"Crash file not found: {crash_file}"
                return result

            # Execute target with crash input under debugger
            debug_info = self._debug_crash(target_command, crash_file)

            if debug_info:
                # Analyze crash information
                crash_analysis = self._analyze_crash_info(debug_info)
                result.update(crash_analysis)

                # Assess exploitability
                exploitability = self._assess_exploitability(debug_info, crash_analysis)
                result['exploitability'] = exploitability

                # Generate recommendations
                recommendations = self._generate_crash_recommendations(crash_analysis)
                result['recommendations'] = recommendations

                result['success'] = True
            else:
                result['error'] = "Failed to reproduce crash under debugger"

            return result

        except Exception as e:
            self.logger.error(f"Crash analysis failed: {e}")
            result['error'] = str(e)
            return result

    def minimize_testcase(self,
                         crash_file: str,
                         target_command: str,
                         strategy: str = 'binary_search') -> Dict[str, Any]:
        """
        Minimize crash testcase to smallest reproducing input.

        Args:
            crash_file: Path to crash input
            target_command: Target command
            strategy: Minimization strategy

        Returns:
            Minimization results
        """
        result = {
            'success': False,
            'original_file': crash_file,
            'minimized_file': None,
            'original_size': 0,
            'minimized_size': 0,
            'reduction_ratio': 0.0,
            'iterations': 0,
            'error': None
        }

        try:
            self.logger.info(f"Minimizing testcase: {crash_file}")

            if not os.path.exists(crash_file):
                result['error'] = f"Crash file not found: {crash_file}"
                return result

            # Read original input
            with open(crash_file, 'rb') as f:
                original_data = f.read()

            result['original_size'] = len(original_data)

            # Perform minimization
            if strategy == 'binary_search':
                minimized_data = self._minimize_binary_search(original_data, target_command)
            elif strategy == 'delta_debugging':
                minimized_data = self._minimize_delta_debugging(original_data, target_command)
            else:
                result['error'] = f"Unknown minimization strategy: {strategy}"
                return result

            # Save minimized input
            minimized_file = crash_file.replace('.crash', '.minimized')
            with open(minimized_file, 'wb') as f:
                f.write(minimized_data)

            result['minimized_file'] = minimized_file
            result['minimized_size'] = len(minimized_data)
            result['reduction_ratio'] = 1.0 - (len(minimized_data) / len(original_data))
            result['success'] = True

            self.logger.info(f"Testcase minimized: {result['original_size']} -> {result['minimized_size']} bytes")
            return result

        except Exception as e:
            self.logger.error(f"Testcase minimization failed: {e}")
            result['error'] = str(e)
            return result

    def _random_fuzzing(self, target_command: str, seed_inputs: List[str], output_dir: str) -> Dict[str, Any]:
        """Perform random fuzzing."""
        result = {
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': []
        }

        try:
            self.logger.info("Starting random fuzzing")

            for iteration in range(self.config['max_iterations']):
                # Generate random input
                if seed_inputs and random.random() < 0.5:
                    # Use seed as base
                    seed_file = random.choice(seed_inputs)
                    with open(seed_file, 'rb') as f:
                        base_data = f.read()
                    fuzz_data = self._randomize_data(base_data)
                else:
                    # Generate completely random data
                    size = random.randint(1, self.config['max_file_size'])
                    fuzz_data = bytes([random.randint(0, 255) for _ in range(size)])

                # Execute target
                execution_result = self._execute_target(target_command, fuzz_data, output_dir)

                if execution_result['crashed']:
                    crash_info = self._process_crash(execution_result, fuzz_data, output_dir, iteration)
                    result['crashes_found'].append(crash_info)

                result['iterations_completed'] += 1
                self.stats['total_executions'] += 1

                # Progress logging
                if iteration % 1000 == 0:
                    self.logger.info(f"Random fuzzing progress: {iteration}/{self.config['max_iterations']}")

        except Exception as e:
            self.logger.debug(f"Random fuzzing error: {e}")

        return result

    def _mutation_fuzzing(self, target_command: str, seed_inputs: List[str], output_dir: str) -> Dict[str, Any]:
        """Perform mutation-based fuzzing."""
        result = {
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': []
        }

        try:
            self.logger.info("Starting mutation fuzzing")

            # Load seed inputs
            seed_data = []
            for seed_file in seed_inputs:
                try:
                    with open(seed_file, 'rb') as f:
                        seed_data.append(f.read())
                except Exception:
                    continue

            if not seed_data:
                seed_data = [b'AAAA']  # Minimal seed

            for iteration in range(self.config['max_iterations']):
                # Select seed
                base_data = random.choice(seed_data)

                # Apply mutations
                mutated_data = self._apply_mutations(base_data)

                # Execute target
                execution_result = self._execute_target(target_command, mutated_data, output_dir)

                if execution_result['crashed']:
                    crash_info = self._process_crash(execution_result, mutated_data, output_dir, iteration)
                    result['crashes_found'].append(crash_info)

                # Add interesting inputs to seed pool
                if self._is_interesting_input(execution_result):
                    seed_data.append(mutated_data)

                result['iterations_completed'] += 1
                self.stats['total_executions'] += 1

                # Progress logging
                if iteration % 1000 == 0:
                    self.logger.info(f"Mutation fuzzing progress: {iteration}/{self.config['max_iterations']}")

        except Exception as e:
            self.logger.debug(f"Mutation fuzzing error: {e}")

        return result
    def _generation_fuzzing(self, target_command: str, output_dir: str) -> Dict[str, Any]:
        """Perform generative fuzzing."""
        result = {
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': []
        }

        try:
            self.logger.info("Starting generation fuzzing")

            for iteration in range(self.config['max_iterations']):
                # Generate input based on common patterns
                generated_data = self._generate_input()

                # Execute target
                execution_result = self._execute_target(target_command, generated_data, output_dir)

                if execution_result['crashed']:
                    crash_info = self._process_crash(execution_result, generated_data, output_dir, iteration)
                    result['crashes_found'].append(crash_info)

                result['iterations_completed'] += 1
                self.stats['total_executions'] += 1

                # Progress logging
                if iteration % 1000 == 0:
                    self.logger.info(f"Generation fuzzing progress: {iteration}/{self.config['max_iterations']}")

        except Exception as e:
            self.logger.debug(f"Generation fuzzing error: {e}")

        return result

    def _grammar_based_fuzzing(self, target_command: str, seed_inputs: List[str], output_dir: str) -> Dict[str, Any]:
        """Perform grammar-based fuzzing."""
        result = {
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': []
        }

        try:
            self.logger.info("Starting grammar-based fuzzing")

            # Detect file format from seeds
            file_format = self._detect_file_format(seed_inputs)

            for iteration in range(self.config['max_iterations']):
                # Generate input using grammar
                if file_format in self.file_grammars:
                    grammar_func = self.file_grammars[file_format]
                    generated_data = grammar_func()
                else:
                    # Default to text generation
                    generated_data = self._generate_text_grammar()

                # Execute target
                execution_result = self._execute_target(target_command, generated_data, output_dir)

                if execution_result['crashed']:
                    crash_info = self._process_crash(execution_result, generated_data, output_dir, iteration)
                    result['crashes_found'].append(crash_info)

                result['iterations_completed'] += 1
                self.stats['total_executions'] += 1

                # Progress logging
                if iteration % 1000 == 0:
                    self.logger.info(f"Grammar fuzzing progress: {iteration}/{self.config['max_iterations']}")

        except Exception as e:
            self.logger.debug(f"Grammar-based fuzzing error: {e}")

        return result

    def _coverage_guided_fuzzing(self, target_command: str, seed_inputs: List[str], output_dir: str) -> Dict[str, Any]:
        """Perform coverage-guided fuzzing."""
        result = {
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': []
        }

        try:
            self.logger.info("Starting coverage-guided fuzzing")

            # Initialize with seeds
            queue = []
            for seed_file in seed_inputs:
                try:
                    with open(seed_file, 'rb') as f:
                        data = f.read()
                        queue.append(data)
                except Exception:
                    continue

            if not queue:
                queue = [b'AAAA']

            for iteration in range(self.config['max_iterations']):
                # Select input from queue
                if queue:
                    base_data = random.choice(queue)
                else:
                    base_data = b'AAAA'

                # Mutate
                mutated_data = self._apply_mutations(base_data)

                # Execute with coverage collection
                execution_result = self._execute_target_with_coverage(target_command, mutated_data, output_dir)

                if execution_result['crashed']:
                    crash_info = self._process_crash(execution_result, mutated_data, output_dir, iteration)
                    result['crashes_found'].append(crash_info)

                # Check for new coverage
                if execution_result.get('new_coverage'):
                    queue.append(mutated_data)
                    self.stats['coverage_paths'] += 1

                result['iterations_completed'] += 1
                self.stats['total_executions'] += 1

                # Progress logging
                if iteration % 1000 == 0:
                    self.logger.info(f"Coverage fuzzing progress: {iteration}/{self.config['max_iterations']}")

        except Exception as e:
            self.logger.debug(f"Coverage-guided fuzzing error: {e}")

        return result

    def _hybrid_fuzzing(self, target_command: str, seed_inputs: List[str], output_dir: str) -> Dict[str, Any]:
        """Perform hybrid fuzzing combining multiple strategies."""
        result = {
            'iterations_completed': 0,
            'crashes_found': [],
            'unique_crashes': []
        }

        try:
            self.logger.info("Starting hybrid fuzzing")

            strategies = [
                ('mutation', 0.4),
                ('random', 0.2),
                ('generation', 0.2),
                ('grammar', 0.2)
            ]

            # Load seeds
            seed_data = []
            for seed_file in seed_inputs:
                try:
                    with open(seed_file, 'rb') as f:
                        seed_data.append(f.read())
                except Exception:
                    continue

            if not seed_data:
                seed_data = [b'AAAA']

            for iteration in range(self.config['max_iterations']):
                # Select strategy based on probabilities
                strategy = self._select_strategy(strategies)

                # Generate input based on strategy
                if strategy == 'mutation':
                    base_data = random.choice(seed_data)
                    fuzz_data = self._apply_mutations(base_data)
                elif strategy == 'random':
                    size = random.randint(1, min(1000, self.config['max_file_size']))
                    fuzz_data = bytes([random.randint(0, 255) for _ in range(size)])
                elif strategy == 'generation':
                    fuzz_data = self._generate_input()
                elif strategy == 'grammar':
                    file_format = self._detect_file_format(seed_inputs)
                    if file_format in self.file_grammars:
                        fuzz_data = self.file_grammars[file_format]()
                    else:
                        fuzz_data = self._generate_text_grammar()
                else:
                    # Fallback to random data if strategy is unknown
                    fuzz_data = bytes([random.randint(0, 255) for _ in range(100)])

                # Execute target
                execution_result = self._execute_target(target_command, fuzz_data, output_dir)

                if execution_result['crashed']:
                    crash_info = self._process_crash(execution_result, fuzz_data, output_dir, iteration)
                    result['crashes_found'].append(crash_info)

                # Add interesting inputs to seeds
                if self._is_interesting_input(execution_result):
                    seed_data.append(fuzz_data)
                    if len(seed_data) > 1000:  # Limit seed pool size
                        seed_data = seed_data[-1000:]

                result['iterations_completed'] += 1
                self.stats['total_executions'] += 1

                # Progress logging
                if iteration % 1000 == 0:
                    self.logger.info(f"Hybrid fuzzing progress: {iteration}/{self.config['max_iterations']}")

        except Exception as e:
            self.logger.debug(f"Hybrid fuzzing error: {e}")

        return result

    def _execute_target(self, target_command: str, input_data: bytes, output_dir: str) -> Dict[str, Any]:
        """Execute target with input data."""
        result = {
            'crashed': False,
            'hanged': False,
            'exit_code': 0,
            'stdout': '',
            'stderr': '',
            'execution_time': 0.0,
            'signal': None
        }

        try:
            # Create temporary input file
            with tempfile.NamedTemporaryFile(mode='wb', delete=False, dir=output_dir) as f:
                f.write(input_data)
                input_file = f.name

            # Replace placeholder in command
            cmd = target_command.replace('@@@', input_file)

            start_time = time.time()

            try:
                # Execute with timeout
                process = subprocess.Popen(
                    cmd.split(),
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    text=True
                )

                try:
                    stdout, stderr = process.communicate(timeout=self.config['timeout'])
                    result['exit_code'] = process.returncode
                    result['stdout'] = stdout
                    result['stderr'] = stderr

                except subprocess.TimeoutExpired:
                    process.kill()
                    result['hanged'] = True

            except Exception as e:
                result['crashed'] = True
                result['stderr'] = str(e)

            result['execution_time'] = time.time() - start_time

            # Check for crash indicators
            if result['exit_code'] < 0:
                result['crashed'] = True
                result['signal'] = -result['exit_code']

            # Cleanup
            try:
                os.unlink(input_file)
            except Exception:
                pass

        except Exception as e:
            self.logger.debug(f"Target execution error: {e}")
            result['crashed'] = True

        return result

    def _execute_target_with_coverage(self, target_command: str, input_data: bytes, output_dir: str) -> Dict[str, Any]:
        """Execute target with coverage collection."""
        # This would implement coverage collection
        # For now, simulate coverage detection
        result = self._execute_target(target_command, input_data, output_dir)
        result['new_coverage'] = random.random() < 0.1  # 10% chance of new coverage
        return result

    def _apply_mutations(self, data: bytes) -> bytes:
        """Apply random mutations to data."""
        if not data:
            return data

        mutated = bytearray(data)

        # Apply random number of mutations
        num_mutations = random.randint(1, max(1, int(len(data) * self.config['mutation_rate'])))

        for _ in range(num_mutations):
            # Select random mutation strategy
            strategy = random.choice(list(self.mutation_strategies.keys()))
            mutation_func = self.mutation_strategies[strategy]

            try:
                mutated = mutation_func(mutated)
            except Exception:
                continue

        return bytes(mutated)

    # Mutation strategy implementations

    def _mutate_bit_flip(self, data: bytearray) -> bytearray:
        """Flip random bits."""
        if not data:
            return data

        pos = random.randint(0, len(data) - 1)
        bit_pos = random.randint(0, 7)
        data[pos] ^= (1 << bit_pos)
        return data

    def _mutate_byte_flip(self, data: bytearray) -> bytearray:
        """Flip random bytes."""
        if not data:
            return data

        pos = random.randint(0, len(data) - 1)
        data[pos] = random.randint(0, 255)
        return data

    def _mutate_arithmetic(self, data: bytearray) -> bytearray:
        """Apply arithmetic operations."""
        if len(data) < 2:
            return data

        pos = random.randint(0, len(data) - 2)

        # Interpret as various integer types
        if random.choice([True, False]):
            # 16-bit integer
            if pos <= len(data) - 2:
                val = struct.unpack('<H', data[pos:pos+2])[0]
                val = (val + random.randint(-100, 100)) % 65536
                struct.pack_into('<H', data, pos, val)
        else:
            # 8-bit integer
            data[pos] = (data[pos] + random.randint(-50, 50)) % 256

        return data

    def _mutate_insert(self, data: bytearray) -> bytearray:
        """Insert random bytes."""
        pos = random.randint(0, len(data))
        insert_data = bytes([random.randint(0, 255) for _ in range(random.randint(1, 10))])
        return bytearray(data[:pos] + insert_data + data[pos:])

    def _mutate_delete(self, data: bytearray) -> bytearray:
        """Delete random bytes."""
        if len(data) <= 1:
            return data

        start = random.randint(0, len(data) - 1)
        end = random.randint(start, min(start + 10, len(data)))
        return bytearray(data[:start] + data[end:])

    def _mutate_duplicate(self, data: bytearray) -> bytearray:
        """Duplicate random chunks."""
        if not data:
            return data

        start = random.randint(0, len(data) - 1)
        end = random.randint(start, min(start + 10, len(data)))
        chunk = data[start:end]

        pos = random.randint(0, len(data))
        return bytearray(data[:pos] + chunk + data[pos:])

    def _mutate_splice(self, data: bytearray) -> bytearray:
        """Splice with magic values."""
        if not data:
            return data

        pos = random.randint(0, len(data))
        magic_value = random.choice(self.magic_values['special_chars'])
        return bytearray(data[:pos] + magic_value + data[pos:])

    def _mutate_magic_values(self, data: bytearray) -> bytearray:
        """Replace with magic values."""
        if len(data) < 4:
            return data

        pos = random.randint(0, len(data) - 4)
        magic_int = random.choice(self.magic_values['integers'])
        struct.pack_into('<I', data, pos, magic_int % (2**32))
        return data

    def _mutate_string_replace(self, data: bytearray) -> bytearray:
        """Replace strings with format string payloads."""
        magic_string = random.choice(self.magic_values['format_strings'])

        if len(data) >= len(magic_string):
            pos = random.randint(0, len(data) - len(magic_string))
            data[pos:pos+len(magic_string)] = magic_string

        return data

    def _mutate_format_aware(self, data: bytearray) -> bytearray:
        """Format-aware mutations."""
        # This would implement format-specific mutations
        # For now, just apply a random mutation
        return self._mutate_byte_flip(data)

    def _generate_input(self) -> bytes:
        """Generate input using common patterns."""
        patterns = [
            self._generate_overflow_pattern,
            self._generate_format_string_pattern,
            self._generate_unicode_pattern,
            self._generate_binary_pattern
        ]

        generator = random.choice(patterns)
        return generator()

    def _generate_overflow_pattern(self) -> bytes:
        """Generate buffer overflow pattern."""
        size = random.randint(100, 2000)
        char = random.choice([b'A', b'B', b'C', b'\x41'])
        return char[0:1] * size

    def _generate_format_string_pattern(self) -> bytes:
        """Generate format string pattern."""
        formats = [b'%s', b'%x', b'%n', b'%p', b'%d']
        num_formats = random.randint(1, 20)
        return b''.join(random.choice(formats) for _ in range(num_formats))

    def _generate_unicode_pattern(self) -> bytes:
        """Generate Unicode pattern."""
        unicode_chars = [b'\xff\xfe', b'\xfe\xff', b'\xef\xbb\xbf']
        base = random.choice(unicode_chars)
        return base + b'A' * random.randint(10, 100)

    def _generate_binary_pattern(self) -> bytes:
        """Generate binary pattern."""
        size = random.randint(10, 1000)
        return bytes([random.randint(0, 255) for _ in range(size)])

    # File format grammar generators

    def _generate_text_grammar(self) -> bytes:
        """Generate text input."""
        words = [b'hello', b'world', b'test', b'data', b'input']
        num_words = random.randint(1, 20)
        return b' '.join(random.choice(words) for _ in range(num_words))

    def _generate_xml_grammar(self) -> bytes:
        """Generate XML input."""
        tag = random.choice([b'root', b'data', b'element'])
        content = b'A' * random.randint(1, 100)
        return b'<?xml version="1.0"?><' + tag + b'>' + content + b'</' + tag + b'>'

    def _generate_json_grammar(self) -> bytes:
        """Generate JSON input."""
        key = b'key' + str(random.randint(1, 100)).encode()
        value = b'A' * random.randint(1, 100)
        return b'{"' + key + b'": "' + value + b'"}'

    def _generate_http_grammar(self) -> bytes:
        """Generate HTTP input."""
        method = random.choice([b'GET', b'POST', b'PUT'])
        path = b'/' + b'A' * random.randint(1, 100)
        return method + b' ' + path + b' HTTP/1.1\r\nHost: test\r\n\r\n'

    def _generate_binary_grammar(self) -> bytes:
        """Generate binary input."""
        header = b'BIN\x00'
        size = random.randint(10, 1000)
        data = bytes([random.randint(0, 255) for _ in range(size)])
        return header + data

    # Helper methods

    def _generate_default_seeds(self) -> List[str]:
        """Generate default seed inputs."""
        seeds = []

        try:
            # Create temporary seed files
            seed_data = [
                b'AAAA',
                b'test input',
                b'\x00\x01\x02\x03',
                b'%s%s%s%s',
                b'A' * 100
            ]

            temp_dir = tempfile.mkdtemp()

            for i, data in enumerate(seed_data):
                seed_file = os.path.join(temp_dir, f'seed_{i}.dat')
                with open(seed_file, 'wb') as f:
                    f.write(data)
                seeds.append(seed_file)

        except Exception as e:
            self.logger.debug(f"Default seed generation error: {e}")

        return seeds

    def _detect_file_format(self, seed_inputs: List[str]) -> str:
        """Detect file format from seed inputs."""
        if not seed_inputs:
            return 'binary'

        try:
            # Read first seed
            with open(seed_inputs[0], 'rb') as f:
                data = f.read(100)  # Read first 100 bytes

            # Simple format detection
            if data.startswith(b'<?xml'):
                return 'xml'
            elif data.startswith(b'{') or data.startswith(b'['):
                return 'json'
            elif b'HTTP' in data:
                return 'http'
            elif all(32 <= b <= 126 for b in data if b != 0):
                return 'text'
            else:
                return 'binary'

        except Exception:
            return 'binary'

    def _randomize_data(self, data: bytes) -> bytes:
        """Randomize data while maintaining some structure."""
        if not data:
            return data

        mutated = bytearray(data)

        # Randomize some percentage of bytes
        num_changes = int(len(data) * random.uniform(0.01, 0.1))

        for _ in range(num_changes):
            pos = random.randint(0, len(mutated) - 1)
            mutated[pos] = random.randint(0, 255)

        return bytes(mutated)

    def _is_interesting_input(self, execution_result: Dict[str, Any]) -> bool:
        """Check if input is interesting for fuzzing."""
        # Consider input interesting if it has new behavior
        return (
            execution_result.get('new_coverage', False) or
            execution_result.get('hanged', False) or
            execution_result['execution_time'] > self.config['timeout'] * 0.8
        )

    def _select_strategy(self, strategies: List[Tuple[str, float]]) -> str:
        """Select fuzzing strategy based on probabilities."""
        rand_val = random.random()
        cumulative = 0.0

        for strategy, probability in strategies:
            cumulative += probability
            if rand_val <= cumulative:
                return strategy

        return strategies[0][0]  # Fallback to first strategy

    def _process_crash(self, execution_result: Dict[str, Any], input_data: bytes,
                      output_dir: str, iteration: int) -> Dict[str, Any]:
        """Process and analyze crash."""
        crash_info = {
            'iteration': iteration,
            'crash_id': self._generate_crash_id(),
            'input_size': len(input_data),
            'exit_code': execution_result['exit_code'],
            'signal': execution_result.get('signal'),
            'stderr': execution_result['stderr'],
            'execution_time': execution_result['execution_time'],
            'crash_file': None,
            'unique': False
        }

        try:
            # Save crash input
            crash_file = os.path.join(output_dir, 'crashes', f"crash_{crash_info['crash_id']}.dat")
            os.makedirs(os.path.dirname(crash_file), exist_ok=True)

            with open(crash_file, 'wb') as f:
                f.write(input_data)

            crash_info['crash_file'] = crash_file

            # Check if crash is unique
            crash_hash = self._calculate_crash_hash(execution_result)

            if crash_hash not in self.unique_crashes:
                self.unique_crashes[crash_hash] = crash_info
                crash_info['unique'] = True
                self.stats['unique_crashes'] += 1

            self.stats['crashes_found'] += 1

        except Exception as e:
            self.logger.debug(f"Crash processing error: {e}")

        return crash_info

    def _calculate_crash_hash(self, execution_result: Dict[str, Any]) -> str:
        """Calculate hash to identify unique crashes."""
        import hashlib

        # Use exit code, signal, and stderr for uniqueness
        crash_data = f"{execution_result['exit_code']}:{execution_result.get('signal', '')}:{execution_result['stderr'][:100]}"
        return hashlib.sha256(crash_data.encode()).hexdigest()[:16]

    def _create_output_directories(self, campaign_id: str) -> str:
        """Create output directories for fuzzing campaign."""
        output_dir = f"/tmp/fuzzing_{campaign_id}"

        os.makedirs(output_dir, exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'crashes'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'hangs'), exist_ok=True)
        os.makedirs(os.path.join(output_dir, 'queue'), exist_ok=True)

        return output_dir

    def _generate_campaign_id(self) -> str:
        """Generate unique campaign identifier."""
        import hashlib
        import time

        data = f"{time.time()}-{random.randint(1000, 9999)}"
        return hashlib.sha256(data.encode()).hexdigest()[:12]

    def _generate_crash_id(self) -> str:
        """Generate unique crash identifier."""
        import hashlib

        data = f"{time.time()}-{random.randint(1000, 9999)}"
        return hashlib.sha256(data.encode()).hexdigest()[:8]

    # Crash analysis methods (stubs for now)

    def _debug_crash(self, target_command: str, crash_file: str) -> Optional[Dict[str, Any]]:
        """Debug crash under debugger."""
        debug_info = {
            'registers': {},
            'stack_trace': [],
            'memory_maps': [],
            'crash_address': None,
            'crash_instruction': None,
            'fault_type': None,
            'signal_info': {},
            'thread_info': {},
            'loaded_modules': [],
            'heap_info': {},
            'stack_info': {}
        }

        try:
            # Try GDB-based debugging (Linux)
            if os.name == 'posix':
                debug_info.update(self._debug_with_gdb(target_command, crash_file))

            # Try WinDbg-based debugging (Windows)
            elif os.name == 'nt':
                debug_info.update(self._debug_with_windbg(target_command, crash_file))

            # Fallback to crash pattern analysis
            else:
                debug_info.update(self._analyze_crash_pattern(crash_file))

        except Exception as e:
            self.logger.warning(f"Debugging failed: {e}")
            debug_info.update(self._analyze_crash_pattern(crash_file))

        return debug_info

    def _debug_with_gdb(self, target_command: str, crash_file: str) -> Dict[str, Any]:
        """Debug crash using GDB."""
        gdb_info = {}

        try:
            # Create GDB script
            gdb_script = f"""
set confirm off
set pagination off
set logging file /tmp/gdb_output.txt
set logging on
file {target_command.split()[0]}
run {crash_file}
info registers
bt
info proc mappings
x/32i $pc-16
x/64wx $sp-32
disas $pc-32,$pc+32
info threads
info sharedlibrary
quit
"""

            gdb_script_file = '/tmp/gdb_debug.script'
            with open(gdb_script_file, 'w') as f:
                f.write(gdb_script)

            # Run GDB
            gdb_cmd = f"gdb -batch -x {gdb_script_file} 2>/dev/null"
            result = subprocess.run(gdb_cmd, shell=True, capture_output=True, text=True, timeout=30)

            # Parse GDB output
            if os.path.exists('/tmp/gdb_output.txt'):
                with open('/tmp/gdb_output.txt', 'r') as f:
                    gdb_output = f.read()

                gdb_info = self._parse_gdb_output(gdb_output)

                # Cleanup
                os.remove('/tmp/gdb_output.txt')
                os.remove(gdb_script_file)

        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            self.logger.debug(f"GDB debugging failed: {e}")

        return gdb_info

    def _debug_with_windbg(self, target_command: str, crash_file: str) -> Dict[str, Any]:
        """Debug crash using WinDbg (Windows)."""
        windbg_info = {}

        try:
            # WinDbg commands
            windbg_script = f"""
.logopen c:\\temp\\windbg_output.txt
.load wow64exts
.load ext\\*
{target_command} {crash_file}
g
r
k
lm
!analyze -v
!heap -p -a @$exr
!address @$exr
u @$ip-20 @$ip+20
dd @$esp-40 @$esp+40
q
"""

            # This would require WinDbg installation
            # For now, return basic analysis
            windbg_info = {
                'platform': 'windows',
                'debugger': 'windbg',
                'status': 'not_available'
            }

        except Exception as e:
            self.logger.debug(f"WinDbg debugging failed: {e}")

        return windbg_info

    def _parse_gdb_output(self, gdb_output: str) -> Dict[str, Any]:
        """Parse GDB debugging output."""
        parsed_info = {
            'registers': {},
            'stack_trace': [],
            'memory_maps': [],
            'crash_address': None,
            'crash_instruction': None,
            'loaded_modules': []
        }

        lines = gdb_output.split('\n')
        current_section = None

        for line in lines:
            line = line.strip()

            # Parse registers
            if line.startswith('rax') or line.startswith('eax'):
                reg_match = re.search(r'(\w+)\s+0x([0-9a-fA-F]+)', line)
                if reg_match:
                    reg_name, reg_value = reg_match.groups()
                    parsed_info['registers'][reg_name] = int(reg_value, 16)

            # Parse stack trace
            elif line.startswith('#'):
                frame_match = re.search(r'#(\d+)\s+0x([0-9a-fA-F]+)\s+in\s+(.+)', line)
                if frame_match:
                    frame_num, addr, func = frame_match.groups()
                    parsed_info['stack_trace'].append({
                        'frame': int(frame_num),
                        'address': int(addr, 16),
                        'function': func
                    })

            # Parse memory mappings
            elif 'mapped' in line and '0x' in line:
                map_match = re.search(r'0x([0-9a-fA-F]+)\s+0x([0-9a-fA-F]+)\s+0x([0-9a-fA-F]+)\s+0x([0-9a-fA-F]+)\s+(.+)', line)
                if map_match:
                    start, end, size, offset, objfile = map_match.groups()
                    parsed_info['memory_maps'].append({
                        'start': int(start, 16),
                        'end': int(end, 16),
                        'size': int(size, 16),
                        'offset': int(offset, 16),
                        'objfile': objfile
                    })

            # Parse crash address
            elif 'Program received signal' in line:
                signal_match = re.search(r'signal\s+(\w+),\s+(.+)', line)
                if signal_match:
                    signal_name, signal_desc = signal_match.groups()
                    parsed_info['signal_info'] = {
                        'signal': signal_name,
                        'description': signal_desc
                    }

        return parsed_info

    def _analyze_crash_pattern(self, crash_file: str) -> Dict[str, Any]:
        """Analyze crash based on input patterns."""
        pattern_info = {
            'input_analysis': {},
            'crash_indicators': [],
            'pattern_type': 'unknown'
        }

        try:
            with open(crash_file, 'rb') as f:
                crash_data = f.read()

            # Analyze input patterns
            pattern_info['input_analysis'] = {
                'size': len(crash_data),
                'has_nulls': b'\x00' in crash_data,
                'has_format_strings': any(fs in crash_data for fs in [b'%s', b'%n', b'%x']),
                'has_long_strings': any(len(chunk) > 100 for chunk in crash_data.split(b'\x00')),
                'entropy': self._calculate_data_entropy(crash_data),
                'repeated_patterns': self._find_repeated_patterns(crash_data)
            }

            # Determine likely crash type
            if b'A' * 50 in crash_data or b'B' * 50 in crash_data:
                pattern_info['pattern_type'] = 'buffer_overflow'
                pattern_info['crash_indicators'].append('long_repeated_chars')

            if any(fs in crash_data for fs in [b'%s', b'%n', b'%x']):
                pattern_info['pattern_type'] = 'format_string'
                pattern_info['crash_indicators'].append('format_specifiers')

            if len(crash_data) > 10000:
                pattern_info['crash_indicators'].append('large_input')

        except Exception as e:
            self.logger.debug(f"Crash pattern analysis failed: {e}")

        return pattern_info

    def _calculate_data_entropy(self, data: bytes) -> float:
        """Calculate entropy of crash data."""
        from ...utils.analysis.entropy_utils import safe_entropy_calculation

        return safe_entropy_calculation(data, max_entropy=8.0)  # Cap at 8 bits for fuzzing analysis

    def _find_repeated_patterns(self, data: bytes) -> List[Dict[str, Any]]:
        """Find repeated patterns in crash data."""
        patterns = []

        # Look for repeated byte sequences
        for pattern_len in [1, 2, 4, 8]:
            if len(data) < pattern_len * 10:
                continue

            for i in range(len(data) - pattern_len * 5):
                pattern = data[i:i+pattern_len]
                count = 0
                pos = i

                while pos < len(data) - pattern_len:
                    if data[pos:pos+pattern_len] == pattern:
                        count += 1
                        pos += pattern_len
                    else:
                        pos += 1

                if count >= 10:  # Found significant repetition
                    patterns.append({
                        'pattern': pattern.hex(),
                        'length': pattern_len,
                        'count': count,
                        'start_offset': i
                    })
                    break

        return patterns[:5]  # Return top 5 patterns

    def _analyze_crash_info(self, debug_info: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze crash debug information."""
        analysis = {
            'crash_type': 'unknown',
            'severity': CrashSeverity.MEDIUM.value,
            'root_cause': 'unknown',
            'crash_details': {},
            'vulnerability_indicators': [],
            'exploitation_complexity': 'unknown',
            'affected_components': [],
            'security_impact': {}
        }

        try:
            # Analyze signal information
            signal_info = debug_info.get('signal_info', {})
            if signal_info:
                analysis.update(self._analyze_signal_crash(signal_info))

            # Analyze register state
            registers = debug_info.get('registers', {})
            if registers:
                analysis.update(self._analyze_register_state(registers))

            # Analyze stack trace
            stack_trace = debug_info.get('stack_trace', [])
            if stack_trace:
                analysis.update(self._analyze_stack_trace(stack_trace))

            # Analyze memory mappings
            memory_maps = debug_info.get('memory_maps', [])
            if memory_maps:
                analysis.update(self._analyze_memory_layout(memory_maps))

            # Analyze input patterns
            input_analysis = debug_info.get('input_analysis', {})
            if input_analysis:
                analysis.update(self._analyze_input_patterns(input_analysis))

            # Determine overall severity
            analysis['severity'] = self._calculate_crash_severity(analysis)

            # Generate security impact assessment
            analysis['security_impact'] = self._assess_security_impact(analysis)

        except Exception as e:
            self.logger.warning(f"Crash analysis failed: {e}")

        return analysis

    def _analyze_signal_crash(self, signal_info: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze crash based on signal information."""
        signal_analysis = {
            'crash_type': 'unknown',
            'vulnerability_indicators': [],
            'crash_details': {}
        }

        signal_name = signal_info.get('signal', '').upper()

        if signal_name == 'SIGSEGV':
            signal_analysis.update({
                'crash_type': 'segmentation_fault',
                'root_cause': 'memory_corruption',
                'vulnerability_indicators': ['memory_access_violation', 'potential_buffer_overflow'],
                'crash_details': {
                    'fault_type': 'memory_access_violation',
                    'description': 'Invalid memory access detected'
                }
            })

        elif signal_name == 'SIGABRT':
            signal_analysis.update({
                'crash_type': 'abort_signal',
                'root_cause': 'assertion_failure',
                'vulnerability_indicators': ['heap_corruption', 'double_free'],
                'crash_details': {
                    'fault_type': 'program_abort',
                    'description': 'Program aborted, possibly due to heap corruption'
                }
            })

        elif signal_name == 'SIGILL':
            signal_analysis.update({
                'crash_type': 'illegal_instruction',
                'root_cause': 'code_corruption',
                'vulnerability_indicators': ['code_injection', 'rop_chain'],
                'crash_details': {
                    'fault_type': 'illegal_instruction',
                    'description': 'Illegal instruction executed'
                }
            })

        elif signal_name == 'SIGFPE':
            signal_analysis.update({
                'crash_type': 'floating_point_exception',
                'root_cause': 'arithmetic_error',
                'vulnerability_indicators': ['division_by_zero', 'integer_overflow'],
                'crash_details': {
                    'fault_type': 'arithmetic_exception',
                    'description': 'Floating point arithmetic error'
                }
            })

        return signal_analysis

    def _analyze_register_state(self, registers: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze crash based on register state."""
        register_analysis = {
            'vulnerability_indicators': [],
            'crash_details': {},
            'exploitation_complexity': 'medium'
        }

        # Check for common exploitation patterns
        for reg_name, reg_value in registers.items():
            if isinstance(reg_value, int):
                # Check for controlled register values (common in exploits)
                if reg_value == 0x41414141:  # 'AAAA'
                    register_analysis['vulnerability_indicators'].append('controlled_eip')
                    register_analysis['exploitation_complexity'] = 'low'
                    register_analysis['crash_details']['controlled_registers'] = [reg_name]

                elif reg_value == 0x42424242:  # 'BBBB'
                    register_analysis['vulnerability_indicators'].append('controlled_register')
                    register_analysis['exploitation_complexity'] = 'low'

                elif reg_value & 0xFFFF0000 == 0x41410000:  # Partial control
                    register_analysis['vulnerability_indicators'].append('partial_register_control')
                    register_analysis['exploitation_complexity'] = 'medium'

                # Check for NULL dereference
                elif reg_value == 0x0:
                    register_analysis['vulnerability_indicators'].append('null_pointer_dereference')

                # Check for stack addresses (potential stack overflow)
                elif 0x7fff00000000 <= reg_value <= 0x7fffffffffff:  # x64 stack range
                    register_analysis['vulnerability_indicators'].append('stack_address_in_register')

        return register_analysis

    def _analyze_stack_trace(self, stack_trace: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze crash based on stack trace."""
        stack_analysis = {
            'affected_components': [],
            'vulnerability_indicators': [],
            'crash_details': {}
        }

        if not stack_trace:
            return stack_analysis

        # Analyze function names in stack trace
        functions = [frame.get('function', '') for frame in stack_trace]

        # Look for vulnerable function patterns
        vulnerable_functions = [
            'strcpy', 'strcat', 'sprintf', 'gets', 'scanf',
            'memcpy', 'memmove', 'strncpy', 'strncat'
        ]

        for func in functions:
            for vuln_func in vulnerable_functions:
                if vuln_func in func:
                    stack_analysis['vulnerability_indicators'].append(f'vulnerable_function_{vuln_func}')
                    stack_analysis['affected_components'].append(func)

        # Check for recursive calls (potential stack overflow)
        func_counts = {}
        for func in functions:
            func_counts[func] = func_counts.get(func, 0) + 1

        for func, count in func_counts.items():
            if count > 10:  # Likely recursion
                stack_analysis['vulnerability_indicators'].append('stack_overflow_recursion')
                stack_analysis['crash_details']['recursive_function'] = func

        # Analyze stack depth
        if len(stack_trace) > 50:
            stack_analysis['vulnerability_indicators'].append('deep_stack_trace')

        return stack_analysis

    def _analyze_memory_layout(self, memory_maps: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze crash based on memory layout."""
        memory_analysis = {
            'vulnerability_indicators': [],
            'crash_details': {},
            'security_mitigations': []
        }

        for mem_map in memory_maps:
            objfile = mem_map.get('objfile', '')
            start = mem_map.get('start', 0)

            # Check for ASLR
            if 'libc' in objfile and start < 0x7f0000000000:
                memory_analysis['security_mitigations'].append('aslr_disabled')
            elif 'libc' in objfile:
                memory_analysis['security_mitigations'].append('aslr_enabled')

            # Check for executable stack
            if '[stack]' in objfile and 'x' in str(mem_map):
                memory_analysis['vulnerability_indicators'].append('executable_stack')

            # Check for RWX mappings
            if all(perm in str(mem_map) for perm in ['r', 'w', 'x']):
                memory_analysis['vulnerability_indicators'].append('rwx_mapping')

        return memory_analysis

    def _analyze_input_patterns(self, input_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Analyze crash based on input patterns."""
        pattern_analysis = {
            'root_cause': 'unknown',
            'vulnerability_indicators': [],
            'exploitation_complexity': 'medium'
        }

        pattern_type = input_analysis.get('pattern_type', 'unknown')

        if pattern_type == 'buffer_overflow':
            pattern_analysis.update({
                'root_cause': 'buffer_overflow',
                'vulnerability_indicators': ['buffer_boundary_violation'],
                'exploitation_complexity': 'low'
            })

        elif pattern_type == 'format_string':
            pattern_analysis.update({
                'root_cause': 'format_string_vulnerability',
                'vulnerability_indicators': ['format_string_injection'],
                'exploitation_complexity': 'medium'
            })

        # Analyze entropy
        entropy = input_analysis.get('entropy', 0)
        if entropy > 7.0:
            pattern_analysis['vulnerability_indicators'].append('high_entropy_input')
        elif entropy < 1.0:
            pattern_analysis['vulnerability_indicators'].append('low_entropy_pattern')

        # Analyze size
        size = input_analysis.get('size', 0)
        if size > 100000:
            pattern_analysis['vulnerability_indicators'].append('extremely_large_input')
        elif size > 10000:
            pattern_analysis['vulnerability_indicators'].append('large_input')

        return pattern_analysis

    def _calculate_crash_severity(self, analysis: Dict[str, Any]) -> str:
        """Calculate overall crash severity."""
        severity_score = 0

        # Base score from crash type
        crash_type = analysis.get('crash_type', '')
        if crash_type in ['segmentation_fault', 'illegal_instruction']:
            severity_score += 3
        elif crash_type in ['abort_signal', 'floating_point_exception']:
            severity_score += 2
        else:
            severity_score += 1

        # Add score for vulnerability indicators
        indicators = analysis.get('vulnerability_indicators', [])
        if 'controlled_eip' in indicators:
            severity_score += 3
        if 'controlled_register' in indicators:
            severity_score += 2
        if 'executable_stack' in indicators:
            severity_score += 2
        if 'rwx_mapping' in indicators:
            severity_score += 2

        # Reduce score for mitigations
        mitigations = analysis.get('security_mitigations', [])
        if 'aslr_enabled' in mitigations:
            severity_score -= 1

        # Determine severity level
        if severity_score >= 6:
            return CrashSeverity.CRITICAL.value
        elif severity_score >= 4:
            return CrashSeverity.HIGH.value
        elif severity_score >= 2:
            return CrashSeverity.MEDIUM.value
        else:
            return CrashSeverity.LOW.value

    def _assess_security_impact(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """Assess security impact of crash."""
        impact = {
            'confidentiality': 'none',
            'integrity': 'none',
            'availability': 'low',
            'attack_vector': 'local',
            'privileges_required': 'none',
            'user_interaction': 'required'
        }

        # Determine impact based on vulnerability indicators
        indicators = analysis.get('vulnerability_indicators', [])

        if 'controlled_eip' in indicators or 'code_injection' in indicators:
            impact.update({
                'confidentiality': 'high',
                'integrity': 'high',
                'availability': 'high',
                'attack_vector': 'network',
                'privileges_required': 'none'
            })

        elif 'controlled_register' in indicators:
            impact.update({
                'confidentiality': 'partial',
                'integrity': 'partial',
                'availability': 'high'
            })

        elif 'memory_corruption' in analysis.get('root_cause', ''):
            impact.update({
                'confidentiality': 'partial',
                'integrity': 'partial',
                'availability': 'high'
            })

        return impact

    def _assess_exploitability(self, debug_info: Dict[str, Any],
                             crash_analysis: Dict[str, Any]) -> str:
        """Assess crash exploitability."""
        exploitability_score = 0

        try:
            # Check vulnerability indicators
            indicators = crash_analysis.get('vulnerability_indicators', [])

            # High exploitability indicators
            if 'controlled_eip' in indicators:
                exploitability_score += 5  # Direct control flow hijacking
            if 'controlled_register' in indicators:
                exploitability_score += 3  # Register control
            if 'code_injection' in indicators:
                exploitability_score += 4  # Code injection possible
            if 'executable_stack' in indicators:
                exploitability_score += 3  # NX bypass not needed
            if 'rwx_mapping' in indicators:
                exploitability_score += 3  # Code execution region

            # Medium exploitability indicators
            if 'buffer_boundary_violation' in indicators:
                exploitability_score += 2  # Classic buffer overflow
            if 'format_string_injection' in indicators:
                exploitability_score += 2  # Format string vuln
            if 'heap_corruption' in indicators:
                exploitability_score += 2  # Heap exploitation
            if 'partial_register_control' in indicators:
                exploitability_score += 1  # Partial control

            # Low exploitability indicators
            if 'null_pointer_dereference' in indicators:
                exploitability_score += 1  # Usually just DoS
            if 'division_by_zero' in indicators:
                exploitability_score += 1  # Arithmetic error

            # Check for exploitation complexity factors
            complexity = crash_analysis.get('exploitation_complexity', 'medium')
            if complexity == 'low':
                exploitability_score += 2
            elif complexity == 'high':
                exploitability_score -= 1

            # Check for security mitigations
            mitigations = crash_analysis.get('security_mitigations', [])
            if 'aslr_enabled' in mitigations:
                exploitability_score -= 2  # ASLR bypass needed
            if 'dep_enabled' in mitigations:
                exploitability_score -= 2  # DEP/NX bypass needed
            if 'stack_canary' in mitigations:
                exploitability_score -= 1  # Stack canary bypass needed
            if 'cfi_enabled' in mitigations:
                exploitability_score -= 2  # CFI bypass needed

            # Check crash type
            crash_type = crash_analysis.get('crash_type', '')
            if crash_type == 'segmentation_fault':
                exploitability_score += 2  # Memory corruption
            elif crash_type == 'illegal_instruction':
                exploitability_score += 3  # Possible ROP/code injection
            elif crash_type == 'abort_signal':
                exploitability_score += 1  # Heap corruption

            # Analyze register state for additional context
            registers = debug_info.get('registers', {})
            if registers:
                # Check for interesting register values
                for reg_name, reg_value in registers.items():
                    if isinstance(reg_value, int):
                        # Check for user-controlled values
                        if reg_value in [0x41414141, 0x42424242, 0x43434343]:
                            exploitability_score += 2
                        # Check for partial control patterns
                        elif (reg_value & 0xFFFF0000) in [0x41410000, 0x42420000]:
                            exploitability_score += 1

            # Check input analysis for exploitation clues
            input_analysis = debug_info.get('input_analysis', {})
            if input_analysis:
                # Repeated patterns suggest controlled input
                patterns = input_analysis.get('repeated_patterns', [])
                if patterns:
                    exploitability_score += 1

                # Large inputs might indicate buffer overflow
                size = input_analysis.get('size', 0)
                if size > 10000:
                    exploitability_score += 1

            # Determine final exploitability assessment
            if exploitability_score >= 8:
                return 'highly_exploitable'
            elif exploitability_score >= 5:
                return 'likely_exploitable'
            elif exploitability_score >= 3:
                return 'potentially_exploitable'
            elif exploitability_score >= 1:
                return 'probably_not_exploitable'
            else:
                return 'not_exploitable'

        except Exception as e:
            self.logger.warning(f"Exploitability assessment failed: {e}")
            return 'unknown_exploitability'

    def _generate_crash_recommendations(self, crash_analysis: Dict[str, Any]) -> List[str]:
        """Generate recommendations for crash."""
        self.logger.debug(f"Generating recommendations for crash type: {crash_analysis.get('crash_type', 'unknown')}")
        return [
            "Analyze crash with debugger",
            "Check for input validation",
            "Review buffer bounds checking"
        ]

    def _minimize_binary_search(self, data: bytes, target_command: str) -> bytes:
        """Minimize using binary search."""
        # Simplified minimization
        current = data

        while len(current) > 1:
            # Try removing half
            half = len(current) // 2
            test_data = current[:half]

            # Test if it still crashes
            execution_result = self._execute_target(target_command, test_data, "/tmp")

            if execution_result['crashed']:
                current = test_data
            else:
                break

        return current

    def _minimize_delta_debugging(self, data: bytes, target_command: str) -> bytes:
        """Minimize using delta debugging."""
        # Simplified delta debugging
        return self._minimize_binary_search(data, target_command)

    def get_statistics(self) -> Dict[str, Any]:
        """Get fuzzing statistics."""
        return self.stats.copy()

    def get_crashes(self) -> Dict[str, Any]:
        """Get crash information."""
        return {
            'total_crashes': self.stats['crashes_found'],
            'unique_crashes': self.stats['unique_crashes'],
            'crash_details': list(self.unique_crashes.values())
        }

    def export_results(self, output_file: str, format: str = 'json') -> bool:
        """Export fuzzing results."""
        try:
            results = {
                'statistics': self.get_statistics(),
                'crashes': self.get_crashes(),
                'configuration': self.config
            }

            if format == 'json':
                import json
                with open(output_file, 'w') as f:
                    json.dump(results, f, indent=2)
            else:
                with open(output_file, 'w') as f:
                    f.write(str(results))

            return True

        except Exception as e:
            self.logger.error(f"Results export failed: {e}")
            return False
