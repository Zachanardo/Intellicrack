"""
This file is part of Intellicrack.
Copyright (C) 2025 Zachary Flint

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
"""

"""
Vulnerability Analyzer

Automated vulnerability analysis engine that combines static analysis,
dynamic analysis, and machine learning for comprehensive vulnerability detection.
"""

import hashlib
import logging
import os
import re
import subprocess
import time
from enum import Enum
from typing import Any, Dict, List, Optional

from ...utils.analysis.analysis_stats import AnalysisStatsGenerator
from ...utils.analysis.entropy_utils import calculate_byte_entropy
from ...utils.severity_levels import ConfidenceLevel
from .base_analyzer import BaseAnalyzer

logger = logging.getLogger(__name__)

# Optional imports for advanced analysis
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError as e:
    logger.error("Import error in vulnerability_analyzer: %s", e)
    NUMPY_AVAILABLE = False

try:
    import sklearn
    SKLEARN_AVAILABLE = True
    # Store sklearn version for compatibility checks
    SKLEARN_VERSION = sklearn.__version__
except ImportError as e:
    logger.error("Import error in vulnerability_analyzer: %s", e)
    SKLEARN_AVAILABLE = False
    SKLEARN_VERSION = None

import hmac
import pickle

# Security configuration for pickle
PICKLE_SECURITY_KEY = os.environ.get('INTELLICRACK_PICKLE_KEY', 'default-key-change-me').encode()

def secure_pickle_dump(obj, file_path):
    """Securely dump object with integrity check."""
    # Serialize object
    data = pickle.dumps(obj)

    # Calculate HMAC for integrity
    mac = hmac.new(PICKLE_SECURITY_KEY, data, hashlib.sha256).digest()

    # Write MAC + data
    with open(file_path, 'wb') as f:
        f.write(mac)
        f.write(data)

def secure_pickle_load(file_path):
    """Securely load object with integrity verification."""
    with open(file_path, 'rb') as f:
        # Read MAC
        stored_mac = f.read(32)  # SHA256 produces 32 bytes
        data = f.read()

    # Verify integrity
    expected_mac = hmac.new(PICKLE_SECURITY_KEY, data, hashlib.sha256).digest()
    if not hmac.compare_digest(stored_mac, expected_mac):
        raise ValueError("Pickle file integrity check failed - possible tampering detected")

    # Load object
    return pickle.loads(data)


class VulnerabilityType(Enum):
    """Types of vulnerabilities"""
    BUFFER_OVERFLOW = "buffer_overflow"
    FORMAT_STRING = "format_string"
    INTEGER_OVERFLOW = "integer_overflow"
    USE_AFTER_FREE = "use_after_free"
    DOUBLE_FREE = "double_free"
    NULL_POINTER_DEREFERENCE = "null_pointer_dereference"
    RACE_CONDITION = "race_condition"
    INJECTION = "injection"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    INFORMATION_DISCLOSURE = "information_disclosure"
    DENIAL_OF_SERVICE = "denial_of_service"


class AnalysisMethod(Enum):
    """Analysis methods"""
    STATIC = "static"
    DYNAMIC = "dynamic"
    HYBRID = "hybrid"
    ML_ASSISTED = "ml_assisted"


# Import ConfidenceLevel from shared utility module


class VulnerabilityAnalyzer(BaseAnalyzer):
    """
    Comprehensive vulnerability analysis engine.
    """

    def __init__(self):
        """Initialize the vulnerability analyzer.
        
        Sets up the comprehensive vulnerability detection and analysis system.
        Configures vulnerability patterns, ML models for classification, 
        and detection algorithms for identifying security weaknesses in binaries.
        """
        super().__init__()
        self.logger = logging.getLogger("IntellicrackLogger.VulnerabilityAnalyzer")

        # Log available ML libraries
        if SKLEARN_AVAILABLE:
            self.logger.debug(f"sklearn version {SKLEARN_VERSION} available for ML analysis")
        if NUMPY_AVAILABLE:
            self.logger.debug("numpy available for numerical computations")

        # Vulnerability detection patterns
        self.vulnerability_patterns = {
            VulnerabilityType.BUFFER_OVERFLOW: {
                'functions': ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf', 'memcpy'],
                'patterns': [
                    r'strcpy\s*\(\s*[^,]+,\s*[^)]+\)',
                    r'strcat\s*\(\s*[^,]+,\s*[^)]+\)',
                    r'sprintf\s*\(\s*[^,]+,\s*[^)]+\)',
                    r'gets\s*\(\s*[^)]+\)',
                    r'scanf\s*\(\s*"[^"]*%s[^"]*"'
                ],
                'severity': 'high'
            },
            VulnerabilityType.FORMAT_STRING: {
                'functions': ['printf', 'fprintf', 'sprintf', 'snprintf', 'syslog'],
                'patterns': [
                    r'printf\s*\(\s*[^"]*\w+[^)]*\)',
                    r'fprintf\s*\(\s*[^,]+,\s*[^"]*\w+[^)]*\)',
                    r'sprintf\s*\(\s*[^,]+,\s*[^"]*\w+[^)]*\)',
                    r'syslog\s*\(\s*[^,]+,\s*[^"]*\w+[^)]*\)'
                ],
                'severity': 'high'
            },
            VulnerabilityType.INTEGER_OVERFLOW: {
                'functions': ['malloc', 'calloc', 'realloc'],
                'patterns': [
                    r'malloc\s*\(\s*\w+\s*\*\s*\w+\)',
                    r'calloc\s*\(\s*\w+\s*,\s*\w+\s*\*\s*\w+\)',
                    r'\w+\s*\+\s*\w+\s*<\s*\w+',  # Integer wrap check
                    r'\w+\s*\*\s*\w+\s*/\s*\w+\s*!=\s*\w+'  # Multiplication overflow check
                ],
                'severity': 'medium'
            },
            VulnerabilityType.USE_AFTER_FREE: {
                'functions': ['free', 'delete'],
                'patterns': [
                    r'free\s*\(\s*\w+\s*\)[^}]*\w+\s*->',
                    r'delete\s+\w+[^}]*\w+\s*->',
                    r'free\s*\(\s*\w+\s*\)[^}]*\*\w+'
                ],
                'severity': 'high'
            },
            VulnerabilityType.DOUBLE_FREE: {
                'functions': ['free', 'delete'],
                'patterns': [
                    r'free\s*\(\s*\w+\s*\).*free\s*\(\s*\w+\s*\)',
                    r'delete\s+\w+.*delete\s+\w+'
                ],
                'severity': 'high'
            },
            VulnerabilityType.NULL_POINTER_DEREFERENCE: {
                'functions': [],
                'patterns': [
                    r'\*\w+\s*(?![=!<>]=)',
                    r'\w+\s*->\s*\w+',
                    r'\w+\[\s*\w+\s*\]'
                ],
                'severity': 'medium'
            }
        }

        # Dynamic analysis patterns
        self.dynamic_indicators = {
            'crash_patterns': [
                'segmentation fault',
                'access violation',
                'heap corruption',
                'stack overflow',
                'assertion failed',
                'abort trap'
            ],
            'security_violations': [
                'invalid permissions',
                'privilege violation',
                'security exception',
                'unauthorized access'
            ],
            'memory_errors': [
                'use after free',
                'double free',
                'buffer overflow',
                'heap overflow',
                'stack smashing'
            ]
        }

        # ML feature extractors
        self.feature_extractors = {
            'code_metrics': self._extract_code_metrics,
            'api_calls': self._extract_api_calls,
            'data_flow': self._extract_data_flow_features,
            'control_flow': self._extract_control_flow_features,
            'string_features': self._extract_string_features,
            'binary_features': self._extract_binary_features
        }

        # Analysis results cache
        self.analysis_cache = {}

        # ML model (would be loaded from file)
        self.ml_model = None

    def analyze_vulnerability(self,
                            target_path: str,
                            analysis_method: AnalysisMethod = AnalysisMethod.HYBRID,
                            vulnerability_types: Optional[List[VulnerabilityType]] = None) -> Dict[str, Any]:
        """
        Perform comprehensive vulnerability analysis.

        Args:
            target_path: Path to target file/directory
            analysis_method: Analysis method to use
            vulnerability_types: Specific vulnerability types to check

        Returns:
            Comprehensive vulnerability analysis results
        """
        result = {
            'success': False,
            'target_path': target_path,
            'analysis_method': analysis_method.value,
            'vulnerabilities': [],
            'statistics': {},
            'recommendations': [],
            'analysis_time': 0,
            'confidence_scores': {},
            'error': None
        }

        start_time = time.time()

        try:
            self.logger.info(f"Starting vulnerability analysis: {target_path}")

            if not os.path.exists(target_path):
                result['error'] = f"Target not found: {target_path}"
                return result

            # Check cache first
            cache_key = self._generate_cache_key(target_path, analysis_method, vulnerability_types)
            if cache_key in self.analysis_cache:
                self.logger.info("Using cached analysis results")
                return self.analysis_cache[cache_key]

            vulnerabilities = []

            # Perform analysis based on method
            if analysis_method in [AnalysisMethod.STATIC, AnalysisMethod.HYBRID]:
                static_vulns = self._static_analysis(target_path, vulnerability_types)
                vulnerabilities.extend(static_vulns)

            if analysis_method in [AnalysisMethod.DYNAMIC, AnalysisMethod.HYBRID]:
                dynamic_vulns = self._dynamic_analysis(target_path, vulnerability_types)
                vulnerabilities.extend(dynamic_vulns)

            if analysis_method == AnalysisMethod.ML_ASSISTED:
                ml_vulns = self._ml_assisted_analysis(target_path, vulnerability_types)
                vulnerabilities.extend(ml_vulns)

            # Merge and deduplicate vulnerabilities
            merged_vulns = self._merge_vulnerabilities(vulnerabilities)

            # Calculate confidence scores
            confidence_scores = self._calculate_confidence_scores(merged_vulns)

            # Generate statistics
            statistics = self._generate_analysis_statistics(merged_vulns)

            # Generate recommendations
            recommendations = self._generate_vulnerability_recommendations(merged_vulns)

            result['vulnerabilities'] = merged_vulns
            result['confidence_scores'] = confidence_scores
            result['statistics'] = statistics
            result['recommendations'] = recommendations
            result['analysis_time'] = time.time() - start_time
            result['success'] = True

            # Cache results
            self.analysis_cache[cache_key] = result

            self.logger.info(f"Vulnerability analysis complete: {len(merged_vulns)} vulnerabilities found")
            return result

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            logger.error("Error in vulnerability_analyzer: %s", e)
            return self.handle_analysis_error(result, e, start_time)

    def analyze_target(self,
                      target_info: Dict[str, Any],
                      analysis_options: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Analyze target for vulnerabilities using target information.

        Args:
            target_info: Dictionary containing target information
            analysis_options: Optional analysis configuration

        Returns:
            Analysis results dictionary
        """
        result = {
            'success': False,
            'target_info': target_info,
            'vulnerabilities': [],
            'statistics': {},
            'recommendations': [],
            'analysis_time': 0,
            'confidence_scores': {},
            'error': None
        }

        start_time = time.time()

        try:
            # Extract target path from target info
            target_path = target_info.get('path') or target_info.get('file_path') or target_info.get('target_path')

            if not target_path:
                result['error'] = "No target path provided in target_info"
                return result

            # Determine analysis method from options
            analysis_method = AnalysisMethod.HYBRID
            if analysis_options:
                method_str = analysis_options.get('analysis_method', 'hybrid')
                try:
                    analysis_method = AnalysisMethod(method_str)
                except ValueError:
                    self.logger.warning(f"Invalid analysis method: {method_str}, using hybrid")

            # Determine vulnerability types to check
            vulnerability_types = None
            if analysis_options and 'vulnerability_types' in analysis_options:
                vuln_type_strs = analysis_options['vulnerability_types']
                if isinstance(vuln_type_strs, list):
                    vulnerability_types = []
                    for vtype_str in vuln_type_strs:
                        try:
                            vulnerability_types.append(VulnerabilityType(vtype_str))
                        except ValueError:
                            self.logger.warning(f"Invalid vulnerability type: {vtype_str}")

            # Perform analysis using existing analyze_vulnerability method
            analysis_result = self.analyze_vulnerability(
                target_path=target_path,
                analysis_method=analysis_method,
                vulnerability_types=vulnerability_types
            )

            # Merge results
            result.update(analysis_result)

            # Add additional target-specific analysis if available
            if target_info.get('binary_info'):
                binary_vulns = self._analyze_binary_specific_vulnerabilities(target_info['binary_info'])
                result['vulnerabilities'].extend(binary_vulns)

            if target_info.get('network_info'):
                network_vulns = self._analyze_network_vulnerabilities(target_info['network_info'])
                result['vulnerabilities'].extend(network_vulns)

            # Recalculate statistics with additional vulnerabilities
            result['statistics'] = self._generate_analysis_statistics(result['vulnerabilities'])
            result['confidence_scores'] = self._calculate_confidence_scores(result['vulnerabilities'])
            result['recommendations'] = self._generate_vulnerability_recommendations(result['vulnerabilities'])

            result['analysis_time'] = time.time() - start_time
            result['success'] = True

            self.logger.info(f"Target analysis complete: {len(result['vulnerabilities'])} vulnerabilities found")

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            result['error'] = str(e)
            result['analysis_time'] = time.time() - start_time
            self.logger.error(f"Target analysis failed: {e}")

        return result

    def _analyze_binary_specific_vulnerabilities(self, binary_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Analyze binary-specific vulnerabilities."""
        vulnerabilities = []

        try:
            # Check for common binary protection bypasses
            if not binary_info.get('has_aslr', True):
                vulnerabilities.append({
                    'type': VulnerabilityType.PRIVILEGE_ESCALATION.value,
                    'description': 'ASLR disabled - memory layout predictable',
                    'severity': 'medium',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': AnalysisMethod.STATIC.value,
                    'file': binary_info.get('path', 'unknown'),
                    'line': 0
                })

            if not binary_info.get('has_dep', True):
                vulnerabilities.append({
                    'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                    'description': 'DEP/NX disabled - executable stack possible',
                    'severity': 'high',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': AnalysisMethod.STATIC.value,
                    'file': binary_info.get('path', 'unknown'),
                    'line': 0
                })

            if not binary_info.get('has_stack_canary', True):
                vulnerabilities.append({
                    'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                    'description': 'Stack canary disabled - stack overflow unprotected',
                    'severity': 'high',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': AnalysisMethod.STATIC.value,
                    'file': binary_info.get('path', 'unknown'),
                    'line': 0
                })

            # Check for dangerous imports
            dangerous_imports = binary_info.get('dangerous_imports', [])
            for imp in dangerous_imports:
                vulnerabilities.append({
                    'type': VulnerabilityType.PRIVILEGE_ESCALATION.value,
                    'description': f'Dangerous import detected: {imp}',
                    'severity': 'medium',
                    'confidence': ConfidenceLevel.MEDIUM.value,
                    'analysis_method': AnalysisMethod.STATIC.value,
                    'file': binary_info.get('path', 'unknown'),
                    'line': 0
                })

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Binary-specific vulnerability analysis failed: {e}")

        return vulnerabilities

    def _analyze_network_vulnerabilities(self, network_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Analyze network-related vulnerabilities."""
        vulnerabilities = []

        try:
            # Check for unencrypted communications
            if network_info.get('uses_http', False) and not network_info.get('uses_https', False):
                vulnerabilities.append({
                    'type': VulnerabilityType.INFORMATION_DISCLOSURE.value,
                    'description': 'Unencrypted HTTP communication detected',
                    'severity': 'medium',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': AnalysisMethod.STATIC.value,
                    'file': 'network_analysis',
                    'line': 0
                })

            # Check for open ports
            open_ports = network_info.get('open_ports', [])
            dangerous_ports = [21, 23, 135, 139, 445, 1433, 3389]  # Common vulnerable ports

            for port in open_ports:
                if port in dangerous_ports:
                    vulnerabilities.append({
                        'type': VulnerabilityType.PRIVILEGE_ESCALATION.value,
                        'description': f'Potentially dangerous port {port} is open',
                        'severity': 'medium',
                        'confidence': ConfidenceLevel.MEDIUM.value,
                        'analysis_method': AnalysisMethod.DYNAMIC.value,
                        'file': 'network_analysis',
                        'line': 0
                    })

            # Check for weak SSL/TLS configuration
            if network_info.get('weak_ssl', False):
                vulnerabilities.append({
                    'type': VulnerabilityType.INFORMATION_DISCLOSURE.value,
                    'description': 'Weak SSL/TLS configuration detected',
                    'severity': 'high',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': AnalysisMethod.DYNAMIC.value,
                    'file': 'network_analysis',
                    'line': 0
                })

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Network vulnerability analysis failed: {e}")

        return vulnerabilities

    def analyze_code_snippet(self,
                           code: str,
                           language: str = 'c',
                           vulnerability_types: Optional[List[VulnerabilityType]] = None) -> Dict[str, Any]:
        """
        Analyze code snippet for vulnerabilities.

        Args:
            code: Code snippet to analyze
            language: Programming language
            vulnerability_types: Specific vulnerability types to check

        Returns:
            Code snippet analysis results
        """
        result = self.create_analysis_result(
            code_hash=hashlib.sha256(code.encode()).hexdigest()[:16],
            language=language,
            vulnerabilities=[],
            line_analysis={},
            statistics={}
        )

        try:
            self.logger.info(f"Analyzing {language} code snippet")

            # Language-specific analysis configurations
            if language.lower() in ['c', 'cpp', 'c++']:
                self.logger.debug("Using C/C++ specific vulnerability patterns")
            elif language.lower() in ['python', 'py']:
                self.logger.debug("Using Python specific vulnerability patterns")
            elif language.lower() in ['javascript', 'js']:
                self.logger.debug("Using JavaScript specific vulnerability patterns")
            else:
                self.logger.debug(f"Using generic patterns for language: {language}")

            if vulnerability_types is None:
                vulnerability_types = list(VulnerabilityType)

            vulnerabilities = []
            line_analysis = {}

            # Analyze each line
            lines = code.split('\n')
            for line_num, line in enumerate(lines, 1):
                line_vulns = self._analyze_code_line(line, line_num, vulnerability_types)
                if line_vulns:
                    vulnerabilities.extend(line_vulns)
                    line_analysis[line_num] = line_vulns

            # Analyze code structure
            structure_vulns = self._analyze_code_structure(code, vulnerability_types)
            vulnerabilities.extend(structure_vulns)

            # Generate statistics
            statistics = {
                'total_lines': len(lines),
                'vulnerable_lines': len(line_analysis),
                'total_vulnerabilities': len(vulnerabilities),
                'by_type': {}
            }

            for vuln in vulnerabilities:
                vuln_type = vuln['type']
                if vuln_type not in statistics['by_type']:
                    statistics['by_type'][vuln_type] = 0
                statistics['by_type'][vuln_type] += 1

            result['vulnerabilities'] = vulnerabilities
            result['line_analysis'] = line_analysis
            result['statistics'] = statistics
            result['success'] = True

            self.logger.info(f"Code snippet analysis complete: {len(vulnerabilities)} vulnerabilities found")
            return result

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.error(f"Code snippet analysis failed: {e}")
            result['error'] = str(e)
            return result

    def _static_analysis(self, target_path: str, vulnerability_types: Optional[List[VulnerabilityType]]) -> List[Dict[str, Any]]:
        """Perform static analysis."""
        vulnerabilities = []

        try:
            self.logger.info("Performing static analysis")

            if vulnerability_types is None:
                vulnerability_types = list(VulnerabilityType)

            if os.path.isfile(target_path):
                # Analyze single file
                file_vulns = self._analyze_file_static(target_path, vulnerability_types)
                vulnerabilities.extend(file_vulns)
            else:
                # Analyze directory
                for root, dirs, files in os.walk(target_path):
                    for file in files:
                        if self._is_source_file(file):
                            file_path = os.path.join(root, file)
                            file_vulns = self._analyze_file_static(file_path, vulnerability_types)
                            vulnerabilities.extend(file_vulns)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Static analysis error: {e}")

        return vulnerabilities

    def _dynamic_analysis(self, target_path: str, vulnerability_types: Optional[List[VulnerabilityType]]) -> List[Dict[str, Any]]:
        """Perform dynamic analysis."""
        vulnerabilities = []

        try:
            self.logger.info("Performing dynamic analysis")

            if vulnerability_types is None:
                vulnerability_types = list(VulnerabilityType)

            # Execute target with various inputs
            test_inputs = self._generate_test_inputs()

            for test_input in test_inputs:
                execution_result = self._execute_with_monitoring(target_path, test_input)

                if execution_result:
                    dynamic_vulns = self._analyze_execution_result(execution_result, vulnerability_types)
                    vulnerabilities.extend(dynamic_vulns)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Dynamic analysis error: {e}")

        return vulnerabilities

    def _ml_assisted_analysis(self, target_path: str, vulnerability_types: Optional[List[VulnerabilityType]]) -> List[Dict[str, Any]]:
        """Research-based analysis using target file characteristics."""
        self.logger.info("Performing research-based vulnerability detection on %s", target_path)
        vulnerabilities = []

        try:
            # Analyze file characteristics and patterns specific to target_path
            file_info = self._get_file_characteristics(target_path)

            # Focus analysis based on requested vulnerability types
            types_to_analyze = vulnerability_types or [VulnerabilityType.BUFFER_OVERFLOW, VulnerabilityType.FORMAT_STRING]

            for vuln_type in types_to_analyze:
                if vuln_type == VulnerabilityType.BUFFER_OVERFLOW:
                    features = self._extract_buffer_overflow_features(target_path)
                    if any(score > 0.3 for score in features.values()):
                        vulnerabilities.append({
                            'type': 'Buffer Overflow',
                            'confidence': max(features.values()),
                            'file_path': target_path,
                            'file_type': file_info.get('type', 'unknown'),
                            'features': features,
                            'description': f"Potential buffer overflow patterns detected in {os.path.basename(target_path)}"
                        })

                elif vuln_type == VulnerabilityType.FORMAT_STRING:
                    features = self._extract_format_string_features(target_path)
                    if any(score > 0.2 for score in features.values()):
                        vulnerabilities.append({
                            'type': 'Format String',
                            'confidence': max(features.values()),
                            'file_path': target_path,
                            'file_type': file_info.get('type', 'unknown'),
                            'features': features,
                            'description': f"Potential format string vulnerability in {os.path.basename(target_path)}"
                        })

        except (OSError, IOError, Exception) as e:
            self.logger.debug(f"Research-based analysis failed for {target_path}: {e}")

        return vulnerabilities

    def _get_file_characteristics(self, file_path: str) -> Dict[str, Any]:
        """Get basic file characteristics for analysis."""
        characteristics = {
            'type': 'unknown',
            'size': 0,
            'is_binary': False,
            'is_source': False
        }

        try:
            if os.path.isfile(file_path):
                stat_info = os.stat(file_path)
                characteristics['size'] = stat_info.st_size

                # Determine file type from extension
                _, ext = os.path.splitext(file_path.lower())
                if ext in ['.c', '.cpp', '.h', '.hpp', '.cc', '.cxx']:
                    characteristics['type'] = 'c_source'
                    characteristics['is_source'] = True
                elif ext in ['.exe', '.dll', '.so', '.dylib']:
                    characteristics['type'] = 'binary'
                    characteristics['is_binary'] = True
                elif ext in ['.py', '.js', '.php', '.pl']:
                    characteristics['type'] = 'script'
                    characteristics['is_source'] = True

        except (OSError, IOError) as e:
            self.logger.debug(f"Failed to get file characteristics for {file_path}: {e}")

        return characteristics



    def _extract_buffer_overflow_features(self, target_path: str) -> Dict[str, float]:
        """Extract features specific to buffer overflow detection."""
        features = {}
        try:
            # Check for buffer-related patterns
            if os.path.isfile(target_path):
                with open(target_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()

                # Count unsafe buffer operations
                features['strcpy_count'] = content.count('strcpy')
                features['strcat_count'] = content.count('strcat')
                features['sprintf_count'] = content.count('sprintf')
                features['gets_count'] = content.count('gets')
                features['buffer_declarations'] = len(re.findall(r'char\s+\w+\[\d+\]', content))
                features['memcpy_count'] = content.count('memcpy')

                # Normalize to 0-1 range
                total_ops = sum(features.values())
                if total_ops > 0:
                    for key in features:
                        features[key] = min(features[key] / 10.0, 1.0)  # Cap at 10 occurrences

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Buffer overflow feature extraction error: {e}")

        return features

    def _extract_format_string_features(self, target_path: str) -> Dict[str, float]:
        """Extract features specific to format string vulnerability detection."""
        features = {}
        try:
            if os.path.isfile(target_path):
                with open(target_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()

                # Count format string functions
                features['printf_count'] = content.count('printf')
                features['fprintf_count'] = content.count('fprintf')
                features['sprintf_count'] = content.count('sprintf')
                features['syslog_count'] = content.count('syslog')

                # Check for user-controlled format strings
                user_controlled_patterns = [
                    r'printf\s*\(\s*\w+\s*\)',  # printf(user_input)
                    r'fprintf\s*\(\s*\w+\s*,\s*\w+\s*\)',  # fprintf(file, user_input)
                    r'sprintf\s*\(\s*\w+\s*,\s*\w+\s*\)'  # sprintf(buf, user_input)
                ]

                features['user_controlled_formats'] = 0
                for pattern in user_controlled_patterns:
                    features['user_controlled_formats'] += len(re.findall(pattern, content))

                # Normalize
                for key in features:
                    features[key] = min(features[key] / 5.0, 1.0)  # Cap at 5 occurrences

        except (OSError, IOError, RuntimeError, re.error) as e:
            self.logger.debug(f"Format string feature extraction error: {e}")

        return features

    def _extract_integer_overflow_features(self, target_path: str) -> Dict[str, float]:
        """Extract features specific to integer overflow detection."""
        features = {}
        try:
            if os.path.isfile(target_path):
                with open(target_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()

                # Count arithmetic operations that could overflow
                features['multiplication_ops'] = len(re.findall(r'\w+\s*\*\s*\w+', content))
                features['addition_ops'] = len(re.findall(r'\w+\s*\+\s*\w+', content))
                features['malloc_with_mult'] = len(re.findall(r'malloc\s*\(\s*\w+\s*\*\s*\w+', content))
                features['calloc_calls'] = content.count('calloc')

                # Check for overflow checks
                features['overflow_checks'] = len(re.findall(r'if\s*\(\s*\w+\s*[<>]\s*\w+\s*[+*]', content))

                # Normalize
                for key in features:
                    features[key] = min(features[key] / 20.0, 1.0)  # Cap at 20 occurrences

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Integer overflow feature extraction error: {e}")

        return features
    def _analyze_file_static(self, file_path: str, vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze single file using static analysis."""
        vulnerabilities = []

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Analyze for each vulnerability type
            for vuln_type in vulnerability_types:
                if vuln_type in self.vulnerability_patterns:
                    pattern_info = self.vulnerability_patterns[vuln_type]

                    # Check function calls
                    for func in pattern_info['functions']:
                        if func in content:
                            # Find all occurrences
                            lines = content.split('\n')
                            for line_num, line in enumerate(lines, 1):
                                if func in line:
                                    vulnerability = {
                                        'type': vuln_type.value,
                                        'file': file_path,
                                        'line': line_num,
                                        'code': line.strip(),
                                        'function': func,
                                        'severity': pattern_info['severity'],
                                        'confidence': ConfidenceLevel.MEDIUM.value,
                                        'analysis_method': 'static',
                                        'description': f'Potentially vulnerable function call: {func}'
                                    }
                                    vulnerabilities.append(vulnerability)

                    # Check regex patterns
                    for pattern in pattern_info['patterns']:
                        matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)

                        for match in matches:
                            # Find line number
                            line_num = content[:match.start()].count('\n') + 1
                            line_content = content.split('\n')[line_num - 1] if line_num <= len(content.split('\n')) else ""

                            vulnerability = {
                                'type': vuln_type.value,
                                'file': file_path,
                                'line': line_num,
                                'code': line_content.strip(),
                                'pattern': pattern,
                                'match': match.group(),
                                'severity': pattern_info['severity'],
                                'confidence': ConfidenceLevel.MEDIUM.value,
                                'analysis_method': 'static',
                                'description': f'Pattern match for {vuln_type.value}: {match.group()}'
                            }
                            vulnerabilities.append(vulnerability)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"File analysis error for {file_path}: {e}")

        return vulnerabilities

    def _analyze_code_line(self, line: str, line_num: int, vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze single line of code."""
        vulnerabilities = []

        try:
            for vuln_type in vulnerability_types:
                if vuln_type in self.vulnerability_patterns:
                    pattern_info = self.vulnerability_patterns[vuln_type]

                    # Check function calls
                    for func in pattern_info['functions']:
                        if func in line:
                            vulnerability = {
                                'type': vuln_type.value,
                                'line': line_num,
                                'code': line.strip(),
                                'function': func,
                                'severity': pattern_info['severity'],
                                'confidence': ConfidenceLevel.LOW.value,
                                'analysis_method': 'static',
                                'description': f'Function call: {func}'
                            }
                            vulnerabilities.append(vulnerability)

                    # Check patterns
                    for pattern in pattern_info['patterns']:
                        if re.search(pattern, line, re.IGNORECASE):
                            vulnerability = {
                                'type': vuln_type.value,
                                'line': line_num,
                                'code': line.strip(),
                                'pattern': pattern,
                                'severity': pattern_info['severity'],
                                'confidence': ConfidenceLevel.LOW.value,
                                'analysis_method': 'static',
                                'description': f'Pattern match: {vuln_type.value}'
                            }
                            vulnerabilities.append(vulnerability)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Line analysis error: {e}")

        return vulnerabilities

    def _analyze_code_structure(self, code: str, vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze code structure for vulnerabilities."""
        vulnerabilities = []

        # Filter analysis based on requested vulnerability types
        if vulnerability_types:
            self.logger.debug(f"Analyzing code structure for {len(vulnerability_types)} specific vulnerability types")

        try:
            # Check for common structural issues
            lines = code.split('\n')

            # Check for potential buffer overflows in loops
            for line_num, line in enumerate(lines, 1):
                # Look for loops with array access
                if any(keyword in line.lower() for keyword in ['for', 'while']) and '[' in line:
                    vulnerability = {
                        'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                        'line': line_num,
                        'code': line.strip(),
                        'severity': 'medium',
                        'confidence': ConfidenceLevel.LOW.value,
                        'analysis_method': 'static',
                        'description': 'Potential buffer overflow in loop with array access'
                    }
                    vulnerabilities.append(vulnerability)

                # Check for missing input validation
                if any(func in line for func in ['scanf', 'gets', 'read']):
                    # Look for validation in nearby lines
                    context_start = max(0, line_num - 3)
                    context_end = min(len(lines), line_num + 3)
                    context = '\n'.join(lines[context_start:context_end])

                    if not any(check in context.lower() for check in ['if', 'check', 'valid', 'length']):
                        vulnerability = {
                            'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                            'line': line_num,
                            'code': line.strip(),
                            'severity': 'high',
                            'confidence': ConfidenceLevel.MEDIUM.value,
                            'analysis_method': 'static',
                            'description': 'Input function without apparent validation'
                        }
                        vulnerabilities.append(vulnerability)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Structure analysis error: {e}")

        return vulnerabilities

    def _generate_test_inputs(self) -> List[bytes]:
        """Generate test inputs for dynamic analysis."""
        test_inputs = [
            b'A' * 100,  # Buffer overflow test
            b'A' * 1000,  # Large buffer overflow test
            b'%s%s%s%s',  # Format string test
            b'\x00' * 100,  # Null bytes
            b'\xff' * 100,  # High bytes
            b'../../../etc/passwd',  # Path traversal
            b'<script>alert(1)</script>',  # XSS test
            b"'; DROP TABLE users; --",  # SQL injection test
        ]

        return test_inputs

    def _execute_with_monitoring(self, target_path: str, test_input: bytes) -> Optional[Dict[str, Any]]:
        """Execute target with monitoring."""
        try:
            # Create temporary input file
            import tempfile
            with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:
                f.write(test_input)
                input_file = f.name

            # Execute target
            try:
                result = subprocess.run(
                    [target_path, input_file],
                    capture_output=True,
                    text=True,
                    timeout=30
                )

                execution_result = {
                    'exit_code': result.returncode,
                    'stdout': result.stdout,
                    'stderr': result.stderr,
                    'input_file': input_file,
                    'input_data': test_input
                }

                return execution_result

            except subprocess.TimeoutExpired as e:
                logger.error("Subprocess timeout in vulnerability_analyzer: %s", e)
                return {
                    'exit_code': -1,
                    'stdout': '',
                    'stderr': 'Timeout',
                    'input_file': input_file,
                    'input_data': test_input,
                    'timeout': True
                }

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Execution monitoring error: {e}")
            return None

        finally:
            # Cleanup
            try:
                os.unlink(input_file)
            except (OSError, IOError) as e:
                logger.error("Error in vulnerability_analyzer: %s", e)
                pass

    def _analyze_execution_result(self, execution_result: Dict[str, Any],
                                vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze execution result for vulnerabilities."""
        self.logger.debug(f"Analyzing execution result for vulnerability types: {[vt.value for vt in vulnerability_types]}")
        vulnerabilities = []

        try:
            # Check for crashes
            if execution_result['exit_code'] < 0:
                vulnerability = {
                    'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                    'severity': 'high',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': 'dynamic',
                    'description': f'Crash detected with exit code {execution_result["exit_code"]}',
                    'exit_code': execution_result['exit_code'],
                    'input_data': execution_result['input_data'].hex() if len(execution_result['input_data']) < 100 else 'large_input'
                }
                vulnerabilities.append(vulnerability)

            # Check stderr for error indicators
            stderr = execution_result['stderr'].lower()

            for category, patterns in self.dynamic_indicators.items():
                for pattern in patterns:
                    if pattern in stderr:
                        if category == 'crash_patterns':
                            vuln_type = VulnerabilityType.BUFFER_OVERFLOW
                        elif category == 'memory_errors':
                            if 'use after free' in pattern:
                                vuln_type = VulnerabilityType.USE_AFTER_FREE
                            elif 'double free' in pattern:
                                vuln_type = VulnerabilityType.DOUBLE_FREE
                            else:
                                vuln_type = VulnerabilityType.BUFFER_OVERFLOW
                        else:
                            vuln_type = VulnerabilityType.DENIAL_OF_SERVICE

                        vulnerability = {
                            'type': vuln_type.value,
                            'severity': 'high',
                            'confidence': ConfidenceLevel.HIGH.value,
                            'analysis_method': 'dynamic',
                            'description': f'Dynamic indicator: {pattern}',
                            'pattern': pattern,
                            'stderr': stderr
                        }
                        vulnerabilities.append(vulnerability)

            # Check for timeouts
            if execution_result.get('timeout'):
                vulnerability = {
                    'type': VulnerabilityType.DENIAL_OF_SERVICE.value,
                    'severity': 'medium',
                    'confidence': ConfidenceLevel.MEDIUM.value,
                    'analysis_method': 'dynamic',
                    'description': 'Execution timeout detected',
                    'input_data': execution_result['input_data'].hex() if len(execution_result['input_data']) < 100 else 'large_input'
                }
                vulnerabilities.append(vulnerability)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Execution result analysis error: {e}")

        return vulnerabilities

    def _extract_ml_features(self, target_path: str) -> Optional[Dict[str, Any]]:
        """Extract features for ML analysis."""
        features = {}

        try:
            if not NUMPY_AVAILABLE:
                return None

            # Extract different types of features
            for feature_type, extractor in self.feature_extractors.items():
                try:
                    feature_values = extractor(target_path)
                    if feature_values:
                        features[feature_type] = feature_values
                except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
                    self.logger.debug(f"Feature extraction error for {feature_type}: {e}")

            # If we have features, process them with numpy for normalization
            if features and NUMPY_AVAILABLE:
                try:
                    # Normalize numeric features using numpy
                    for feature_type, values in features.items():
                        if isinstance(values, dict):
                            numeric_values = []
                            keys = []
                            for k, v in values.items():
                                if isinstance(v, (int, float)):
                                    numeric_values.append(v)
                                    keys.append(k)

                            if numeric_values:
                                # Convert to numpy array for statistical processing
                                arr = np.array(numeric_values)

                                # Calculate statistics
                                features[f"{feature_type}_stats"] = {
                                    'mean': float(np.mean(arr)),
                                    'std': float(np.std(arr)),
                                    'min': float(np.min(arr)),
                                    'max': float(np.max(arr)),
                                    'median': float(np.median(arr))
                                }

                                # Normalize values (min-max normalization)
                                if np.max(arr) - np.min(arr) > 0:
                                    normalized = (arr - np.min(arr)) / (np.max(arr) - np.min(arr))
                                    for i, key in enumerate(keys):
                                        features[feature_type][f"{key}_normalized"] = float(normalized[i])

                except Exception as e:
                    self.logger.debug(f"Numpy feature processing error: {e}")

            return features if features else None

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"ML feature extraction error: {e}")
            return None

    def _extract_code_metrics(self, target_path: str) -> Dict[str, float]:
        """Extract code complexity metrics."""
        metrics = {}

        try:
            if os.path.isfile(target_path):
                files_to_analyze = [target_path]
            else:
                files_to_analyze = []
                for root, dirs, files in os.walk(target_path):
                    for file in files:
                        if self._is_source_file(file):
                            files_to_analyze.append(os.path.join(root, file))

            total_lines = 0
            total_functions = 0
            total_complexity = 0

            for file_path in files_to_analyze:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()

                    lines = len(content.split('\n'))
                    functions = content.count('function') + content.count('def ') + content.count('void ') + content.count('int ')
                    complexity = content.count('if') + content.count('for') + content.count('while') + content.count('switch')

                    total_lines += lines
                    total_functions += functions
                    total_complexity += complexity

                except (OSError, IOError) as e:
                    logger.error("Error in vulnerability_analyzer: %s", e)
                    continue

            if files_to_analyze:
                metrics = {
                    'avg_lines_per_file': total_lines / len(files_to_analyze),
                    'avg_functions_per_file': total_functions / len(files_to_analyze),
                    'avg_complexity_per_file': total_complexity / len(files_to_analyze),
                    'total_files': len(files_to_analyze)
                }

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Code metrics extraction error: {e}")

        return metrics

    def _extract_api_calls(self, target_path: str) -> Dict[str, int]:
        """Extract API call frequencies."""
        api_calls = {}

        try:
            # Common vulnerable API calls
            vulnerable_apis = [
                'strcpy', 'strcat', 'sprintf', 'gets', 'scanf',
                'malloc', 'free', 'calloc', 'realloc',
                'system', 'exec', 'popen',
                'printf', 'fprintf'
            ]

            if os.path.isfile(target_path):
                files_to_analyze = [target_path]
            else:
                files_to_analyze = []
                for root, dirs, files in os.walk(target_path):
                    for file in files:
                        if self._is_source_file(file):
                            files_to_analyze.append(os.path.join(root, file))

            for api in vulnerable_apis:
                api_calls[api] = 0

            for file_path in files_to_analyze:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()

                    for api in vulnerable_apis:
                        api_calls[api] += content.count(api)

                except (OSError, IOError) as e:
                    logger.error("Error in vulnerability_analyzer: %s", e)
                    continue

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"API calls extraction error: {e}")

        return api_calls

    def _extract_data_flow_features(self, target_path: str) -> Dict[str, float]:
        """Extract data flow features."""
        self.logger.debug(f"Extracting data flow features from: {target_path}")

        # Simplified data flow analysis based on file existence and size
        try:
            import os
            file_size = os.path.getsize(target_path) if os.path.exists(target_path) else 0

            # Estimate features based on file characteristics
            size_factor = min(file_size / 1000000, 1.0)  # Normalize to 0-1 based on 1MB

            return {
                'input_functions': size_factor * 0.3,
                'output_functions': size_factor * 0.2,
                'data_transformations': size_factor * 0.4
            }
        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.warning(f"Error extracting data flow features from {target_path}: {e}")
            return {
                'input_functions': 0.0,
                'output_functions': 0.0,
                'data_transformations': 0.0
            }

    def _extract_control_flow_features(self, target_path: str) -> Dict[str, float]:
        """Extract control flow features."""
        self.logger.debug(f"Extracting control flow features from: {target_path}")

        # Simplified control flow analysis based on file characteristics
        try:
            import os
            if not os.path.exists(target_path):
                self.logger.warning(f"Target path does not exist: {target_path}")
                return {
                    'branching_factor': 0.0,
                    'loop_complexity': 0.0,
                    'function_calls': 0.0
                }

            file_size = os.path.getsize(target_path)
            complexity_factor = min(file_size / 500000, 1.0)  # Normalize based on 500KB

            return {
                'branching_factor': complexity_factor * 0.6,
                'loop_complexity': complexity_factor * 0.4,
                'function_calls': complexity_factor * 0.8
            }
        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.warning(f"Error extracting control flow features from {target_path}: {e}")
            return {
                'branching_factor': 0.0,
                'loop_complexity': 0.0,
                'function_calls': 0.0
            }

    def _extract_string_features(self, target_path: str) -> Dict[str, int]:
        """Extract string-based features."""
        features = {}

        try:
            if os.path.isfile(target_path):
                # Extract strings from binary
                result = subprocess.run(['strings', target_path], capture_output=True, text=True)
                if result.returncode == 0:
                    strings = result.stdout.split('\n')

                    features = {
                        'total_strings': len(strings),
                        'format_strings': sum(1 for s in strings if '%' in s),
                        'long_strings': sum(1 for s in strings if len(s) > 100),
                        'suspicious_strings': sum(1 for s in strings if any(
                            keyword in s.lower() for keyword in ['password', 'admin', 'root', 'secret']
                        ))
                    }

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"String features extraction error: {e}")

        return features

    def _extract_binary_features(self, target_path: str) -> Dict[str, Any]:
        """Extract binary-specific features."""
        features = {}

        try:
            if os.path.isfile(target_path):
                # File size and entropy
                file_size = os.path.getsize(target_path)

                # Calculate entropy
                with open(target_path, 'rb') as f:
                    data = f.read(min(file_size, 10000))  # Sample first 10KB

                if data:
                    entropy = calculate_byte_entropy(data)

                    features = {
                        'file_size': file_size,
                        'entropy': entropy,
                        'executable': os.access(target_path, os.X_OK)
                    }

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Binary features extraction error: {e}")

        return features


    def _predict_vulnerabilities(self, features: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Predict vulnerabilities using ML model."""
        self.logger.debug(f"Predicting vulnerabilities using features: {list(features.keys())}")
        predictions = []

        try:
            if self.ml_model and SKLEARN_AVAILABLE:
                # Check if model can actually predict (is trained)
                if hasattr(self.ml_model, 'predict_proba') and hasattr(self.ml_model, 'n_features_in_'):
                    try:
                        # Convert features to sklearn-compatible format
                        feature_vector = self._convert_features_to_vector(features)

                        if feature_vector is not None and len(feature_vector) == self.ml_model.n_features_in_:
                            # Use actual sklearn model for prediction
                            probabilities = self.ml_model.predict_proba([feature_vector])[0]

                            # Map probabilities to vulnerability types
                            vuln_types = list(VulnerabilityType)
                            for i, prob in enumerate(probabilities):
                                if i < len(vuln_types) and prob > 0.3:  # Threshold
                                    predictions.append({
                                        'type': vuln_types[i].value,
                                        'probability': float(prob),
                                        'confidence': ConfidenceLevel.HIGH.value if prob > 0.7 else ConfidenceLevel.MEDIUM.value
                                    })
                        else:
                            # Fallback to heuristic predictions
                            self.logger.debug("Feature vector incompatible with model, using heuristics")
                            predictions = self._heuristic_predictions(features)

                    except Exception as e:
                        self.logger.debug(f"Model prediction failed: {e}, using heuristics")
                        predictions = self._heuristic_predictions(features)
                else:
                    # Model not trained, use heuristic predictions
                    predictions = self._heuristic_predictions(features)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"ML prediction error: {e}")

        return predictions

    def _convert_predictions_to_vulnerabilities(self, predictions: List[Dict[str, Any]],
                                             target_path: str) -> List[Dict[str, Any]]:
        """Convert ML predictions to vulnerability objects."""
        vulnerabilities = []

        try:
            for pred in predictions:
                if pred['probability'] > 0.5:  # Threshold for reporting
                    vulnerability = {
                        'type': pred['type'],
                        'file': target_path,
                        'severity': 'medium',
                        'confidence': pred['confidence'],
                        'analysis_method': 'ml',
                        'description': f'ML prediction: {pred["type"]} (probability: {pred["probability"]:.2f})',
                        'probability': pred['probability']
                    }
                    vulnerabilities.append(vulnerability)

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Prediction conversion error: {e}")

        return vulnerabilities

    def _merge_vulnerabilities(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Merge and deduplicate vulnerabilities."""
        merged = []
        seen = set()

        try:
            for vuln in vulnerabilities:
                # Create unique key for deduplication
                key = f"{vuln.get('type', '')}:{vuln.get('file', '')}:{vuln.get('line', 0)}"

                if key not in seen:
                    seen.add(key)
                    merged.append(vuln)
                else:
                    # Merge with existing vulnerability (increase confidence)
                    for existing in merged:
                        existing_key = f"{existing.get('type', '')}:{existing.get('file', '')}:{existing.get('line', 0)}"
                        if existing_key == key:
                            # Combine analysis methods
                            if 'analysis_methods' not in existing:
                                existing['analysis_methods'] = [existing.get('analysis_method', '')]
                            if vuln.get('analysis_method') not in existing['analysis_methods']:
                                existing['analysis_methods'].append(vuln.get('analysis_method', ''))
                            break

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Vulnerability merging error: {e}")

        return merged

    def _calculate_confidence_scores(self, vulnerabilities: List[Dict[str, Any]]) -> Dict[str, float]:
        """Calculate confidence scores."""
        scores = {}

        try:
            total_vulns = len(vulnerabilities)
            if total_vulns == 0:
                return scores

            # Count by confidence level
            confidence_counts = {}
            for vuln in vulnerabilities:
                conf = vuln.get('confidence', ConfidenceLevel.LOW.value)
                confidence_counts[conf] = confidence_counts.get(conf, 0) + 1

            # Calculate scores
            for conf, count in confidence_counts.items():
                scores[conf] = count / total_vulns

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.debug(f"Confidence calculation error: {e}")

        return scores

    def _generate_analysis_statistics(self, vulnerabilities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate analysis statistics."""
        def _compute_stats():
            return {
                'total_vulnerabilities': len(vulnerabilities),
                'by_type': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'type'),
                'by_severity': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'severity'),
                'by_confidence': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'confidence'),
                'by_method': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'analysis_method')
            }

        # Use safe statistics generation
        result = AnalysisStatsGenerator.safe_stats_generation(_compute_stats)
        if not result:
            # Return default stats on error
            return {
                'total_vulnerabilities': 0,
                'by_type': {},
                'by_severity': {},
                'by_confidence': {},
                'by_method': {}
            }
        return result

    def _generate_vulnerability_recommendations(self, vulnerabilities: List[Dict[str, Any]]) -> List[str]:
        """Generate recommendations based on found vulnerabilities."""
        def _compute_recommendations():
            recommendations = []
            vuln_types = set(vuln.get('type') for vuln in vulnerabilities)

            # Type-specific recommendations
            if VulnerabilityType.BUFFER_OVERFLOW.value in vuln_types:
                recommendations.extend([
                    "Use safe string functions (strncpy, strncat, snprintf)",
                    "Implement proper input length validation",
                    "Enable stack protection mechanisms"
                ])

            if VulnerabilityType.FORMAT_STRING.value in vuln_types:
                recommendations.extend([
                    "Never use user input directly in format strings",
                    "Use printf(\"%s\", user_input) instead of printf(user_input)",
                    "Validate all format string arguments"
                ])

            if VulnerabilityType.USE_AFTER_FREE.value in vuln_types:
                recommendations.extend([
                    "Set pointers to NULL after freeing",
                    "Use reference counting or garbage collection",
                    "Implement proper object lifetime management"
                ])

            # General recommendations
            high_severity_count = sum(1 for v in vulnerabilities if v.get('severity') == 'high')
            if high_severity_count > 5:
                recommendations.append("Consider comprehensive security code review")

            if len(vulnerabilities) > 10:
                recommendations.append("Implement automated security testing in CI/CD pipeline")

            if not recommendations:
                recommendations.append("Continue regular security assessments")

            return recommendations

        # Use safe recommendation generation
        return AnalysisStatsGenerator.safe_recommendation_generation(_compute_recommendations)

    def _is_source_file(self, filename: str) -> bool:
        """Check if file is a source code file."""
        source_extensions = ['.c', '.cpp', '.h', '.hpp', '.py', '.java', '.js', '.php', '.rb', '.go']
        return any(filename.lower().endswith(ext) for ext in source_extensions)

    def _generate_cache_key(self, target_path: str, analysis_method: AnalysisMethod,
                          vulnerability_types: Optional[List[VulnerabilityType]]) -> str:
        """Generate cache key for analysis results."""
        import hashlib

        key_data = f"{target_path}:{analysis_method.value}:"
        if vulnerability_types:
            key_data += ":".join(vt.value for vt in vulnerability_types)

        return hashlib.sha256(key_data.encode()).hexdigest()[:16]

    def get_analysis_cache(self) -> Dict[str, Any]:
        """Get current analysis cache."""
        return self.analysis_cache.copy()

    def clear_analysis_cache(self):
        """Clear analysis cache."""
        self.analysis_cache.clear()

    def load_ml_model(self, model_path: str) -> bool:
        """Load ML model for vulnerability prediction."""
        self.logger.info(f"Attempting to load ML model from: {model_path}")

        try:
            import os
            if not os.path.exists(model_path):
                self.logger.error(f"ML model file not found: {model_path}")
                return False

            if SKLEARN_AVAILABLE:
                # Load actual ML model from the specified path
                import pickle

                from sklearn.ensemble import RandomForestClassifier

                try:
                    # Try to load a saved model
                    with open(model_path, 'rb') as f:
                        self.ml_model = pickle.load(f)

                    # Verify it's a valid sklearn model
                    if hasattr(self.ml_model, 'predict') and hasattr(self.ml_model, 'predict_proba'):
                        self.logger.info(f"ML model loaded successfully from {model_path}")
                        return True
                    else:
                        self.logger.warning(f"Invalid model format in {model_path}")
                        self.ml_model = None
                        return False

                except FileNotFoundError:
                    # Create a default model if file doesn't exist
                    self.logger.info(f"Creating default RandomForest model as {model_path} not found")
                    self.ml_model = RandomForestClassifier(
                        n_estimators=100,
                        max_depth=10,
                        random_state=42
                    )
                    # Model needs to be trained before use
                    return True

                except Exception as e:
                    self.logger.error(f"Failed to load model from {model_path}: {e}")
                    self.ml_model = None
                    return False
            else:
                self.logger.warning(f"Cannot load ML model from {model_path} - sklearn not available")
                return False

        except (OSError, ValueError, RuntimeError, AttributeError, KeyError) as e:
            self.logger.error(f"ML model loading failed: {e}")
            return False

    def _convert_features_to_vector(self, features: Dict[str, Any]) -> Optional[List[float]]:
        """Convert feature dictionary to sklearn-compatible vector."""
        if not NUMPY_AVAILABLE:
            return None

        try:
            vector = []

            # Extract numeric values from features in a consistent order
            for feature_type in ['api_calls', 'strings', 'static', 'code_metrics']:
                if feature_type in features:
                    feat_data = features[feature_type]
                    if isinstance(feat_data, dict):
                        # Extract specific numeric values
                        if feature_type == 'api_calls':
                            vector.append(feat_data.get('high_risk_count', 0))
                            vector.append(feat_data.get('medium_risk_count', 0))
                            vector.append(feat_data.get('low_risk_count', 0))
                        elif feature_type == 'strings':
                            vector.append(feat_data.get('suspicious_count', 0))
                            vector.append(feat_data.get('total_count', 0))
                        elif feature_type == 'static':
                            vector.append(feat_data.get('file_size', 0) / 1000000.0)  # Normalize
                            vector.append(feat_data.get('entropy', 0))
                        elif feature_type == 'code_metrics':
                            vector.append(feat_data.get('avg_complexity_per_file', 0))
                            vector.append(feat_data.get('avg_functions_per_file', 0))

            return vector if vector else None

        except Exception as e:
            self.logger.debug(f"Feature vector conversion error: {e}")
            return None

    def _heuristic_predictions(self, features: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Generate vulnerability predictions using heuristics."""
        predictions = []

        try:
            # Calculate risk score based on features
            api_call_risk = features.get('api_calls', {}).get('high_risk_count', 0) * 0.3
            string_risk = features.get('strings', {}).get('suspicious_count', 0) * 0.2
            file_size = features.get('static', {}).get('file_size', 0)
            size_risk = min(file_size / 1000000, 1.0) * 0.1  # Normalize file size

            total_risk = api_call_risk + string_risk + size_risk
            self.logger.debug(f"Calculated total risk score: {total_risk}")

            # Generate predictions based on risk thresholds
            if total_risk > 0.5:
                predictions.append({
                    'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                    'probability': min(total_risk, 0.9),
                    'confidence': ConfidenceLevel.HIGH.value if total_risk > 0.7 else ConfidenceLevel.MEDIUM.value
                })

            if total_risk > 0.3:
                predictions.append({
                    'type': VulnerabilityType.FORMAT_STRING.value,
                    'probability': min(total_risk * 0.6, 0.8),
                    'confidence': ConfidenceLevel.MEDIUM.value if total_risk > 0.5 else ConfidenceLevel.LOW.value
                })

            if not predictions:
                # Default low-risk prediction if no significant risks found
                predictions = [{
                    'type': VulnerabilityType.INFORMATION_DISCLOSURE.value,
                    'probability': 0.1,
                    'confidence': ConfidenceLevel.LOW.value
                }]

        except Exception as e:
            self.logger.debug(f"Heuristic prediction error: {e}")

        return predictions

    def export_analysis(self, result: Dict[str, Any], output_file: str, format: str = 'json') -> bool:
        """Export analysis results to file."""
        from ...utils.analysis.analysis_exporter import AnalysisExporter
        return AnalysisExporter.export_analysis(result, output_file, format, 'vulnerability')
