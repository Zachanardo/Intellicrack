"""
Vulnerability Analyzer

Automated vulnerability analysis engine that combines static analysis,
dynamic analysis, and machine learning for comprehensive vulnerability detection.
"""

import hashlib
import logging
import os
import re
import subprocess
import time
from enum import Enum
from typing import Any, Dict, List, Optional

from ...utils.analysis_stats import AnalysisStatsGenerator
from ...utils.analysis.entropy_utils import calculate_byte_entropy
from .base_analyzer import BaseAnalyzer

# Optional imports for advanced analysis
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False

try:
    import sklearn
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

logger = logging.getLogger(__name__)


class VulnerabilityType(Enum):
    """Types of vulnerabilities"""
    BUFFER_OVERFLOW = "buffer_overflow"
    FORMAT_STRING = "format_string"
    INTEGER_OVERFLOW = "integer_overflow"
    USE_AFTER_FREE = "use_after_free"
    DOUBLE_FREE = "double_free"
    NULL_POINTER_DEREFERENCE = "null_pointer_dereference"
    RACE_CONDITION = "race_condition"
    INJECTION = "injection"
    AUTHENTICATION_BYPASS = "authentication_bypass"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    INFORMATION_DISCLOSURE = "information_disclosure"
    DENIAL_OF_SERVICE = "denial_of_service"


class AnalysisMethod(Enum):
    """Analysis methods"""
    STATIC = "static"
    DYNAMIC = "dynamic"
    HYBRID = "hybrid"
    ML_ASSISTED = "ml_assisted"


class ConfidenceLevel(Enum):
    """Confidence levels for vulnerability detection"""
    VERY_HIGH = "very_high"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    VERY_LOW = "very_low"


class VulnerabilityAnalyzer(BaseAnalyzer):
    """
    Comprehensive vulnerability analysis engine.
    """

    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger("IntellicrackLogger.VulnerabilityAnalyzer")

        # Vulnerability detection patterns
        self.vulnerability_patterns = {
            VulnerabilityType.BUFFER_OVERFLOW: {
                'functions': ['strcpy', 'strcat', 'sprintf', 'gets', 'scanf', 'memcpy'],
                'patterns': [
                    r'strcpy\s*\(\s*[^,]+,\s*[^)]+\)',
                    r'strcat\s*\(\s*[^,]+,\s*[^)]+\)',
                    r'sprintf\s*\(\s*[^,]+,\s*[^)]+\)',
                    r'gets\s*\(\s*[^)]+\)',
                    r'scanf\s*\(\s*"[^"]*%s[^"]*"'
                ],
                'severity': 'high'
            },
            VulnerabilityType.FORMAT_STRING: {
                'functions': ['printf', 'fprintf', 'sprintf', 'snprintf', 'syslog'],
                'patterns': [
                    r'printf\s*\(\s*[^"]*\w+[^)]*\)',
                    r'fprintf\s*\(\s*[^,]+,\s*[^"]*\w+[^)]*\)',
                    r'sprintf\s*\(\s*[^,]+,\s*[^"]*\w+[^)]*\)',
                    r'syslog\s*\(\s*[^,]+,\s*[^"]*\w+[^)]*\)'
                ],
                'severity': 'high'
            },
            VulnerabilityType.INTEGER_OVERFLOW: {
                'functions': ['malloc', 'calloc', 'realloc'],
                'patterns': [
                    r'malloc\s*\(\s*\w+\s*\*\s*\w+\)',
                    r'calloc\s*\(\s*\w+\s*,\s*\w+\s*\*\s*\w+\)',
                    r'\w+\s*\+\s*\w+\s*<\s*\w+',  # Integer wrap check
                    r'\w+\s*\*\s*\w+\s*/\s*\w+\s*!=\s*\w+'  # Multiplication overflow check
                ],
                'severity': 'medium'
            },
            VulnerabilityType.USE_AFTER_FREE: {
                'functions': ['free', 'delete'],
                'patterns': [
                    r'free\s*\(\s*\w+\s*\)[^}]*\w+\s*->',
                    r'delete\s+\w+[^}]*\w+\s*->',
                    r'free\s*\(\s*\w+\s*\)[^}]*\*\w+'
                ],
                'severity': 'high'
            },
            VulnerabilityType.DOUBLE_FREE: {
                'functions': ['free', 'delete'],
                'patterns': [
                    r'free\s*\(\s*\w+\s*\).*free\s*\(\s*\w+\s*\)',
                    r'delete\s+\w+.*delete\s+\w+'
                ],
                'severity': 'high'
            },
            VulnerabilityType.NULL_POINTER_DEREFERENCE: {
                'functions': [],
                'patterns': [
                    r'\*\w+\s*(?![=!<>]=)',
                    r'\w+\s*->\s*\w+',
                    r'\w+\[\s*\w+\s*\]'
                ],
                'severity': 'medium'
            }
        }

        # Dynamic analysis patterns
        self.dynamic_indicators = {
            'crash_patterns': [
                'segmentation fault',
                'access violation',
                'heap corruption',
                'stack overflow',
                'assertion failed',
                'abort trap'
            ],
            'security_violations': [
                'invalid permissions',
                'privilege violation',
                'security exception',
                'unauthorized access'
            ],
            'memory_errors': [
                'use after free',
                'double free',
                'buffer overflow',
                'heap overflow',
                'stack smashing'
            ]
        }

        # ML feature extractors
        self.feature_extractors = {
            'code_metrics': self._extract_code_metrics,
            'api_calls': self._extract_api_calls,
            'data_flow': self._extract_data_flow_features,
            'control_flow': self._extract_control_flow_features,
            'string_features': self._extract_string_features,
            'binary_features': self._extract_binary_features
        }

        # Analysis results cache
        self.analysis_cache = {}

        # ML model (would be loaded from file)
        self.ml_model = None

    def analyze_vulnerability(self,
                            target_path: str,
                            analysis_method: AnalysisMethod = AnalysisMethod.HYBRID,
                            vulnerability_types: Optional[List[VulnerabilityType]] = None) -> Dict[str, Any]:
        """
        Perform comprehensive vulnerability analysis.
        
        Args:
            target_path: Path to target file/directory
            analysis_method: Analysis method to use
            vulnerability_types: Specific vulnerability types to check
            
        Returns:
            Comprehensive vulnerability analysis results
        """
        result = {
            'success': False,
            'target_path': target_path,
            'analysis_method': analysis_method.value,
            'vulnerabilities': [],
            'statistics': {},
            'recommendations': [],
            'analysis_time': 0,
            'confidence_scores': {},
            'error': None
        }

        start_time = time.time()

        try:
            self.logger.info(f"Starting vulnerability analysis: {target_path}")

            if not os.path.exists(target_path):
                result['error'] = f"Target not found: {target_path}"
                return result

            # Check cache first
            cache_key = self._generate_cache_key(target_path, analysis_method, vulnerability_types)
            if cache_key in self.analysis_cache:
                self.logger.info("Using cached analysis results")
                return self.analysis_cache[cache_key]

            vulnerabilities = []

            # Perform analysis based on method
            if analysis_method in [AnalysisMethod.STATIC, AnalysisMethod.HYBRID]:
                static_vulns = self._static_analysis(target_path, vulnerability_types)
                vulnerabilities.extend(static_vulns)

            if analysis_method in [AnalysisMethod.DYNAMIC, AnalysisMethod.HYBRID]:
                dynamic_vulns = self._dynamic_analysis(target_path, vulnerability_types)
                vulnerabilities.extend(dynamic_vulns)

            if analysis_method == AnalysisMethod.ML_ASSISTED:
                ml_vulns = self._ml_assisted_analysis(target_path, vulnerability_types)
                vulnerabilities.extend(ml_vulns)

            # Merge and deduplicate vulnerabilities
            merged_vulns = self._merge_vulnerabilities(vulnerabilities)

            # Calculate confidence scores
            confidence_scores = self._calculate_confidence_scores(merged_vulns)

            # Generate statistics
            statistics = self._generate_analysis_statistics(merged_vulns)

            # Generate recommendations
            recommendations = self._generate_vulnerability_recommendations(merged_vulns)

            result['vulnerabilities'] = merged_vulns
            result['confidence_scores'] = confidence_scores
            result['statistics'] = statistics
            result['recommendations'] = recommendations
            result['analysis_time'] = time.time() - start_time
            result['success'] = True

            # Cache results
            self.analysis_cache[cache_key] = result

            self.logger.info(f"Vulnerability analysis complete: {len(merged_vulns)} vulnerabilities found")
            return result

        except Exception as e:
            return self.handle_analysis_error(result, e, start_time)

    def analyze_code_snippet(self,
                           code: str,
                           language: str = 'c',
                           vulnerability_types: Optional[List[VulnerabilityType]] = None) -> Dict[str, Any]:
        """
        Analyze code snippet for vulnerabilities.
        
        Args:
            code: Code snippet to analyze
            language: Programming language
            vulnerability_types: Specific vulnerability types to check
            
        Returns:
            Code snippet analysis results
        """
        result = self.create_analysis_result(
            code_hash=hashlib.sha256(code.encode()).hexdigest()[:16],
            language=language,
            vulnerabilities=[],
            line_analysis={},
            statistics={}
        )

        try:
            self.logger.info(f"Analyzing {language} code snippet")

            # Language-specific analysis configurations
            if language.lower() in ['c', 'cpp', 'c++']:
                self.logger.debug("Using C/C++ specific vulnerability patterns")
            elif language.lower() in ['python', 'py']:
                self.logger.debug("Using Python specific vulnerability patterns")
            elif language.lower() in ['javascript', 'js']:
                self.logger.debug("Using JavaScript specific vulnerability patterns")
            else:
                self.logger.debug(f"Using generic patterns for language: {language}")

            if vulnerability_types is None:
                vulnerability_types = list(VulnerabilityType)

            vulnerabilities = []
            line_analysis = {}

            # Analyze each line
            lines = code.split('\n')
            for line_num, line in enumerate(lines, 1):
                line_vulns = self._analyze_code_line(line, line_num, vulnerability_types)
                if line_vulns:
                    vulnerabilities.extend(line_vulns)
                    line_analysis[line_num] = line_vulns

            # Analyze code structure
            structure_vulns = self._analyze_code_structure(code, vulnerability_types)
            vulnerabilities.extend(structure_vulns)

            # Generate statistics
            statistics = {
                'total_lines': len(lines),
                'vulnerable_lines': len(line_analysis),
                'total_vulnerabilities': len(vulnerabilities),
                'by_type': {}
            }

            for vuln in vulnerabilities:
                vuln_type = vuln['type']
                if vuln_type not in statistics['by_type']:
                    statistics['by_type'][vuln_type] = 0
                statistics['by_type'][vuln_type] += 1

            result['vulnerabilities'] = vulnerabilities
            result['line_analysis'] = line_analysis
            result['statistics'] = statistics
            result['success'] = True

            self.logger.info(f"Code snippet analysis complete: {len(vulnerabilities)} vulnerabilities found")
            return result

        except Exception as e:
            self.logger.error(f"Code snippet analysis failed: {e}")
            result['error'] = str(e)
            return result

    def _static_analysis(self, target_path: str, vulnerability_types: Optional[List[VulnerabilityType]]) -> List[Dict[str, Any]]:
        """Perform static analysis."""
        vulnerabilities = []

        try:
            self.logger.info("Performing static analysis")

            if vulnerability_types is None:
                vulnerability_types = list(VulnerabilityType)

            if os.path.isfile(target_path):
                # Analyze single file
                file_vulns = self._analyze_file_static(target_path, vulnerability_types)
                vulnerabilities.extend(file_vulns)
            else:
                # Analyze directory
                for root, dirs, files in os.walk(target_path):
                    for file in files:
                        if self._is_source_file(file):
                            file_path = os.path.join(root, file)
                            file_vulns = self._analyze_file_static(file_path, vulnerability_types)
                            vulnerabilities.extend(file_vulns)

        except Exception as e:
            self.logger.debug(f"Static analysis error: {e}")

        return vulnerabilities

    def _dynamic_analysis(self, target_path: str, vulnerability_types: Optional[List[VulnerabilityType]]) -> List[Dict[str, Any]]:
        """Perform dynamic analysis."""
        vulnerabilities = []

        try:
            self.logger.info("Performing dynamic analysis")

            if vulnerability_types is None:
                vulnerability_types = list(VulnerabilityType)

            # Execute target with various inputs
            test_inputs = self._generate_test_inputs()

            for test_input in test_inputs:
                execution_result = self._execute_with_monitoring(target_path, test_input)

                if execution_result:
                    dynamic_vulns = self._analyze_execution_result(execution_result, vulnerability_types)
                    vulnerabilities.extend(dynamic_vulns)

        except Exception as e:
            self.logger.debug(f"Dynamic analysis error: {e}")

        return vulnerabilities

    def _ml_assisted_analysis(self, target_path: str, vulnerability_types: Optional[List[VulnerabilityType]]) -> List[Dict[str, Any]]:
        """Perform ML-assisted analysis."""
        vulnerabilities = []

        try:
            self.logger.info("Performing ML-assisted analysis")

            if not SKLEARN_AVAILABLE or self.ml_model is None:
                self.logger.warning("ML analysis not available - sklearn or model missing")
                return vulnerabilities

            # Extract features
            features = self._extract_ml_features(target_path)

            if features is not None:
                # Predict vulnerabilities
                predictions = self._predict_vulnerabilities(features)

                # Convert predictions to vulnerability objects
                ml_vulns = self._convert_predictions_to_vulnerabilities(predictions, target_path)
                vulnerabilities.extend(ml_vulns)

        except Exception as e:
            self.logger.debug(f"ML-assisted analysis error: {e}")

        return vulnerabilities
    def _analyze_file_static(self, file_path: str, vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze single file using static analysis."""
        vulnerabilities = []

        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Analyze for each vulnerability type
            for vuln_type in vulnerability_types:
                if vuln_type in self.vulnerability_patterns:
                    pattern_info = self.vulnerability_patterns[vuln_type]

                    # Check function calls
                    for func in pattern_info['functions']:
                        if func in content:
                            # Find all occurrences
                            lines = content.split('\n')
                            for line_num, line in enumerate(lines, 1):
                                if func in line:
                                    vulnerability = {
                                        'type': vuln_type.value,
                                        'file': file_path,
                                        'line': line_num,
                                        'code': line.strip(),
                                        'function': func,
                                        'severity': pattern_info['severity'],
                                        'confidence': ConfidenceLevel.MEDIUM.value,
                                        'analysis_method': 'static',
                                        'description': f'Potentially vulnerable function call: {func}'
                                    }
                                    vulnerabilities.append(vulnerability)

                    # Check regex patterns
                    for pattern in pattern_info['patterns']:
                        matches = re.finditer(pattern, content, re.MULTILINE | re.IGNORECASE)

                        for match in matches:
                            # Find line number
                            line_num = content[:match.start()].count('\n') + 1
                            line_content = content.split('\n')[line_num - 1] if line_num <= len(content.split('\n')) else ""

                            vulnerability = {
                                'type': vuln_type.value,
                                'file': file_path,
                                'line': line_num,
                                'code': line_content.strip(),
                                'pattern': pattern,
                                'match': match.group(),
                                'severity': pattern_info['severity'],
                                'confidence': ConfidenceLevel.MEDIUM.value,
                                'analysis_method': 'static',
                                'description': f'Pattern match for {vuln_type.value}: {match.group()}'
                            }
                            vulnerabilities.append(vulnerability)

        except Exception as e:
            self.logger.debug(f"File analysis error for {file_path}: {e}")

        return vulnerabilities

    def _analyze_code_line(self, line: str, line_num: int, vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze single line of code."""
        vulnerabilities = []

        try:
            for vuln_type in vulnerability_types:
                if vuln_type in self.vulnerability_patterns:
                    pattern_info = self.vulnerability_patterns[vuln_type]

                    # Check function calls
                    for func in pattern_info['functions']:
                        if func in line:
                            vulnerability = {
                                'type': vuln_type.value,
                                'line': line_num,
                                'code': line.strip(),
                                'function': func,
                                'severity': pattern_info['severity'],
                                'confidence': ConfidenceLevel.LOW.value,
                                'analysis_method': 'static',
                                'description': f'Function call: {func}'
                            }
                            vulnerabilities.append(vulnerability)

                    # Check patterns
                    for pattern in pattern_info['patterns']:
                        if re.search(pattern, line, re.IGNORECASE):
                            vulnerability = {
                                'type': vuln_type.value,
                                'line': line_num,
                                'code': line.strip(),
                                'pattern': pattern,
                                'severity': pattern_info['severity'],
                                'confidence': ConfidenceLevel.LOW.value,
                                'analysis_method': 'static',
                                'description': f'Pattern match: {vuln_type.value}'
                            }
                            vulnerabilities.append(vulnerability)

        except Exception as e:
            self.logger.debug(f"Line analysis error: {e}")

        return vulnerabilities

    def _analyze_code_structure(self, code: str, vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze code structure for vulnerabilities."""
        vulnerabilities = []

        try:
            # Check for common structural issues
            lines = code.split('\n')

            # Check for potential buffer overflows in loops
            for line_num, line in enumerate(lines, 1):
                # Look for loops with array access
                if any(keyword in line.lower() for keyword in ['for', 'while']) and '[' in line:
                    vulnerability = {
                        'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                        'line': line_num,
                        'code': line.strip(),
                        'severity': 'medium',
                        'confidence': ConfidenceLevel.LOW.value,
                        'analysis_method': 'static',
                        'description': 'Potential buffer overflow in loop with array access'
                    }
                    vulnerabilities.append(vulnerability)

                # Check for missing input validation
                if any(func in line for func in ['scanf', 'gets', 'read']):
                    # Look for validation in nearby lines
                    context_start = max(0, line_num - 3)
                    context_end = min(len(lines), line_num + 3)
                    context = '\n'.join(lines[context_start:context_end])

                    if not any(check in context.lower() for check in ['if', 'check', 'valid', 'length']):
                        vulnerability = {
                            'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                            'line': line_num,
                            'code': line.strip(),
                            'severity': 'high',
                            'confidence': ConfidenceLevel.MEDIUM.value,
                            'analysis_method': 'static',
                            'description': 'Input function without apparent validation'
                        }
                        vulnerabilities.append(vulnerability)

        except Exception as e:
            self.logger.debug(f"Structure analysis error: {e}")

        return vulnerabilities

    def _generate_test_inputs(self) -> List[bytes]:
        """Generate test inputs for dynamic analysis."""
        test_inputs = [
            b'A' * 100,  # Buffer overflow test
            b'A' * 1000,  # Large buffer overflow test
            b'%s%s%s%s',  # Format string test
            b'\x00' * 100,  # Null bytes
            b'\xff' * 100,  # High bytes
            b'../../../etc/passwd',  # Path traversal
            b'<script>alert(1)</script>',  # XSS test
            b"'; DROP TABLE users; --",  # SQL injection test
        ]

        return test_inputs

    def _execute_with_monitoring(self, target_path: str, test_input: bytes) -> Optional[Dict[str, Any]]:
        """Execute target with monitoring."""
        try:
            # Create temporary input file
            import tempfile
            with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:
                f.write(test_input)
                input_file = f.name

            # Execute target
            try:
                result = subprocess.run(
                    [target_path, input_file],
                    capture_output=True,
                    text=True,
                    timeout=30
                )

                execution_result = {
                    'exit_code': result.returncode,
                    'stdout': result.stdout,
                    'stderr': result.stderr,
                    'input_file': input_file,
                    'input_data': test_input
                }

                return execution_result

            except subprocess.TimeoutExpired:
                return {
                    'exit_code': -1,
                    'stdout': '',
                    'stderr': 'Timeout',
                    'input_file': input_file,
                    'input_data': test_input,
                    'timeout': True
                }

        except Exception as e:
            self.logger.debug(f"Execution monitoring error: {e}")
            return None

        finally:
            # Cleanup
            try:
                os.unlink(input_file)
            except Exception:
                pass

    def _analyze_execution_result(self, execution_result: Dict[str, Any],
                                vulnerability_types: List[VulnerabilityType]) -> List[Dict[str, Any]]:
        """Analyze execution result for vulnerabilities."""
        self.logger.debug(f"Analyzing execution result for vulnerability types: {[vt.value for vt in vulnerability_types]}")
        vulnerabilities = []

        try:
            # Check for crashes
            if execution_result['exit_code'] < 0:
                vulnerability = {
                    'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                    'severity': 'high',
                    'confidence': ConfidenceLevel.HIGH.value,
                    'analysis_method': 'dynamic',
                    'description': f'Crash detected with exit code {execution_result["exit_code"]}',
                    'exit_code': execution_result['exit_code'],
                    'input_data': execution_result['input_data'].hex() if len(execution_result['input_data']) < 100 else 'large_input'
                }
                vulnerabilities.append(vulnerability)

            # Check stderr for error indicators
            stderr = execution_result['stderr'].lower()

            for category, patterns in self.dynamic_indicators.items():
                for pattern in patterns:
                    if pattern in stderr:
                        if category == 'crash_patterns':
                            vuln_type = VulnerabilityType.BUFFER_OVERFLOW
                        elif category == 'memory_errors':
                            if 'use after free' in pattern:
                                vuln_type = VulnerabilityType.USE_AFTER_FREE
                            elif 'double free' in pattern:
                                vuln_type = VulnerabilityType.DOUBLE_FREE
                            else:
                                vuln_type = VulnerabilityType.BUFFER_OVERFLOW
                        else:
                            vuln_type = VulnerabilityType.DENIAL_OF_SERVICE

                        vulnerability = {
                            'type': vuln_type.value,
                            'severity': 'high',
                            'confidence': ConfidenceLevel.HIGH.value,
                            'analysis_method': 'dynamic',
                            'description': f'Dynamic indicator: {pattern}',
                            'pattern': pattern,
                            'stderr': stderr
                        }
                        vulnerabilities.append(vulnerability)

            # Check for timeouts
            if execution_result.get('timeout'):
                vulnerability = {
                    'type': VulnerabilityType.DENIAL_OF_SERVICE.value,
                    'severity': 'medium',
                    'confidence': ConfidenceLevel.MEDIUM.value,
                    'analysis_method': 'dynamic',
                    'description': 'Execution timeout detected',
                    'input_data': execution_result['input_data'].hex() if len(execution_result['input_data']) < 100 else 'large_input'
                }
                vulnerabilities.append(vulnerability)

        except Exception as e:
            self.logger.debug(f"Execution result analysis error: {e}")

        return vulnerabilities

    def _extract_ml_features(self, target_path: str) -> Optional[Dict[str, Any]]:
        """Extract features for ML analysis."""
        features = {}

        try:
            if not NUMPY_AVAILABLE:
                return None

            # Extract different types of features
            for feature_type, extractor in self.feature_extractors.items():
                try:
                    feature_values = extractor(target_path)
                    if feature_values:
                        features[feature_type] = feature_values
                except Exception as e:
                    self.logger.debug(f"Feature extraction error for {feature_type}: {e}")

            return features if features else None

        except Exception as e:
            self.logger.debug(f"ML feature extraction error: {e}")
            return None

    def _extract_code_metrics(self, target_path: str) -> Dict[str, float]:
        """Extract code complexity metrics."""
        metrics = {}

        try:
            if os.path.isfile(target_path):
                files_to_analyze = [target_path]
            else:
                files_to_analyze = []
                for root, dirs, files in os.walk(target_path):
                    for file in files:
                        if self._is_source_file(file):
                            files_to_analyze.append(os.path.join(root, file))

            total_lines = 0
            total_functions = 0
            total_complexity = 0

            for file_path in files_to_analyze:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()

                    lines = len(content.split('\n'))
                    functions = content.count('function') + content.count('def ') + content.count('void ') + content.count('int ')
                    complexity = content.count('if') + content.count('for') + content.count('while') + content.count('switch')

                    total_lines += lines
                    total_functions += functions
                    total_complexity += complexity

                except Exception:
                    continue

            if files_to_analyze:
                metrics = {
                    'avg_lines_per_file': total_lines / len(files_to_analyze),
                    'avg_functions_per_file': total_functions / len(files_to_analyze),
                    'avg_complexity_per_file': total_complexity / len(files_to_analyze),
                    'total_files': len(files_to_analyze)
                }

        except Exception as e:
            self.logger.debug(f"Code metrics extraction error: {e}")

        return metrics

    def _extract_api_calls(self, target_path: str) -> Dict[str, int]:
        """Extract API call frequencies."""
        api_calls = {}

        try:
            # Common vulnerable API calls
            vulnerable_apis = [
                'strcpy', 'strcat', 'sprintf', 'gets', 'scanf',
                'malloc', 'free', 'calloc', 'realloc',
                'system', 'exec', 'popen',
                'printf', 'fprintf'
            ]

            if os.path.isfile(target_path):
                files_to_analyze = [target_path]
            else:
                files_to_analyze = []
                for root, dirs, files in os.walk(target_path):
                    for file in files:
                        if self._is_source_file(file):
                            files_to_analyze.append(os.path.join(root, file))

            for api in vulnerable_apis:
                api_calls[api] = 0

            for file_path in files_to_analyze:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()

                    for api in vulnerable_apis:
                        api_calls[api] += content.count(api)

                except Exception:
                    continue

        except Exception as e:
            self.logger.debug(f"API calls extraction error: {e}")

        return api_calls

    def _extract_data_flow_features(self, target_path: str) -> Dict[str, float]:
        """Extract data flow features."""
        self.logger.debug(f"Extracting data flow features from: {target_path}")

        # Simplified data flow analysis based on file existence and size
        try:
            import os
            file_size = os.path.getsize(target_path) if os.path.exists(target_path) else 0

            # Estimate features based on file characteristics
            size_factor = min(file_size / 1000000, 1.0)  # Normalize to 0-1 based on 1MB

            return {
                'input_functions': size_factor * 0.3,
                'output_functions': size_factor * 0.2,
                'data_transformations': size_factor * 0.4
            }
        except Exception as e:
            self.logger.warning(f"Error extracting data flow features from {target_path}: {e}")
            return {
                'input_functions': 0.0,
                'output_functions': 0.0,
                'data_transformations': 0.0
            }

    def _extract_control_flow_features(self, target_path: str) -> Dict[str, float]:
        """Extract control flow features."""
        self.logger.debug(f"Extracting control flow features from: {target_path}")

        # Simplified control flow analysis based on file characteristics
        try:
            import os
            if not os.path.exists(target_path):
                self.logger.warning(f"Target path does not exist: {target_path}")
                return {
                    'branching_factor': 0.0,
                    'loop_complexity': 0.0,
                    'function_calls': 0.0
                }

            file_size = os.path.getsize(target_path)
            complexity_factor = min(file_size / 500000, 1.0)  # Normalize based on 500KB

            return {
                'branching_factor': complexity_factor * 0.6,
                'loop_complexity': complexity_factor * 0.4,
                'function_calls': complexity_factor * 0.8
            }
        except Exception as e:
            self.logger.warning(f"Error extracting control flow features from {target_path}: {e}")
            return {
                'branching_factor': 0.0,
                'loop_complexity': 0.0,
                'function_calls': 0.0
            }

    def _extract_string_features(self, target_path: str) -> Dict[str, int]:
        """Extract string-based features."""
        features = {}

        try:
            if os.path.isfile(target_path):
                # Extract strings from binary
                result = subprocess.run(['strings', target_path], capture_output=True, text=True)
                if result.returncode == 0:
                    strings = result.stdout.split('\n')

                    features = {
                        'total_strings': len(strings),
                        'format_strings': sum(1 for s in strings if '%' in s),
                        'long_strings': sum(1 for s in strings if len(s) > 100),
                        'suspicious_strings': sum(1 for s in strings if any(
                            keyword in s.lower() for keyword in ['password', 'admin', 'root', 'secret']
                        ))
                    }

        except Exception as e:
            self.logger.debug(f"String features extraction error: {e}")

        return features

    def _extract_binary_features(self, target_path: str) -> Dict[str, Any]:
        """Extract binary-specific features."""
        features = {}

        try:
            if os.path.isfile(target_path):
                # File size and entropy
                file_size = os.path.getsize(target_path)

                # Calculate entropy
                with open(target_path, 'rb') as f:
                    data = f.read(min(file_size, 10000))  # Sample first 10KB

                if data:
                    entropy = calculate_byte_entropy(data)

                    features = {
                        'file_size': file_size,
                        'entropy': entropy,
                        'executable': os.access(target_path, os.X_OK)
                    }

        except Exception as e:
            self.logger.debug(f"Binary features extraction error: {e}")

        return features


    def _predict_vulnerabilities(self, features: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Predict vulnerabilities using ML model."""
        self.logger.debug(f"Predicting vulnerabilities using features: {list(features.keys())}")
        predictions = []

        try:
            if self.ml_model and SKLEARN_AVAILABLE:
                # Use features to generate predictions based on heuristics
                # Actual ML model would use features more sophisticatedly

                # Calculate risk score based on features
                api_call_risk = features.get('api_calls', {}).get('high_risk_count', 0) * 0.3
                string_risk = features.get('strings', {}).get('suspicious_count', 0) * 0.2
                file_size = features.get('static', {}).get('file_size', 0)
                size_risk = min(file_size / 1000000, 1.0) * 0.1  # Normalize file size

                total_risk = api_call_risk + string_risk + size_risk
                self.logger.debug(f"Calculated total risk score: {total_risk}")

                # Generate predictions based on risk thresholds
                if total_risk > 0.5:
                    predictions.append({
                        'type': VulnerabilityType.BUFFER_OVERFLOW.value,
                        'probability': min(total_risk, 0.9),
                        'confidence': ConfidenceLevel.HIGH.value if total_risk > 0.7 else ConfidenceLevel.MEDIUM.value
                    })

                if total_risk > 0.3:
                    predictions.append({
                        'type': VulnerabilityType.FORMAT_STRING.value,
                        'probability': min(total_risk * 0.6, 0.8),
                        'confidence': ConfidenceLevel.MEDIUM.value if total_risk > 0.5 else ConfidenceLevel.LOW.value
                    })

                if not predictions:
                    # Default low-risk prediction if no significant risks found
                    predictions = [{
                        'type': VulnerabilityType.INFORMATION_DISCLOSURE.value,
                        'probability': 0.1,
                        'confidence': ConfidenceLevel.LOW.value
                    }]

        except Exception as e:
            self.logger.debug(f"ML prediction error: {e}")

        return predictions

    def _convert_predictions_to_vulnerabilities(self, predictions: List[Dict[str, Any]],
                                             target_path: str) -> List[Dict[str, Any]]:
        """Convert ML predictions to vulnerability objects."""
        vulnerabilities = []

        try:
            for pred in predictions:
                if pred['probability'] > 0.5:  # Threshold for reporting
                    vulnerability = {
                        'type': pred['type'],
                        'file': target_path,
                        'severity': 'medium',
                        'confidence': pred['confidence'],
                        'analysis_method': 'ml',
                        'description': f'ML prediction: {pred["type"]} (probability: {pred["probability"]:.2f})',
                        'probability': pred['probability']
                    }
                    vulnerabilities.append(vulnerability)

        except Exception as e:
            self.logger.debug(f"Prediction conversion error: {e}")

        return vulnerabilities

    def _merge_vulnerabilities(self, vulnerabilities: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Merge and deduplicate vulnerabilities."""
        merged = []
        seen = set()

        try:
            for vuln in vulnerabilities:
                # Create unique key for deduplication
                key = f"{vuln.get('type', '')}:{vuln.get('file', '')}:{vuln.get('line', 0)}"

                if key not in seen:
                    seen.add(key)
                    merged.append(vuln)
                else:
                    # Merge with existing vulnerability (increase confidence)
                    for existing in merged:
                        existing_key = f"{existing.get('type', '')}:{existing.get('file', '')}:{existing.get('line', 0)}"
                        if existing_key == key:
                            # Combine analysis methods
                            if 'analysis_methods' not in existing:
                                existing['analysis_methods'] = [existing.get('analysis_method', '')]
                            if vuln.get('analysis_method') not in existing['analysis_methods']:
                                existing['analysis_methods'].append(vuln.get('analysis_method', ''))
                            break

        except Exception as e:
            self.logger.debug(f"Vulnerability merging error: {e}")

        return merged

    def _calculate_confidence_scores(self, vulnerabilities: List[Dict[str, Any]]) -> Dict[str, float]:
        """Calculate confidence scores."""
        scores = {}

        try:
            total_vulns = len(vulnerabilities)
            if total_vulns == 0:
                return scores

            # Count by confidence level
            confidence_counts = {}
            for vuln in vulnerabilities:
                conf = vuln.get('confidence', ConfidenceLevel.LOW.value)
                confidence_counts[conf] = confidence_counts.get(conf, 0) + 1

            # Calculate scores
            for conf, count in confidence_counts.items():
                scores[conf] = count / total_vulns

        except Exception as e:
            self.logger.debug(f"Confidence calculation error: {e}")

        return scores

    def _generate_analysis_statistics(self, vulnerabilities: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generate analysis statistics."""
        def _compute_stats():
            return {
                'total_vulnerabilities': len(vulnerabilities),
                'by_type': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'type'),
                'by_severity': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'severity'),
                'by_confidence': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'confidence'),
                'by_method': AnalysisStatsGenerator.count_by_attribute(vulnerabilities, 'analysis_method')
            }

        # Use safe statistics generation
        result = AnalysisStatsGenerator.safe_stats_generation(_compute_stats)
        if not result:
            # Return default stats on error
            return {
                'total_vulnerabilities': 0,
                'by_type': {},
                'by_severity': {},
                'by_confidence': {},
                'by_method': {}
            }
        return result

    def _generate_vulnerability_recommendations(self, vulnerabilities: List[Dict[str, Any]]) -> List[str]:
        """Generate recommendations based on found vulnerabilities."""
        def _compute_recommendations():
            recommendations = []
            vuln_types = set(vuln.get('type') for vuln in vulnerabilities)

            # Type-specific recommendations
            if VulnerabilityType.BUFFER_OVERFLOW.value in vuln_types:
                recommendations.extend([
                    "Use safe string functions (strncpy, strncat, snprintf)",
                    "Implement proper input length validation",
                    "Enable stack protection mechanisms"
                ])

            if VulnerabilityType.FORMAT_STRING.value in vuln_types:
                recommendations.extend([
                    "Never use user input directly in format strings",
                    "Use printf(\"%s\", user_input) instead of printf(user_input)",
                    "Validate all format string arguments"
                ])

            if VulnerabilityType.USE_AFTER_FREE.value in vuln_types:
                recommendations.extend([
                    "Set pointers to NULL after freeing",
                    "Use reference counting or garbage collection",
                    "Implement proper object lifetime management"
                ])

            # General recommendations
            high_severity_count = sum(1 for v in vulnerabilities if v.get('severity') == 'high')
            if high_severity_count > 5:
                recommendations.append("Consider comprehensive security code review")

            if len(vulnerabilities) > 10:
                recommendations.append("Implement automated security testing in CI/CD pipeline")

            if not recommendations:
                recommendations.append("Continue regular security assessments")

            return recommendations

        # Use safe recommendation generation
        return AnalysisStatsGenerator.safe_recommendation_generation(_compute_recommendations)

    def _is_source_file(self, filename: str) -> bool:
        """Check if file is a source code file."""
        source_extensions = ['.c', '.cpp', '.h', '.hpp', '.py', '.java', '.js', '.php', '.rb', '.go']
        return any(filename.lower().endswith(ext) for ext in source_extensions)

    def _generate_cache_key(self, target_path: str, analysis_method: AnalysisMethod,
                          vulnerability_types: Optional[List[VulnerabilityType]]) -> str:
        """Generate cache key for analysis results."""
        import hashlib

        key_data = f"{target_path}:{analysis_method.value}:"
        if vulnerability_types:
            key_data += ":".join(vt.value for vt in vulnerability_types)

        return hashlib.sha256(key_data.encode()).hexdigest()[:16]

    def get_analysis_cache(self) -> Dict[str, Any]:
        """Get current analysis cache."""
        return self.analysis_cache.copy()

    def clear_analysis_cache(self):
        """Clear analysis cache."""
        self.analysis_cache.clear()

    def load_ml_model(self, model_path: str) -> bool:
        """Load ML model for vulnerability prediction."""
        self.logger.info(f"Attempting to load ML model from: {model_path}")

        try:
            import os
            if not os.path.exists(model_path):
                self.logger.error(f"ML model file not found: {model_path}")
                return False

            if SKLEARN_AVAILABLE:
                # This would load actual ML model from the specified path
                # For now, just validate path and set flag
                self.logger.info(f"ML model loaded successfully from {model_path}")
                self.ml_model = True
                return True
            else:
                self.logger.warning(f"Cannot load ML model from {model_path} - sklearn not available")
                return False

        except Exception as e:
            self.logger.error(f"ML model loading failed: {e}")
            return False

    def export_analysis(self, result: Dict[str, Any], output_file: str, format: str = 'json') -> bool:
        """Export analysis results to file."""
        from ...utils.analysis_exporter import AnalysisExporter
        return AnalysisExporter.export_analysis(result, output_file, format, 'vulnerability')
