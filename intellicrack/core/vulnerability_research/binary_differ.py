"""
Binary Diffing Engine

Automated binary comparison and patch analysis for vulnerability research.
Identifies security-relevant changes between binary versions.
"""

import hashlib
import logging
import os
import subprocess
import time
from enum import Enum
from typing import Any, Dict, List

from ...utils.analysis.analysis_stats import AnalysisStatsGenerator
from .base_analyzer import BaseAnalyzer
from .common_enums import SecurityRelevance

# Optional imports for advanced analysis
try:
    import capstone
    CAPSTONE_AVAILABLE = True
except ImportError:
    CAPSTONE_AVAILABLE = False

try:
    import lief
    LIEF_AVAILABLE = True
except ImportError:
    LIEF_AVAILABLE = False

logger = logging.getLogger(__name__)


class DiffType(Enum):
    """Types of binary differences"""
    FUNCTION_ADDED = "function_added"
    FUNCTION_REMOVED = "function_removed"
    FUNCTION_MODIFIED = "function_modified"
    DATA_CHANGED = "data_changed"
    IMPORT_ADDED = "import_added"
    IMPORT_REMOVED = "import_removed"
    SECTION_ADDED = "section_added"
    SECTION_REMOVED = "section_removed"
    SECTION_MODIFIED = "section_modified"
    SECURITY_FEATURE_ADDED = "security_feature_added"
    SECURITY_FEATURE_REMOVED = "security_feature_removed"


class BinaryDiffer(BaseAnalyzer):
    """
    Advanced binary diffing engine for vulnerability research.
    """

    def __init__(self):
        super().__init__()
        self.logger = logging.getLogger("IntellicrackLogger.BinaryDiffer")

        # Security-relevant function patterns
        self.security_functions = {
            'memory': ['malloc', 'free', 'calloc', 'realloc', 'memcpy', 'memset', 'strcpy', 'strcat', 'sprintf'],
            'crypto': ['encrypt', 'decrypt', 'hash', 'random', 'aes', 'rsa', 'sha', 'md5'],
            'auth': ['login', 'authenticate', 'verify', 'check', 'validate', 'authorize'],
            'network': ['socket', 'connect', 'bind', 'listen', 'send', 'recv', 'http', 'ssl'],
            'file': ['fopen', 'fread', 'fwrite', 'open', 'read', 'write', 'chmod', 'chown'],
            'process': ['exec', 'system', 'fork', 'spawn', 'thread', 'process']
        }

        # Security mitigations
        self.security_mitigations = {
            'stack_protection': ['__stack_chk_fail', '__stack_chk_guard'],
            'aslr': ['__randomize_layout', 'ASLR'],
            'dep': ['NX', 'DEP', 'EXECUTE_PROTECT'],
            'cfg': ['__guard_dispatch', 'CFG'],
            'cfi': ['__cfi_check', '__typeid'],
            'fortify': ['__fortify_function', '__builtin___memcpy_chk']
        }

        # Vulnerability patterns
        self.vuln_patterns = {
            'buffer_overflow': [
                'strcpy', 'strcat', 'sprintf', 'gets', 'scanf',
                'memcpy_unsafe', 'strncpy_unsafe'
            ],
            'format_string': ['printf', 'sprintf', 'fprintf', 'snprintf'],
            'integer_overflow': ['add_overflow', 'mul_overflow', 'size_check'],
            'use_after_free': ['free', 'delete', 'use_after'],
            'double_free': ['double_free', 'free_twice'],
            'null_deref': ['null_check', 'deref_null']
        }

        # Analysis cache
        self.analysis_cache = {}

    def compare_binaries(self,
                        old_binary: str,
                        new_binary: str,
                        analysis_level: str = 'comprehensive') -> Dict[str, Any]:
        """
        Compare two binary files and identify security-relevant differences.

        Args:
            old_binary: Path to original binary
            new_binary: Path to updated binary
            analysis_level: Level of analysis ('basic', 'intermediate', 'comprehensive')

        Returns:
            Comprehensive diff analysis results
        """
        result = {
            'success': False,
            'old_binary': old_binary,
            'new_binary': new_binary,
            'analysis_level': analysis_level,
            'differences': [],
            'security_impact': {},
            'statistics': {},
            'recommendations': [],
            'analysis_time': 0,
            'error': None
        }

        start_time = time.time()

        try:
            self.logger.info(f"Comparing binaries: {old_binary} vs {new_binary}")

            # Validate input files
            if not os.path.exists(old_binary):
                result['error'] = f"Old binary not found: {old_binary}"
                return result

            if not os.path.exists(new_binary):
                result['error'] = f"New binary not found: {new_binary}"
                return result

            # Perform analysis based on level
            differences = []

            # Basic analysis - always performed
            basic_diffs = self._basic_analysis(old_binary, new_binary)
            differences.extend(basic_diffs)

            if analysis_level in ['intermediate', 'comprehensive']:
                # Intermediate analysis
                intermediate_diffs = self._intermediate_analysis(old_binary, new_binary)
                differences.extend(intermediate_diffs)

            if analysis_level == 'comprehensive':
                # Comprehensive analysis
                comprehensive_diffs = self._comprehensive_analysis(old_binary, new_binary)
                differences.extend(comprehensive_diffs)

            # Analyze security impact
            security_impact = self._analyze_security_impact(differences)

            # Generate statistics
            statistics = self._generate_statistics(differences, old_binary, new_binary)

            # Generate recommendations
            recommendations = self._generate_recommendations(differences, security_impact)

            result['differences'] = differences
            result['security_impact'] = security_impact
            result['statistics'] = statistics
            result['recommendations'] = recommendations
            result['analysis_time'] = time.time() - start_time
            result['success'] = True

            self.logger.info(f"Binary comparison complete: {len(differences)} differences found")
            return result

        except Exception as e:
            return self.handle_analysis_error(result, e, start_time)

    def analyze_patch(self,
                     patch_file: str,
                     target_binary: str) -> Dict[str, Any]:
        """
        Analyze a patch file for security implications.

        Args:
            patch_file: Path to patch file
            target_binary: Path to target binary

        Returns:
            Patch analysis results
        """
        result = self.create_analysis_result(
            patch_file=patch_file,
            target_binary=target_binary,
            patch_type=None,
            security_fixes=[],
            potential_vulnerabilities=[],
            impact_assessment={}
        )

        try:
            self.logger.info(f"Analyzing patch: {patch_file}")

            if not os.path.exists(patch_file):
                result['error'] = f"Patch file not found: {patch_file}"
                return result

            # Read and parse patch
            with open(patch_file, 'r') as f:
                patch_content = f.read()

            # Analyze patch content
            patch_analysis = self._analyze_patch_content(patch_content)

            # Map to binary changes if target provided
            if target_binary and os.path.exists(target_binary):
                binary_impact = self._map_patch_to_binary(patch_content, target_binary)
                result.update(binary_impact)

            result.update(patch_analysis)
            result['success'] = True

            self.logger.info("Patch analysis complete")
            return result

        except Exception as e:
            self.logger.error(f"Patch analysis failed: {e}")
            result['error'] = str(e)
            return result

    def find_similar_functions(self,
                              binary_path: str,
                              target_function: bytes,
                              similarity_threshold: float = 0.8) -> List[Dict[str, Any]]:
        """
        Find functions similar to a target function in a binary.

        Args:
            binary_path: Path to binary to search
            target_function: Target function bytes
            similarity_threshold: Minimum similarity score

        Returns:
            List of similar functions found
        """
        similar_functions = []

        try:
            self.logger.info(f"Finding similar functions in {binary_path}")

            # Extract functions from binary
            functions = self._extract_functions(binary_path)

            # Compare each function to target
            for func_addr, func_data in functions.items():
                similarity = self._calculate_function_similarity(target_function, func_data['bytes'])

                if similarity >= similarity_threshold:
                    similar_functions.append({
                        'address': func_addr,
                        'similarity': similarity,
                        'size': len(func_data['bytes']),
                        'name': func_data.get('name', f'sub_{func_addr:x}'),
                        'analysis': func_data.get('analysis', {})
                    })

            # Sort by similarity
            similar_functions.sort(key=lambda x: x['similarity'], reverse=True)

            self.logger.info(f"Found {len(similar_functions)} similar functions")
            return similar_functions

        except Exception as e:
            self.logger.error(f"Similar function search failed: {e}")
            return similar_functions

    def _basic_analysis(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Perform basic binary analysis."""
        differences = []

        try:
            # File size comparison
            old_size = os.path.getsize(old_binary)
            new_size = os.path.getsize(new_binary)

            if old_size != new_size:
                differences.append({
                    'type': DiffType.DATA_CHANGED.value,
                    'description': f'File size changed: {old_size} -> {new_size}',
                    'security_relevance': SecurityRelevance.LOW.value,
                    'old_value': old_size,
                    'new_value': new_size
                })

            # Hash comparison
            old_hash = self._calculate_file_hash(old_binary)
            new_hash = self._calculate_file_hash(new_binary)

            if old_hash != new_hash:
                differences.append({
                    'type': DiffType.DATA_CHANGED.value,
                    'description': 'Binary content changed',
                    'security_relevance': SecurityRelevance.MEDIUM.value,
                    'old_value': old_hash,
                    'new_value': new_hash
                })

            # Section comparison using hexdump
            old_sections = self._get_basic_sections(old_binary)
            new_sections = self._get_basic_sections(new_binary)

            # Compare sections
            for section_name in set(old_sections.keys()) | set(new_sections.keys()):
                if section_name in old_sections and section_name not in new_sections:
                    differences.append({
                        'type': DiffType.SECTION_REMOVED.value,
                        'description': f'Section removed: {section_name}',
                        'security_relevance': SecurityRelevance.MEDIUM.value,
                        'section': section_name
                    })
                elif section_name not in old_sections and section_name in new_sections:
                    differences.append({
                        'type': DiffType.SECTION_ADDED.value,
                        'description': f'Section added: {section_name}',
                        'security_relevance': SecurityRelevance.MEDIUM.value,
                        'section': section_name
                    })
                else:
                    # Both binaries have this section - check if content changed
                    if section_name in old_sections and section_name in new_sections:
                        old_content = old_sections[section_name]
                        new_content = new_sections[section_name]

                        if old_content != new_content:
                            # Calculate content change metrics
                            old_size = len(old_content) if isinstance(old_content, str) else 0
                            new_size = len(new_content) if isinstance(new_content, str) else 0
                            size_change = new_size - old_size

                            differences.append({
                                'type': DiffType.SECTION_MODIFIED.value,
                                'description': f'Section modified: {section_name} (size change: {size_change:+d})',
                                'security_relevance': SecurityRelevance.MEDIUM.value,
                                'section': section_name,
                                'old_size': old_size,
                                'new_size': new_size,
                                'size_change': size_change
                            })

        except Exception as e:
            self.logger.debug(f"Basic analysis error: {e}")

        return differences

    def _intermediate_analysis(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Perform intermediate binary analysis."""
        differences = []

        try:
            # Import table comparison
            old_imports = self._extract_imports(old_binary)
            new_imports = self._extract_imports(new_binary)

            # Find import differences
            old_import_set = set(old_imports)
            new_import_set = set(new_imports)

            added_imports = new_import_set - old_import_set
            removed_imports = old_import_set - new_import_set

            for import_name in added_imports:
                security_relevance = self._assess_import_security_relevance(import_name)
                differences.append({
                    'type': DiffType.IMPORT_ADDED.value,
                    'description': f'Import added: {import_name}',
                    'security_relevance': security_relevance.value,
                    'import': import_name
                })

            for import_name in removed_imports:
                security_relevance = self._assess_import_security_relevance(import_name)
                differences.append({
                    'type': DiffType.IMPORT_REMOVED.value,
                    'description': f'Import removed: {import_name}',
                    'security_relevance': security_relevance.value,
                    'import': import_name
                })

            # String comparison
            old_strings = self._extract_strings(old_binary)
            new_strings = self._extract_strings(new_binary)

            string_diffs = self._compare_strings(old_strings, new_strings)
            differences.extend(string_diffs)

            # Function signature analysis (if tools available)
            if CAPSTONE_AVAILABLE:
                func_diffs = self._compare_function_signatures(old_binary, new_binary)
                differences.extend(func_diffs)

        except Exception as e:
            self.logger.debug(f"Intermediate analysis error: {e}")

        return differences

    def _comprehensive_analysis(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Perform comprehensive binary analysis."""
        differences = []

        try:
            # Control flow analysis
            if CAPSTONE_AVAILABLE:
                cfg_diffs = self._compare_control_flow(old_binary, new_binary)
                differences.extend(cfg_diffs)

            # Security mitigation analysis
            mitigation_diffs = self._compare_security_mitigations(old_binary, new_binary)
            differences.extend(mitigation_diffs)

            # Vulnerability pattern analysis
            vuln_diffs = self._compare_vulnerability_patterns(old_binary, new_binary)
            differences.extend(vuln_diffs)

            # Advanced binary structure analysis
            if LIEF_AVAILABLE:
                structure_diffs = self._compare_binary_structure(old_binary, new_binary)
                differences.extend(structure_diffs)

        except Exception as e:
            self.logger.debug(f"Comprehensive analysis error: {e}")

        return differences
    def _analyze_security_impact(self, differences: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze the security impact of identified differences."""
        impact = {
            'overall_risk': SecurityRelevance.LOW.value,
            'categories': {},
            'critical_changes': [],
            'mitigation_changes': [],
            'vulnerability_indicators': []
        }

        try:
            # Categorize differences
            categories = {}
            critical_changes = []
            mitigation_changes = []
            vulnerability_indicators = []

            for diff in differences:
                diff_type = diff['type']
                security_level = diff['security_relevance']

                # Count by category
                if diff_type not in categories:
                    categories[diff_type] = 0
                categories[diff_type] += 1

                # Identify critical changes
                if security_level in ['critical', 'high']:
                    critical_changes.append(diff)

                # Identify mitigation changes
                if 'mitigation' in diff.get('description', '').lower():
                    mitigation_changes.append(diff)

                # Identify vulnerability indicators
                if any(vuln in diff.get('description', '').lower()
                       for vuln in ['overflow', 'underflow', 'injection', 'bypass']):
                    vulnerability_indicators.append(diff)

            # Determine overall risk
            if critical_changes:
                impact['overall_risk'] = SecurityRelevance.CRITICAL.value
            elif len([d for d in differences if d['security_relevance'] == 'high']) > 3:
                impact['overall_risk'] = SecurityRelevance.HIGH.value
            elif len([d for d in differences if d['security_relevance'] == 'medium']) > 5:
                impact['overall_risk'] = SecurityRelevance.MEDIUM.value

            impact['categories'] = categories
            impact['critical_changes'] = critical_changes
            impact['mitigation_changes'] = mitigation_changes
            impact['vulnerability_indicators'] = vulnerability_indicators

        except Exception as e:
            self.logger.debug(f"Security impact analysis error: {e}")

        return impact

    def _generate_statistics(self, differences: List[Dict[str, Any]],
                           old_binary: str, new_binary: str) -> Dict[str, Any]:
        """Generate statistics about the binary comparison."""
        def _compute_stats():
            stats = {
                'total_differences': len(differences),
                'by_type': AnalysisStatsGenerator.count_by_attribute(differences, 'type'),
                'by_security_level': AnalysisStatsGenerator.count_by_attribute(differences, 'security_relevance'),
                'file_info': {},
                'change_summary': {}
            }

            # File information
            stats['file_info'] = {
                'old_binary': {
                    'path': old_binary,
                    'size': os.path.getsize(old_binary),
                    'hash': self._calculate_file_hash(old_binary)
                },
                'new_binary': {
                    'path': new_binary,
                    'size': os.path.getsize(new_binary),
                    'hash': self._calculate_file_hash(new_binary)
                }
            }

            # Change summary
            stats['change_summary'] = {
                'additions': len([d for d in differences if 'added' in d['type']]),
                'removals': len([d for d in differences if 'removed' in d['type']]),
                'modifications': len([d for d in differences if 'modified' in d['type']]),
                'security_relevant': len([d for d in differences if d['security_relevance'] in ['high', 'critical']])
            }

            return stats

        # Use safe statistics generation
        result = AnalysisStatsGenerator.safe_stats_generation(_compute_stats)
        if not result:
            # Return default stats on error
            return {
                'total_differences': 0,
                'by_type': {},
                'by_security_level': {},
                'file_info': {},
                'change_summary': {}
            }
        return result

    def _generate_recommendations(self, differences: List[Dict[str, Any]],
                                security_impact: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on analysis results."""
        def _compute_recommendations():
            recommendations = []

            # Critical changes recommendations
            if security_impact['critical_changes']:
                recommendations.append("CRITICAL: Review all critical security changes immediately")
                recommendations.append("Perform thorough security testing before deployment")

            # Mitigation changes
            if security_impact['mitigation_changes']:
                recommendations.append("Review security mitigation changes for potential bypasses")

            # Vulnerability indicators
            if security_impact['vulnerability_indicators']:
                recommendations.append("Investigate potential vulnerability indicators")
                recommendations.append("Consider additional security testing and code review")

            # Import changes
            import_changes = [d for d in differences if 'import' in d['type']]
            if import_changes:
                recommendations.append("Review import table changes for security implications")

            # Function changes
            function_changes = [d for d in differences if 'function' in d['type']]
            if function_changes:
                recommendations.append("Analyze function changes for logic vulnerabilities")

            # General recommendations
            if len(differences) > 20:
                recommendations.append("Large number of changes detected - consider staged testing")

            if not recommendations:
                recommendations.append("Changes appear minimal - standard testing recommended")

            return recommendations

        # Use safe recommendation generation
        return AnalysisStatsGenerator.safe_recommendation_generation(_compute_recommendations)

    # Helper methods for binary analysis

    def _calculate_file_hash(self, file_path: str) -> str:
        """Calculate SHA256 hash of file."""
        try:
            hasher = hashlib.sha256()
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hasher.update(chunk)
            return hasher.hexdigest()
        except Exception:
            return ""

    def _get_basic_sections(self, binary_path: str) -> Dict[str, str]:
        """Extract basic section information using hexdump."""
        sections = {}

        try:
            # Use objdump if available
            result = subprocess.run(['objdump', '-h', binary_path],
                                  capture_output=True, text=True)

            if result.returncode == 0:
                lines = result.stdout.split('\n')
                for line in lines:
                    if 'CONTENTS' in line:
                        parts = line.split()
                        if len(parts) >= 2:
                            section_name = parts[1]
                            sections[section_name] = line.strip()
            else:
                # Fallback to basic file analysis
                with open(binary_path, 'rb') as f:
                    data = f.read(1024)  # Read first 1KB
                    sections['header'] = data.hex()

        except Exception as e:
            self.logger.debug(f"Section extraction error: {e}")

        return sections

    def _extract_imports(self, binary_path: str) -> List[str]:
        """Extract import table from binary."""
        imports = []

        try:
            # Try objdump first
            result = subprocess.run(['objdump', '-T', binary_path],
                                  capture_output=True, text=True)

            if result.returncode == 0:
                lines = result.stdout.split('\n')
                for line in lines:
                    if 'DF' in line or '*UND*' in line:
                        parts = line.split()
                        if len(parts) >= 7:
                            import_name = parts[-1]
                            imports.append(import_name)
            else:
                # Try nm command
                result = subprocess.run(['nm', '-D', binary_path],
                                      capture_output=True, text=True)
                if result.returncode == 0:
                    lines = result.stdout.split('\n')
                    for line in lines:
                        if 'U ' in line:
                            parts = line.split()
                            if len(parts) >= 2:
                                imports.append(parts[-1])

        except Exception as e:
            self.logger.debug(f"Import extraction error: {e}")

        return list(set(imports))  # Remove duplicates

    def _extract_strings(self, binary_path: str) -> List[str]:
        """Extract strings from binary."""
        strings = []

        try:
            # Use strings command
            result = subprocess.run(['strings', '-n', '4', binary_path],
                                  capture_output=True, text=True)

            if result.returncode == 0:
                strings = result.stdout.strip().split('\n')
                # Filter for meaningful strings
                strings = [s for s in strings if len(s) >= 4 and len(s) <= 100]

        except Exception as e:
            self.logger.debug(f"String extraction error: {e}")

        return strings

    def _compare_strings(self, old_strings: List[str], new_strings: List[str]) -> List[Dict[str, Any]]:
        """Compare string tables between binaries."""
        differences = []

        try:
            old_set = set(old_strings)
            new_set = set(new_strings)

            added_strings = new_set - old_set
            removed_strings = old_set - new_set

            # Look for security-relevant strings
            security_keywords = ['password', 'secret', 'key', 'token', 'admin', 'root', 'auth']

            # Analyze added strings for security impact
            for string in added_strings:
                security_relevance = SecurityRelevance.LOW

                # Enhance security analysis with keyword matching
                string_lower = string.lower()
                matched_keywords = [kw for kw in security_keywords if kw in string_lower]

                if matched_keywords:
                    security_relevance = SecurityRelevance.MEDIUM
                    # Log matched security keywords for investigation
                    self.logger.info(f"Added string contains security keywords {matched_keywords}: {string[:30]}...")

                differences.append({
                    'type': 'string_added',
                    'description': f'String added: {string[:50]}...',
                    'security_relevance': security_relevance.value,
                    'string': string,
                    'matched_keywords': matched_keywords
                })

            # Analyze removed strings for security impact
            for string in removed_strings:
                security_relevance = SecurityRelevance.LOW

                # Enhance security analysis with keyword matching
                string_lower = string.lower()
                matched_keywords = [kw for kw in security_keywords if kw in string_lower]

                if matched_keywords:
                    security_relevance = SecurityRelevance.MEDIUM
                    # Log matched security keywords for investigation
                    self.logger.info(f"Removed string contains security keywords {matched_keywords}: {string[:30]}...")

                differences.append({
                    'type': 'string_removed',
                    'description': f'String removed: {string[:50]}...',
                    'security_relevance': security_relevance.value,
                    'string': string,
                    'matched_keywords': matched_keywords
                })

        except Exception as e:
            self.logger.debug(f"String comparison error: {e}")

        return differences

    def _assess_import_security_relevance(self, import_name: str) -> SecurityRelevance:
        """Assess security relevance of an import."""
        import_lower = import_name.lower()

        # Check against security function categories
        for category, functions in self.security_functions.items():
            if any(func in import_lower for func in functions):
                if category in ['crypto', 'auth']:
                    return SecurityRelevance.HIGH
                elif category in ['memory', 'network']:
                    return SecurityRelevance.MEDIUM
                else:
                    return SecurityRelevance.LOW

        return SecurityRelevance.LOW

    def _assess_function_security_relevance(self, function_name: str) -> SecurityRelevance:
        """Assess security relevance of a function based on its name."""
        func_lower = function_name.lower()

        # Check against security function categories
        for category, functions in self.security_functions.items():
            if any(func in func_lower for func in functions):
                if category in ['crypto', 'auth']:
                    return SecurityRelevance.HIGH
                elif category in ['memory', 'network', 'process']:
                    return SecurityRelevance.MEDIUM
                else:
                    return SecurityRelevance.LOW

        # Check for vulnerability patterns
        for vuln_type, patterns in self.vuln_patterns.items():
            if any(pattern in func_lower for pattern in patterns):
                return SecurityRelevance.HIGH

        # Check for security mitigations
        for mitigation, indicators in self.security_mitigations.items():
            if any(indicator.lower() in func_lower for indicator in indicators):
                return SecurityRelevance.MEDIUM

        return SecurityRelevance.LOW

    def _compare_function_signatures(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Compare function signatures using Capstone."""
        differences = []

        if not CAPSTONE_AVAILABLE:
            self.logger.debug(f"Capstone not available for function signature comparison of {old_binary} vs {new_binary}")
            return differences

        try:
            # Log the binaries being compared
            self.logger.debug(f"Comparing function signatures: {old_binary} vs {new_binary}")

            # Extract functions from both binaries
            old_functions = self._extract_functions(old_binary)
            new_functions = self._extract_functions(new_binary)

            # Compare function counts and basic metrics
            if len(old_functions) != len(new_functions):
                differences.append({
                    'type': DiffType.FUNCTION_MODIFIED.value,
                    'description': f'Function count changed: {len(old_functions)} -> {len(new_functions)}',
                    'security_relevance': SecurityRelevance.MEDIUM.value,
                    'old_count': len(old_functions),
                    'new_count': len(new_functions)
                })

            # Find added/removed functions
            old_names = {f.get('name', f'sub_{addr:x}') for addr, f in old_functions.items()}
            new_names = {f.get('name', f'sub_{addr:x}') for addr, f in new_functions.items()}

            added_funcs = new_names - old_names
            removed_funcs = old_names - new_names

            for func_name in added_funcs:
                security_relevance = self._assess_function_security_relevance(func_name)
                differences.append({
                    'type': DiffType.FUNCTION_ADDED.value,
                    'description': f'Function added: {func_name}',
                    'security_relevance': security_relevance.value,
                    'function': func_name
                })

            for func_name in removed_funcs:
                security_relevance = self._assess_function_security_relevance(func_name)
                differences.append({
                    'type': DiffType.FUNCTION_REMOVED.value,
                    'description': f'Function removed: {func_name}',
                    'security_relevance': security_relevance.value,
                    'function': func_name
                })

        except Exception as e:
            self.logger.debug(f"Function signature comparison error for {old_binary} vs {new_binary}: {e}")

        return differences

    def _compare_control_flow(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Compare control flow graphs."""
        differences = []

        try:
            self.logger.debug(f"Comparing control flow: {old_binary} vs {new_binary}")

            # Basic control flow indicators through string analysis
            old_strings = self._extract_strings(old_binary)
            new_strings = self._extract_strings(new_binary)

            # Look for control flow related patterns
            control_flow_patterns = {
                'jumps': ['jmp', 'je', 'jne', 'jz', 'jnz', 'call', 'ret'],
                'conditions': ['if', 'else', 'switch', 'case', 'cmp', 'test'],
                'loops': ['for', 'while', 'loop', 'jmp'],
                'error_handlers': ['catch', 'except', 'finally', 'error', 'fail']
            }

            old_cf_indicators = {cat: 0 for cat in control_flow_patterns}
            new_cf_indicators = {cat: 0 for cat in control_flow_patterns}

            # Count control flow indicators
            for string in old_strings:
                for category, patterns in control_flow_patterns.items():
                    if any(pattern in string.lower() for pattern in patterns):
                        old_cf_indicators[category] += 1

            for string in new_strings:
                for category, patterns in control_flow_patterns.items():
                    if any(pattern in string.lower() for pattern in patterns):
                        new_cf_indicators[category] += 1

            # Compare indicators
            for category in control_flow_patterns:
                if old_cf_indicators[category] != new_cf_indicators[category]:
                    change = new_cf_indicators[category] - old_cf_indicators[category]
                    differences.append({
                        'type': 'control_flow_change',
                        'description': f'Control flow {category} changed by {change:+d} ({old_cf_indicators[category]} -> {new_cf_indicators[category]})',
                        'security_relevance': SecurityRelevance.MEDIUM.value if abs(change) > 5 else SecurityRelevance.LOW.value,
                        'category': category,
                        'old_count': old_cf_indicators[category],
                        'new_count': new_cf_indicators[category]
                    })

            # If we have significant changes in error handlers, that's security relevant
            if abs(new_cf_indicators['error_handlers'] - old_cf_indicators['error_handlers']) > 3:
                differences.append({
                    'type': 'error_handling_change',
                    'description': 'Significant change in error handling detected',
                    'security_relevance': SecurityRelevance.HIGH.value
                })

        except Exception as e:
            self.logger.debug(f"Control flow comparison error for {old_binary} vs {new_binary}: {e}")

        return differences

    def _compare_security_mitigations(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Compare security mitigations between binaries."""
        differences = []

        try:
            old_mitigations = self._detect_security_mitigations(old_binary)
            new_mitigations = self._detect_security_mitigations(new_binary)

            # Compare mitigation presence
            for mitigation, indicators in self.security_mitigations.items():
                old_present = old_mitigations.get(mitigation, False)
                new_present = new_mitigations.get(mitigation, False)

                if old_present and not new_present:
                    differences.append({
                        'type': DiffType.SECURITY_FEATURE_REMOVED.value,
                        'description': f'Security mitigation removed: {mitigation}',
                        'security_relevance': SecurityRelevance.CRITICAL.value,
                        'mitigation': mitigation
                    })
                elif not old_present and new_present:
                    differences.append({
                        'type': DiffType.SECURITY_FEATURE_ADDED.value,
                        'description': f'Security mitigation added: {mitigation}',
                        'security_relevance': SecurityRelevance.HIGH.value,
                        'mitigation': mitigation
                    })

        except Exception as e:
            self.logger.debug(f"Security mitigation comparison error: {e}")

        return differences

    def _detect_security_mitigations(self, binary_path: str) -> Dict[str, bool]:
        """Detect security mitigations in binary."""
        mitigations = {}

        try:
            # Extract strings and symbols
            strings = self._extract_strings(binary_path)
            imports = self._extract_imports(binary_path)

            all_symbols = strings + imports
            all_text = ' '.join(all_symbols).lower()

            # Check for each mitigation
            for mitigation, indicators in self.security_mitigations.items():
                mitigations[mitigation] = any(
                    indicator.lower() in all_text for indicator in indicators
                )

        except Exception as e:
            self.logger.debug(f"Mitigation detection error: {e}")

        return mitigations

    def _compare_vulnerability_patterns(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Compare vulnerability patterns between binaries."""
        differences = []

        try:
            old_patterns = self._detect_vulnerability_patterns(old_binary)
            new_patterns = self._detect_vulnerability_patterns(new_binary)

            # Compare pattern presence
            for vuln_type, patterns in self.vuln_patterns.items():
                old_count = old_patterns.get(vuln_type, 0)
                new_count = new_patterns.get(vuln_type, 0)

                if new_count > old_count:
                    differences.append({
                        'type': 'vulnerability_pattern_increased',
                        'description': f'Potential {vuln_type} patterns increased: {old_count} -> {new_count}',
                        'security_relevance': SecurityRelevance.HIGH.value,
                        'vulnerability_type': vuln_type,
                        'old_count': old_count,
                        'new_count': new_count
                    })
                elif new_count < old_count:
                    differences.append({
                        'type': 'vulnerability_pattern_decreased',
                        'description': f'Potential {vuln_type} patterns decreased: {old_count} -> {new_count}',
                        'security_relevance': SecurityRelevance.MEDIUM.value,
                        'vulnerability_type': vuln_type,
                        'old_count': old_count,
                        'new_count': new_count
                    })

        except Exception as e:
            self.logger.debug(f"Vulnerability pattern comparison error: {e}")

        return differences

    def _detect_vulnerability_patterns(self, binary_path: str) -> Dict[str, int]:
        """Detect vulnerability patterns in binary."""
        patterns = {}

        try:
            # Extract strings and imports
            strings = self._extract_strings(binary_path)
            imports = self._extract_imports(binary_path)

            all_symbols = strings + imports
            all_text = ' '.join(all_symbols).lower()

            # Count patterns for each vulnerability type
            for vuln_type, pattern_list in self.vuln_patterns.items():
                count = sum(
                    all_text.count(pattern.lower()) for pattern in pattern_list
                )
                patterns[vuln_type] = count

        except Exception as e:
            self.logger.debug(f"Vulnerability pattern detection error: {e}")

        return patterns

    def _compare_binary_structure(self, old_binary: str, new_binary: str) -> List[Dict[str, Any]]:
        """Compare binary structure using LIEF."""
        differences = []

        if not LIEF_AVAILABLE:
            self.logger.debug(f"LIEF not available for binary structure comparison of {old_binary} vs {new_binary}")
            # Fallback to basic structure analysis
            try:
                # Compare file headers
                with open(old_binary, 'rb') as f:
                    old_header = f.read(1024)
                with open(new_binary, 'rb') as f:
                    new_header = f.read(1024)

                # Check for PE/ELF/Mach-O signatures
                if old_header[:2] != new_header[:2]:
                    differences.append({
                        'type': 'binary_format_change',
                        'description': 'Binary format signature changed',
                        'security_relevance': SecurityRelevance.HIGH.value
                    })

                # Check for architecture changes (basic heuristic)
                if old_header[4:8] != new_header[4:8]:
                    differences.append({
                        'type': 'architecture_change',
                        'description': 'Binary architecture indicators changed',
                        'security_relevance': SecurityRelevance.MEDIUM.value
                    })

            except Exception as e:
                self.logger.debug(f"Fallback binary structure analysis error: {e}")
            return differences

        try:
            self.logger.info(f"Comparing binary structure using LIEF: {old_binary} vs {new_binary}")

            # Parse binaries with LIEF
            if not hasattr(lief, 'parse'):
                self.logger.warning("lief.parse not available")
                return differences

            # Use lief.parse with proper error handling
            try:
                old_bin = lief.parse(old_binary)
                new_bin = lief.parse(new_binary)
            except AttributeError:
                self.logger.warning("lief.parse not available - lief may not be properly installed")
                return differences
            except Exception as e:
                self.logger.warning(f"Failed to parse binaries with LIEF: {e}")
                return differences

            if not old_bin or not new_bin:
                self.logger.warning("Failed to parse one or both binaries with LIEF")
                return differences

            # Compare binary types
            if type(old_bin) != type(new_bin):
                differences.append({
                    'type': 'binary_type_change',
                    'description': f'Binary type changed: {type(old_bin).__name__} -> {type(new_bin).__name__}',
                    'security_relevance': SecurityRelevance.CRITICAL.value
                })
                return differences

            # PE specific comparisons
            if hasattr(old_bin, 'optional_header') and hasattr(new_bin, 'optional_header'):
                old_opt = old_bin.optional_header
                new_opt = new_bin.optional_header

                # Check security features
                if hasattr(old_opt, 'dll_characteristics') and hasattr(new_opt, 'dll_characteristics'):
                    old_chars = old_opt.dll_characteristics
                    new_chars = new_opt.dll_characteristics

                    # Check for DEP/NX
                    old_dep = bool(old_chars & 0x0100)  # IMAGE_DLLCHARACTERISTICS_NX_COMPAT
                    new_dep = bool(new_chars & 0x0100)
                    if old_dep != new_dep:
                        differences.append({
                            'type': DiffType.SECURITY_FEATURE_ADDED.value if new_dep else DiffType.SECURITY_FEATURE_REMOVED.value,
                            'description': f'DEP/NX {"enabled" if new_dep else "disabled"}',
                            'security_relevance': SecurityRelevance.CRITICAL.value
                        })

                    # Check for ASLR
                    old_aslr = bool(old_chars & 0x0040)  # IMAGE_DLLCHARACTERISTICS_DYNAMIC_BASE
                    new_aslr = bool(new_chars & 0x0040)
                    if old_aslr != new_aslr:
                        differences.append({
                            'type': DiffType.SECURITY_FEATURE_ADDED.value if new_aslr else DiffType.SECURITY_FEATURE_REMOVED.value,
                            'description': f'ASLR {"enabled" if new_aslr else "disabled"}',
                            'security_relevance': SecurityRelevance.CRITICAL.value
                        })

                # Check entry point
                if hasattr(old_opt, 'addressof_entrypoint') and hasattr(new_opt, 'addressof_entrypoint'):
                    if old_opt.addressof_entrypoint != new_opt.addressof_entrypoint:
                        differences.append({
                            'type': 'entry_point_change',
                            'description': f'Entry point changed: 0x{old_opt.addressof_entrypoint:x} -> 0x{new_opt.addressof_entrypoint:x}',
                            'security_relevance': SecurityRelevance.HIGH.value
                        })

            # Section comparisons
            if hasattr(old_bin, 'sections') and hasattr(new_bin, 'sections'):
                old_sections = {s.name: s for s in old_bin.sections}
                new_sections = {s.name: s for s in new_bin.sections}

                # Check for section changes
                for name in set(old_sections.keys()) | set(new_sections.keys()):
                    if name in old_sections and name not in new_sections:
                        differences.append({
                            'type': DiffType.SECTION_REMOVED.value,
                            'description': f'Section removed: {name}',
                            'security_relevance': SecurityRelevance.MEDIUM.value
                        })
                    elif name not in old_sections and name in new_sections:
                        new_sec = new_sections[name]
                        new_size = getattr(new_sec, 'size', 0)

                        differences.append({
                            'type': DiffType.SECTION_ADDED.value,
                            'description': f'Section added: {name} (size: {new_size})',
                            'security_relevance': SecurityRelevance.MEDIUM.value,
                            'section_size': new_size
                        })
                    elif name in old_sections and name in new_sections:
                        old_sec = old_sections[name]
                        new_sec = new_sections[name]

                        # Check section characteristics
                        if hasattr(old_sec, 'characteristics') and hasattr(new_sec, 'characteristics'):
                            old_chars = old_sec.characteristics
                            new_chars = new_sec.characteristics

                            if old_chars != new_chars:
                                differences.append({
                                    'type': 'section_permissions_change',
                                    'description': f'Section {name} permissions changed (0x{old_chars:x} -> 0x{new_chars:x})',
                                    'security_relevance': SecurityRelevance.HIGH.value,
                                    'old_characteristics': old_chars,
                                    'new_characteristics': new_chars
                                })

                        # Check section size changes
                        old_size = getattr(old_sec, 'size', 0)
                        new_size = getattr(new_sec, 'size', 0)

                        if old_size != new_size:
                            size_change = new_size - old_size
                            differences.append({
                                'type': 'section_size_change',
                                'description': f'Section {name} size changed: {old_size} -> {new_size} ({size_change:+d})',
                                'security_relevance': SecurityRelevance.LOW.value if abs(size_change) < 1024 else SecurityRelevance.MEDIUM.value,
                                'old_size': old_size,
                                'new_size': new_size,
                                'size_change': size_change
                            })

        except Exception as e:
            self.logger.debug(f"Binary structure comparison error for {old_binary} vs {new_binary}: {e}")

        return differences

    def _analyze_patch_content(self, patch_content: str) -> Dict[str, Any]:
        """Analyze patch file content for security implications."""
        analysis = {
            'patch_type': 'unknown',
            'security_fixes': [],
            'potential_vulnerabilities': [],
            'impact_assessment': {}
        }

        try:
            # Analyze patch for security keywords
            security_keywords = {
                'fixes': ['fix', 'patch', 'security', 'vulnerability', 'cve'],
                'dangerous': ['buffer', 'overflow', 'injection', 'bypass', 'privilege'],
                'crypto': ['encrypt', 'decrypt', 'hash', 'random', 'crypto'],
                'auth': ['auth', 'login', 'password', 'token', 'access']
            }

            patch_lower = patch_content.lower()

            for category, keywords in security_keywords.items():
                for keyword in keywords:
                    if keyword in patch_lower:
                        if category == 'fixes':
                            analysis['security_fixes'].append(keyword)
                        elif category == 'dangerous':
                            analysis['potential_vulnerabilities'].append(keyword)

            # Determine patch type
            if analysis['security_fixes']:
                analysis['patch_type'] = 'security_fix'
            elif analysis['potential_vulnerabilities']:
                analysis['patch_type'] = 'potentially_dangerous'
            else:
                analysis['patch_type'] = 'regular'

        except Exception as e:
            self.logger.debug(f"Patch content analysis error: {e}")

        return analysis

    def _map_patch_to_binary(self, patch_content: str, binary_path: str) -> Dict[str, Any]:
        """Map patch changes to binary file."""
        mapping = {
            'affected_functions': [],
            'affected_sections': [],
            'binary_changes': [],
            'patch_size': len(patch_content),
            'binary_info': {}
        }

        try:
            self.logger.debug(f"Mapping patch to binary: {binary_path} (patch size: {len(patch_content)} bytes)")

            # Get binary information
            if os.path.exists(binary_path):
                mapping['binary_info'] = {
                    'path': binary_path,
                    'size': os.path.getsize(binary_path),
                    'hash': self._calculate_file_hash(binary_path)
                }

            # Parse patch content for addresses and function names
            patch_lines = patch_content.split('\n')

            # Look for hex addresses (common in patches)
            import re
            hex_pattern = r'0x[0-9a-fA-F]+'
            func_pattern = r'(?:function|func|sub_|FUN_)[0-9a-zA-Z_]+'

            addresses = []
            functions = []

            for line in patch_lines:
                # Find hex addresses
                hex_matches = re.findall(hex_pattern, line)
                addresses.extend(hex_matches)

                # Find function references
                func_matches = re.findall(func_pattern, line, re.IGNORECASE)
                functions.extend(func_matches)

            # Extract functions from binary to cross-reference
            binary_functions = self._extract_functions(binary_path)
            binary_func_names = {f.get('name', f'sub_{addr:x}').lower() for addr, f in binary_functions.items()}

            # Map patch references to binary functions
            matched_functions = 0
            for func_ref in set(functions):
                func_lower = func_ref.lower()
                matching_funcs = [bin_func for bin_func in binary_func_names if func_lower in bin_func]

                if matching_funcs:
                    security_relevance = self._assess_function_security_relevance(func_ref)
                    mapping['affected_functions'].append({
                        'name': func_ref,
                        'type': 'direct_reference',
                        'security_relevance': security_relevance.value,
                        'matches': matching_funcs[:5]  # First 5 matches
                    })
                    matched_functions += 1

            if matched_functions > 0:
                self.logger.debug(f"Patch references {matched_functions} functions in binary")

            # Analyze patch for section references
            section_keywords = ['.text', '.data', '.rdata', '.bss', '.reloc', '.rsrc', '.init', '.plt', '.got']
            section_references = {}

            for line in patch_lines:
                for section in section_keywords:
                    if section in line:
                        if section not in section_references:
                            section_references[section] = 0
                        section_references[section] += 1
                        mapping['affected_sections'].append(section)

            mapping['affected_sections'] = list(set(mapping['affected_sections']))

            # Log section reference statistics
            if section_references:
                self.logger.debug(f"Patch contains section references: {section_references}")
                mapping['section_reference_counts'] = section_references

            # Determine patch type based on content
            if addresses:
                mapping['binary_changes'].append({
                    'description': f'Patch contains {len(set(addresses))} unique address references',
                    'type': 'address_patch',
                    'addresses': list(set(addresses))[:10]  # First 10 unique addresses
                })

            if mapping['affected_functions']:
                mapping['binary_changes'].append({
                    'description': f'Patch affects {len(mapping["affected_functions"])} functions',
                    'type': 'function_patch'
                })

            if mapping['affected_sections']:
                mapping['binary_changes'].append({
                    'description': f'Patch references {len(mapping["affected_sections"])} sections',
                    'type': 'section_patch'
                })

            # Analyze patch patterns
            patch_lower = patch_content.lower()
            if 'nop' in patch_lower or '0x90' in patch_lower:
                mapping['binary_changes'].append({
                    'description': 'Patch contains NOP instructions (possible bypass)',
                    'type': 'nop_patch',
                    'security_relevance': SecurityRelevance.HIGH.value
                })

            if 'jmp' in patch_lower or 'call' in patch_lower:
                mapping['binary_changes'].append({
                    'description': 'Patch modifies control flow (JMP/CALL)',
                    'type': 'control_flow_patch',
                    'security_relevance': SecurityRelevance.MEDIUM.value
                })

            if not mapping['binary_changes']:
                mapping['binary_changes'].append({
                    'description': 'Patch analysis complete',
                    'type': 'generic_patch'
                })

        except Exception as e:
            self.logger.debug(f"Patch-to-binary mapping error for {binary_path}: {e}")
            mapping['binary_changes'].append({
                'description': f'Mapping error: {str(e)}',
                'type': 'error'
            })

        return mapping

    def _extract_functions(self, binary_path: str) -> Dict[int, Dict[str, Any]]:
        """Extract function information from binary."""
        functions = {}

        try:
            # Use objdump to get function symbols
            result = subprocess.run(['objdump', '-t', binary_path],
                                  capture_output=True, text=True, check=False)

            if result.returncode == 0:
                lines = result.stdout.split('\n')
                functions_found = 0

                for line in lines:
                    if 'F .text' in line:
                        parts = line.split()
                        if len(parts) >= 6:
                            try:
                                addr = int(parts[0], 16)
                                size = int(parts[4], 16) if parts[4] != '' and parts[4].isdigit() else 0
                                name = parts[-1]

                                # Enhanced function analysis
                                security_relevance = self._assess_function_security_relevance(name)

                                functions[addr] = {
                                    'name': name,
                                    'size': size,
                                    'bytes': b'',  # Would extract actual bytes in full implementation
                                    'analysis': {
                                        'security_relevance': security_relevance.value,
                                        'extracted_from': binary_path
                                    }
                                }
                                functions_found += 1

                            except (ValueError, IndexError) as parse_error:
                                self.logger.debug(f"Failed to parse function line '{line}': {parse_error}")
                                continue

                self.logger.debug(f"Extracted {functions_found} functions from {binary_path}")
            else:
                # Try alternative approach with nm if objdump fails
                nm_result = subprocess.run(['nm', '-C', '-D', binary_path],
                                         capture_output=True, text=True, check=False)
                if nm_result.returncode == 0:
                    nm_lines = nm_result.stdout.split('\n')
                    nm_functions_found = 0

                    for line in nm_lines:
                        if ' T ' in line or ' t ' in line:  # Text symbols
                            parts = line.split()
                            if len(parts) >= 3:
                                try:
                                    addr = int(parts[0], 16)
                                    name = parts[-1]

                                    security_relevance = self._assess_function_security_relevance(name)

                                    functions[addr] = {
                                        'name': name,
                                        'size': 0,  # nm doesn't provide size
                                        'bytes': b'',
                                        'analysis': {
                                            'security_relevance': security_relevance.value,
                                            'extracted_from': binary_path,
                                            'extraction_method': 'nm'
                                        }
                                    }
                                    nm_functions_found += 1

                                except (ValueError, IndexError) as parse_error:
                                    self.logger.debug(f"Failed to parse nm line '{line}': {parse_error}")
                                    continue

                    self.logger.debug(f"Extracted {nm_functions_found} functions from {binary_path} using nm")

        except Exception as e:
            self.logger.debug(f"Function extraction error for {binary_path}: {e}")

        return functions

    def _calculate_function_similarity(self, func1: bytes, func2: bytes) -> float:
        """Calculate similarity between two functions."""
        try:
            if not func1 or not func2:
                return 0.0

            # Simple byte-based similarity
            min_len = min(len(func1), len(func2))
            max_len = max(len(func1), len(func2))

            if max_len == 0:
                return 1.0

            matches = sum(1 for i in range(min_len) if func1[i] == func2[i])
            similarity = matches / max_len

            return similarity

        except Exception:
            return 0.0

    def get_analysis_cache(self) -> Dict[str, Any]:
        """Get current analysis cache."""
        return self.analysis_cache.copy()

    def clear_analysis_cache(self):
        """Clear analysis cache."""
        self.analysis_cache.clear()

    def export_analysis(self, result: Dict[str, Any], output_file: str, format: str = 'json') -> bool:
        """Export analysis results to file."""
        from ...utils.analysis.analysis_exporter import AnalysisExporter
        return AnalysisExporter.export_analysis(result, output_file, format, 'binary_diff')

