#!/usr/bin/env python3
"""
Comprehensive AI Integration Demo - All Advanced Features

Copyright (C) 2025 Zachary Flint

This file is part of Intellicrack.

Intellicrack is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

Intellicrack is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with Intellicrack.  If not, see <https://www.gnu.org/licenses/>.
"""

import asyncio
import time
from pathlib import Path

from intellicrack.ai import (
    # Core AI components
    LLMManager,
    AILearningEngine,
    MultiAgentSystem,
    RealTimeAdaptationEngine,
    SemanticCodeAnalyzer,
    AutomatedExploitChainBuilder,

    # Data structures
    Vulnerability,
    ExploitType,
    AgentRole,
    AdaptationType,

    # Performance and monitoring
    PerformanceMonitor,
    performance_monitor,
    profile_ai_operation
)


class ComprehensiveAIDemo:
    """Comprehensive demonstration of all AI capabilities."""

    def __init__(self):
        print("üöÄ Initializing Comprehensive AI Demo")
        print("=" * 60)

        # Initialize core components
        self.llm_manager = LLMManager()
        self.learning_engine = AILearningEngine()
        self.multi_agent_system = MultiAgentSystem(self.llm_manager)
        self.adaptation_engine = RealTimeAdaptationEngine()
        self.semantic_analyzer = SemanticCodeAnalyzer(self.llm_manager)
        self.exploit_builder = AutomatedExploitChainBuilder(self.llm_manager)

        print("‚úÖ All AI components initialized successfully")

    async def demonstrate_learning_system(self):
        """Demonstrate AI learning and evolution."""
        print("\nüß† AI Learning & Evolution System Demo")
        print("-" * 40)

        # Record some learning experiences
        experiences = [
            ("script_generation", {"target": "binary.exe"}, {"script": "frida_hook.js"}, True, 0.85, 2.1),
            ("vulnerability_analysis", {"file": "vuln.c"}, {"vulns": ["buffer_overflow"]}, True, 0.92, 5.4),
            ("exploit_chain", {"vuln_type": "buffer_overflow"}, {"chain_id": "chain_001"}, True, 0.78, 8.2),
            ("code_modification", {"target": "license.py"}, {"changes": 3}, False, 0.45, 12.1),
            ("semantic_analysis", {"code": "auth_func"}, {"intent": "authentication"}, True, 0.89, 3.7)
        ]

        print("üìù Recording learning experiences...")
        for task_type, input_data, output_data, success, confidence, exec_time in experiences:
            record_id = self.learning_engine.record_experience(
                task_type=task_type,
                input_data=input_data,
                output_data=output_data,
                success=success,
                confidence=confidence,
                execution_time=exec_time,
                memory_usage=1024 * (1 + exec_time),  # Simulate memory usage
                context={"demo": True, "version": "1.0"}
            )
            print(f"   ‚úì Recorded {task_type}: {record_id}")

        # Evolve patterns
        print("\nüîÑ Evolving AI patterns...")
        evolution_results = self.learning_engine.evolve_patterns()
        print(f"   üìä Evolution results: {evolution_results}")

        # Analyze failures
        print("\nüîç Analyzing failure patterns...")
        failure_analysis = self.learning_engine.analyze_failures()
        print(f"   üìä Failure analysis: {failure_analysis}")

        # Get insights
        insights = self.learning_engine.get_learning_insights()
        print("\nüí° Learning insights:")
        print(f"   - Total records: {insights['total_records']}")
        print(f"   - Success rate: {insights['success_rate']:.2%}")
        print(f"   - Avg confidence: {insights['avg_confidence']:.2f}")

    async def demonstrate_multi_agent_system(self):
        """Demonstrate multi-agent collaboration."""
        print("\nü§ñ Multi-Agent Collaboration Demo")
        print("-" * 40)

        # Create specialized agents
        print("üèóÔ∏è Creating specialized agents...")

        agent_ids = []
        for role in [AgentRole.STATIC_ANALYZER, AgentRole.DYNAMIC_ANALYZER, AgentRole.EXPLOIT_DEVELOPER]:
            agent_id = self.multi_agent_system.create_agent(
                role=role,
                capabilities=[f"{role.value}_capability"],
                config={"max_concurrent_tasks": 3}
            )
            agent_ids.append(agent_id)
            print(f"   ‚úì Created {role.value} agent: {agent_id}")

        # Create collaborative task
        print("\nüìã Creating collaborative analysis task...")
        task_id = self.multi_agent_system.create_collaborative_task(
            task_type="comprehensive_binary_analysis",
            description="Analyze suspicious binary with multiple techniques",
            input_data={
                "binary_path": "/demo/suspicious.exe",
                "analysis_depth": "comprehensive",
                "generate_exploits": True
            },
            required_agents=[AgentRole.STATIC_ANALYZER, AgentRole.DYNAMIC_ANALYZER],
            optional_agents=[AgentRole.EXPLOIT_DEVELOPER]
        )
        print(f"   üìù Created task: {task_id}")

        # Simulate task execution
        print("\n‚ö° Executing collaborative task...")
        await asyncio.sleep(0.1)  # Simulate processing time

        # Get task status
        status = self.multi_agent_system.get_task_status(task_id)
        print(f"   üìä Task status: {status}")

        # Get system statistics
        stats = self.multi_agent_system.get_system_statistics()
        print("\nüìà Multi-agent system stats:")
        print(f"   - Active agents: {stats['active_agents']}")
        print(f"   - Total tasks: {stats['total_tasks']}")
        print(f"   - Messages exchanged: {stats['messages_exchanged']}")

    async def demonstrate_realtime_adaptation(self):
        """Demonstrate real-time adaptation engine."""
        print("\n‚ö° Real-Time Adaptation Engine Demo")
        print("-" * 40)

        # Add adaptation rules
        print("üìú Adding adaptation rules...")

        rule_ids = []
        rules = [
            ("performance_degradation", 0.5, AdaptationType.PARAMETER_TUNING, "Reduce analysis depth"),
            ("memory_pressure", 0.8, AdaptationType.RESOURCE_ALLOCATION, "Increase memory limit"),
            ("error_rate_increase", 0.3, AdaptationType.ALGORITHM_SELECTION, "Switch to backup algorithm")
        ]

        for condition, threshold, adaptation_type, action in rules:
            from intellicrack.ai.realtime_adaptation_engine import TriggerCondition, AdaptationRule

            rule = AdaptationRule(
                rule_id=f"rule_{len(rule_ids)+1}",
                name=f"Rule for {condition}",
                condition=TriggerCondition(condition.upper()),
                threshold=threshold,
                adaptation_type=adaptation_type,
                action=action
            )

            rule_id = self.adaptation_engine.add_rule(rule)
            rule_ids.append(rule_id)
            print(f"   ‚úì Added rule: {rule.name}")

        # Simulate metrics and trigger adaptations
        print("\nüìä Simulating runtime metrics...")

        from intellicrack.ai.realtime_adaptation_engine import RuntimeMetric
        from datetime import datetime

        metrics = [
            RuntimeMetric("cpu_usage", 0.75, datetime.now(), "system", "performance"),
            RuntimeMetric("memory_usage", 0.85, datetime.now(), "system", "resource"),
            RuntimeMetric("error_rate", 0.35, datetime.now(), "analysis", "quality"),
            RuntimeMetric("success_rate", 0.65, datetime.now(), "analysis", "quality")
        ]

        for metric in metrics:
            self.adaptation_engine.process_metric(metric)
            print(f"   üìà Processed metric: {metric.metric_name} = {metric.value}")

        # Check for triggered adaptations
        adaptations = self.adaptation_engine.get_recent_adaptations(limit=10)
        print(f"\nüîß Triggered adaptations: {len(adaptations)}")
        for adaptation in adaptations:
            print(f"   ‚öôÔ∏è  {adaptation.adaptation_type.value}: {adaptation.action_taken}")

    async def demonstrate_semantic_analysis(self):
        """Demonstrate semantic code understanding."""
        print("\nüß† Semantic Code Understanding Demo")
        print("-" * 40)

        # Sample code for analysis
        sample_code = '''
def validate_license(key):
    if not key or len(key) < 16:
        return False

    if not key.startswith("LIC-"):
        return False

    # Check cryptographic signature
    if not verify_signature(key):
        log_failed_validation(key)
        return False

    return True

class UserManager:
    def authenticate_user(self, username, password):
        user = self.get_user(username)
        if not user:
            return None

        if hashlib.sha256(password.encode()).hexdigest() == user.password_hash:
            self.log_successful_login(username)
            return user

        self.log_failed_login(username)
        return None
'''

        print("üîç Analyzing code semantics...")

        # Create a temporary file for analysis
        temp_file = Path("/tmp/demo_code.py")
        temp_file.write_text(sample_code)

        try:
            # Perform semantic analysis
            analysis_result = self.semantic_analyzer.analyze_file(str(temp_file))

            print("   üìä Analysis complete:")
            print(f"   - Semantic nodes found: {len(analysis_result.semantic_nodes)}")
            print(f"   - Relationships discovered: {len(analysis_result.relationships)}")
            print(f"   - Business patterns detected: {len(analysis_result.business_patterns)}")

            # Display detected intents
            if analysis_result.semantic_nodes:
                print("\nüéØ Detected semantic intents:")
                for node in analysis_result.semantic_nodes[:3]:  # Show first 3
                    print(f"   - {node.name}: {node.semantic_intent.value} (confidence: {node.confidence:.2f})")

            # Display business patterns
            if analysis_result.business_patterns:
                print("\nüè¢ Business logic patterns:")
                for pattern_name, confidence in analysis_result.business_patterns.items():
                    print(f"   - {pattern_name}: {confidence:.2f}")

        finally:
            # Cleanup
            if temp_file.exists():
                temp_file.unlink()

    async def demonstrate_exploit_chain_builder(self):
        """Demonstrate automated exploit chain building."""
        print("\nüí• Automated Exploit Chain Builder Demo")
        print("-" * 40)

        # Create sample vulnerabilities
        vulnerabilities = [
            Vulnerability(
                vuln_id="demo_vuln_001",
                vuln_type=ExploitType.BUFFER_OVERFLOW,
                severity="high",
                description="Stack buffer overflow in input parsing function",
                location={"file": "parser.c", "function": "parse_input", "line": 145},
                prerequisites=["network_access"],
                impact={"confidentiality": "high", "integrity": "high", "availability": "medium"},
                confidence=0.92,
                exploitability=0.85
            ),
            Vulnerability(
                vuln_id="demo_vuln_002",
                vuln_type=ExploitType.USE_AFTER_FREE,
                severity="critical",
                description="Use-after-free in object destructor",
                location={"file": "memory.cpp", "function": "~Object", "line": 89},
                prerequisites=["heap_layout_knowledge"],
                impact={"confidentiality": "high", "integrity": "high", "availability": "high"},
                confidence=0.87,
                exploitability=0.72
            ),
            Vulnerability(
                vuln_id="demo_vuln_003",
                vuln_type=ExploitType.INTEGER_OVERFLOW,
                severity="medium",
                description="Integer overflow in size calculation",
                location={"file": "utils.c", "function": "calculate_size", "line": 234},
                prerequisites=["input_control"],
                impact={"confidentiality": "medium", "integrity": "medium", "availability": "low"},
                confidence=0.78,
                exploitability=0.64
            )
        ]

        print("üî® Building exploit chains...")

        built_chains = []
        for vuln in vulnerabilities:
            print(f"\n   üéØ Processing {vuln.vuln_type.value} vulnerability...")

            # Build exploit chain
            chain = self.exploit_builder.build_exploit_chain(vuln)

            if chain:
                built_chains.append(chain)
                print(f"   ‚úÖ Built chain: {chain.name}")
                print(f"      - Steps: {len(chain.steps)}")
                print(f"      - Success probability: {chain.success_probability:.2f}")
                print(f"      - Complexity: {chain.complexity.value}")
                print(f"      - Safety verified: {chain.safety_verified}")

                # Validate the chain
                validation = self.exploit_builder.validate_chain(chain.chain_id)
                print(f"      - Validation: {'‚úÖ Valid' if validation.is_valid else '‚ùå Invalid'}")

                if validation.warnings:
                    print(f"      - Warnings: {len(validation.warnings)}")
                if validation.optimizations:
                    print(f"      - Optimization suggestions: {len(validation.optimizations)}")
            else:
                print(f"   ‚ùå Failed to build chain for {vuln.vuln_type.value}")

        # Get builder statistics
        stats = self.exploit_builder.get_chain_statistics()
        print("\nüìä Exploit chain builder statistics:")
        print(f"   - Total chains built: {stats['total_chains']}")
        if stats['total_chains'] > 0:
            print(f"   - Average success probability: {stats['avg_success_probability']:.2f}")
            print(f"   - Safety verified chains: {stats['safety_verified']}")
            print(f"   - Complexity distribution: {stats['complexity_distribution']}")

    async def demonstrate_performance_monitoring(self):
        """Demonstrate performance monitoring capabilities."""
        print("\nüìä Performance Monitoring Demo")
        print("-" * 40)

        # Simulate AI operations with performance monitoring
        print("‚ö° Running monitored AI operations...")

        @profile_ai_operation("demo_operation_1")
        def cpu_intensive_task():
            """Simulate CPU-intensive AI task."""
            import math
            result = 0
            for i in range(100000):
                result += math.sqrt(i)
            return result

        @profile_ai_operation("demo_operation_2")
        def memory_intensive_task():
            """Simulate memory-intensive AI task."""
            data = []
            for i in range(10000):
                data.append([j for j in range(100)])
            return len(data)

        @profile_ai_operation("demo_operation_3")
        def io_intensive_task():
            """Simulate I/O-intensive AI task."""
            import time
            time.sleep(0.1)  # Simulate I/O wait
            return "completed"

        # Run operations
        with PerformanceMonitor():
            results = []
            for i in range(3):
                results.append(cpu_intensive_task())
                results.append(memory_intensive_task())
                results.append(io_intensive_task())
                print(f"   ‚úì Completed operation batch {i+1}")

        # Get performance summary
        print("\nüìà Performance analysis:")
        summary = performance_monitor.get_metrics_summary()

        if "operation_summary" in summary:
            for op_name, stats in summary["operation_summary"].items():
                print(f"   {op_name}:")
                print(f"     - Executions: {stats.get('total_executions', 0)}")
                print(f"     - Avg time: {stats.get('avg_execution_time', 0):.3f}s")
                print(f"     - Success rate: {stats.get('success_rate', 0):.1%}")

        # System health
        health = summary.get("system_health", {})
        print(f"\nüè• System health: {health.get('status', 'unknown').upper()}")
        print(f"   Health score: {health.get('score', 0):.1f}/100")

    async def demonstrate_integrated_workflow(self):
        """Demonstrate all systems working together."""
        print("\nüåü Integrated AI Workflow Demo")
        print("-" * 40)

        print("üîÑ Executing complete AI-powered analysis workflow...")

        # Step 1: Semantic analysis
        print("\n1Ô∏è‚É£ Semantic Analysis Phase")
        sample_code = '''
def check_password(password):
    if len(password) < 8:
        return False
    return password == "admin123"
'''

        temp_file = Path("/tmp/workflow_code.py")
        temp_file.write_text(sample_code)

        try:
            semantic_result = self.semantic_analyzer.analyze_file(str(temp_file))
            print(f"   ‚úÖ Identified {len(semantic_result.semantic_nodes)} semantic elements")

            # Step 2: Multi-agent analysis
            print("\n2Ô∏è‚É£ Multi-Agent Analysis Phase")

            # Create analysis task
            task_id = self.multi_agent_system.create_collaborative_task(
                task_type="code_security_analysis",
                description="Analyze code for security vulnerabilities",
                input_data={"code_content": sample_code, "semantic_analysis": "completed"},
                required_agents=[AgentRole.STATIC_ANALYZER]
            )

            await asyncio.sleep(0.1)  # Simulate processing
            print(f"   ‚úÖ Multi-agent analysis completed: {task_id}")

            # Step 3: Vulnerability identification
            print("\n3Ô∏è‚É£ Vulnerability Identification Phase")

            # Create mock vulnerability based on analysis
            vulnerability = Vulnerability(
                vuln_id="workflow_vuln_001",
                vuln_type=ExploitType.AUTHENTICATION_BYPASS,
                severity="critical",
                description="Hardcoded password in authentication function",
                location={"file": "workflow_code.py", "function": "check_password", "line": 3},
                confidence=0.95,
                exploitability=0.90
            )
            print(f"   ‚úÖ Identified vulnerability: {vulnerability.vuln_type.value}")

            # Step 4: Exploit chain generation
            print("\n4Ô∏è‚É£ Exploit Chain Generation Phase")

            exploit_chain = self.exploit_builder.build_exploit_chain(vulnerability)
            if exploit_chain:
                print(f"   ‚úÖ Generated exploit chain: {exploit_chain.chain_id}")
                print(f"      Success probability: {exploit_chain.success_probability:.2f}")
                print(f"      Safety verified: {exploit_chain.safety_verified}")

            # Step 5: Learning and adaptation
            print("\n5Ô∏è‚É£ Learning & Adaptation Phase")

            # Record the complete workflow experience
            workflow_record = self.learning_engine.record_experience(
                task_type="integrated_workflow",
                input_data={"code_analysis": True, "vulnerability_found": True},
                output_data={"exploit_generated": exploit_chain is not None},
                success=exploit_chain is not None,
                confidence=0.87,
                execution_time=2.5,
                memory_usage=2048,
                context={
                    "workflow_step": "complete",
                    "components_used": ["semantic", "multi_agent", "exploit_builder"]
                }
            )
            print(f"   ‚úÖ Recorded workflow learning: {workflow_record}")

            # Step 6: Performance analysis
            print("\n6Ô∏è‚É£ Performance Analysis Phase")

            perf_summary = performance_monitor.get_metrics_summary()
            operations_count = len(perf_summary.get("operation_summary", {}))
            print(f"   ‚úÖ Analyzed {operations_count} performance metrics")

            print("\nüéâ Integrated workflow completed successfully!")
            print("   All AI systems collaborated effectively to:")
            print("   - Analyze code semantics")
            print("   - Identify security vulnerabilities") 
            print("   - Generate exploit chains")
            print("   - Learn from the experience")
            print("   - Monitor performance throughout")

        finally:
            # Cleanup
            if temp_file.exists():
                temp_file.unlink()

    async def run_complete_demo(self):
        """Run the complete demonstration."""
        start_time = time.time()

        try:
            # Run all demonstration modules
            await self.demonstrate_learning_system()
            await self.demonstrate_multi_agent_system()
            await self.demonstrate_realtime_adaptation()
            await self.demonstrate_semantic_analysis()
            await self.demonstrate_exploit_chain_builder()
            await self.demonstrate_performance_monitoring()
            await self.demonstrate_integrated_workflow()

            execution_time = time.time() - start_time

            print("\n\nüèÜ COMPREHENSIVE AI DEMO COMPLETED!")
            print("=" * 60)
            print(f"‚è±Ô∏è  Total execution time: {execution_time:.2f} seconds")
            print("üéØ All advanced AI systems demonstrated:")
            print("   ‚úÖ AI Learning & Evolution Engine")
            print("   ‚úÖ Multi-Agent Collaboration System") 
            print("   ‚úÖ Real-Time Adaptation Engine")
            print("   ‚úÖ Semantic Code Understanding")
            print("   ‚úÖ Automated Exploit Chain Builder")
            print("   ‚úÖ Performance Monitoring System")
            print("   ‚úÖ Integrated AI Workflows")
            print("\nüí° The Intellicrack AI system is production-ready!")
            print("üöÄ All 15 phases of AI implementation completed successfully!")

        except Exception as e:
            print(f"\n‚ùå Demo error: {e}")
            import traceback
            traceback.print_exc()


async def main():
    """Main demonstration function."""
    try:
        print("üåü Starting Comprehensive Intellicrack AI Demo")
        print("üî¨ Demonstrating all advanced AI capabilities")
        print()

        demo = ComprehensiveAIDemo()
        await demo.run_complete_demo()

    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è  Demo interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Demo error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # Run the comprehensive demonstration
    asyncio.run(main())