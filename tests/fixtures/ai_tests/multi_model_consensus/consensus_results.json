[
  {
    "scenario": {
      "name": "basic_function_analysis",
      "binary_type": "simple_executable",
      "task": "generate_frida_hook",
      "target_function": "main"
    },
    "model_responses": [
      {
        "model": "gpt-4",
        "quality_score": 0.894,
        "response_time": 1.6099999999999999,
        "script_generated": "// GPT-4 generated script for generate_frida_hook",
        "confidence": 0.8046,
        "analysis_depth": "high"
      },
      {
        "model": "claude-3",
        "quality_score": 0.982,
        "response_time": 2.24,
        "script_generated": "// CLAUDE-3 generated script for generate_frida_hook",
        "confidence": 0.8838,
        "analysis_depth": "high"
      },
      {
        "model": "gemini-pro",
        "quality_score": 0.8680000000000001,
        "response_time": 2.79,
        "script_generated": "// GEMINI-PRO generated script for generate_frida_hook",
        "confidence": 0.7812000000000001,
        "analysis_depth": "high"
      },
      {
        "model": "local-llama",
        "quality_score": 0.922,
        "response_time": 1.8199999999999998,
        "script_generated": "// LOCAL-LLAMA generated script for generate_frida_hook",
        "confidence": 0.8298000000000001,
        "analysis_depth": "high"
      }
    ],
    "consensus": {
      "confidence": 0.8248500000000001,
      "quality_variance": 0.002392999999999996,
      "avg_response_time": 2.115,
      "model_agreement": 0.9466248780856084,
      "recommended_model": "claude-3"
    },
    "timestamp": 1753500086.1856654
  },
  {
    "scenario": {
      "name": "complex_obfuscation_analysis",
      "binary_type": "vmprotect_protected",
      "task": "identify_protection_scheme",
      "complexity": "high"
    },
    "model_responses": [
      {
        "model": "gpt-4",
        "quality_score": 0.91,
        "response_time": 1.26,
        "script_generated": "// GPT-4 generated script for identify_protection_scheme",
        "confidence": 0.8190000000000001,
        "analysis_depth": "high"
      },
      {
        "model": "claude-3",
        "quality_score": 0.902,
        "response_time": 2.27,
        "script_generated": "// CLAUDE-3 generated script for identify_protection_scheme",
        "confidence": 0.8118000000000001,
        "analysis_depth": "high"
      },
      {
        "model": "gemini-pro",
        "quality_score": 0.9600000000000001,
        "response_time": 2.76,
        "script_generated": "// GEMINI-PRO generated script for identify_protection_scheme",
        "confidence": 0.8640000000000001,
        "analysis_depth": "high"
      },
      {
        "model": "local-llama",
        "quality_score": 0.896,
        "response_time": 1.6099999999999999,
        "script_generated": "// LOCAL-LLAMA generated script for identify_protection_scheme",
        "confidence": 0.8064,
        "analysis_depth": "high"
      }
    ],
    "consensus": {
      "confidence": 0.8253,
      "quality_variance": 0.0008546666666666682,
      "avg_response_time": 1.9749999999999999,
      "model_agreement": 0.9681192119966838,
      "recommended_model": "gemini-pro"
    },
    "timestamp": 1753500086.1856654
  },
  {
    "scenario": {
      "name": "cross_architecture_analysis",
      "binary_type": "arm64_binary",
      "task": "generate_ghidra_script",
      "architecture": "aarch64"
    },
    "model_responses": [
      {
        "model": "gpt-4",
        "quality_score": 0.89,
        "response_time": 2.46,
        "script_generated": "// GPT-4 generated script for generate_ghidra_script",
        "confidence": 0.801,
        "analysis_depth": "high"
      },
      {
        "model": "claude-3",
        "quality_score": 0.8620000000000001,
        "response_time": 2.0,
        "script_generated": "// CLAUDE-3 generated script for generate_ghidra_script",
        "confidence": 0.7758000000000002,
        "analysis_depth": "high"
      },
      {
        "model": "gemini-pro",
        "quality_score": 0.806,
        "response_time": 2.09,
        "script_generated": "// GEMINI-PRO generated script for generate_ghidra_script",
        "confidence": 0.7254,
        "analysis_depth": "medium"
      },
      {
        "model": "local-llama",
        "quality_score": 0.8140000000000001,
        "response_time": 1.76,
        "script_generated": "// LOCAL-LLAMA generated script for generate_ghidra_script",
        "confidence": 0.7326,
        "analysis_depth": "medium"
      }
    ],
    "consensus": {
      "confidence": 0.7587,
      "quality_variance": 0.0015933333333333327,
      "avg_response_time": 2.0775,
      "model_agreement": 0.9526493716728424,
      "recommended_model": "gpt-4"
    },
    "timestamp": 1753500086.1856654
  }
]