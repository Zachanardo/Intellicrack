                self.deep_analysis_combo.setCurrentIndex(index)

            if hasattr(self, "analysis_depth_slider"):
                self.analysis_depth_slider.setValue(50)

        elif preset_name == "Maximum Security":
            self.stealth_checkbox.setChecked(True)
            self.auto_patch_checkbox.setChecked(False)  # Manual control for security
            self.heuristic_patch_checkbox.setChecked(False)  # No heuristics for security
            self.frida_checkbox.setChecked(True)
            self.qiling_checkbox.setChecked(True)
            self.backup_checkbox.setChecked(True)

            index = self.deep_analysis_combo.findText("Symbolic Execution")
            if index >= 0:
                self.deep_analysis_combo.setCurrentIndex(index)

            if hasattr(self, "analysis_depth_slider"):
                self.analysis_depth_slider.setValue(100)  # Maximum depth

        elif preset_name == "Performance Optimized":
            self.stealth_checkbox.setChecked(False)
            self.auto_patch_checkbox.setChecked(True)
            self.heuristic_patch_checkbox.setChecked(True)  # Use heuristics for speed
            self.frida_checkbox.setChecked(False)  # Skip runtime hooking for speed
            self.qiling_checkbox.setChecked(False)  # Skip emulation for speed
            self.backup_checkbox.setChecked(True)

            index = self.deep_analysis_combo.findText("Packing Detection")
            if index >= 0:
                self.deep_analysis_combo.setCurrentIndex(index)

            if hasattr(self, "analysis_depth_slider"):
                self.analysis_depth_slider.setValue(30)  # Lower depth for speed

        elif preset_name == "Deep Analysis":
            self.stealth_checkbox.setChecked(False)
            self.auto_patch_checkbox.setChecked(False)
            self.heuristic_patch_checkbox.setChecked(True)
            self.frida_checkbox.setChecked(True)
            self.qiling_checkbox.setChecked(True)
            self.backup_checkbox.setChecked(True)

            index = self.deep_analysis_combo.findText("Taint Analysis")
            if index >= 0:
                self.deep_analysis_combo.setCurrentIndex(index)

            if hasattr(self, "analysis_depth_slider"):
                self.analysis_depth_slider.setValue(80)

        elif preset_name == "Basic Analysis":
            self.stealth_checkbox.setChecked(False)
            self.auto_patch_checkbox.setChecked(True)
            self.heuristic_patch_checkbox.setChecked(False)
            self.frida_checkbox.setChecked(False)
            self.qiling_checkbox.setChecked(False)
            self.backup_checkbox.setChecked(True)

            index = self.deep_analysis_combo.findText("License Logic")
            if index >= 0:
                self.deep_analysis_combo.setCurrentIndex(index)

            if hasattr(self, "analysis_depth_slider"):
                self.analysis_depth_slider.setValue(20)

        self.update_output.emit(log_message(f"[Config] Applied '{preset_name}' configuration preset"))

    def apply_log_filter(self):
        """Applies the filter to the log output."""
        filter_text = self.log_filter.toPlainText().strip().lower()
        if not filter_text:
            return

        # Get all text
        full_text = self.log_output.toPlainText()

        # Filter lines
        filtered_lines = []
        for line in full_text.splitlines():
            if filter_text in line.lower():
                filtered_lines.append(line)

        # Update display
        if filtered_lines:
            self.log_output.setPlainText("\n".join(filtered_lines))
        else:
            self.log_output.setPlainText("No matching log entries found")

    def clear_logs(self):
        """Clears the log output."""
        self.log_output.clear()

    def save_logs(self):
        """Saves the current logs to a file."""
        path, _ = QFileDialog.getSaveFileName(
            self, "Save Logs", "", "Log Files (*.log);;Text Files (*.txt);;All Files (*)")
        if path:
            try:
                with open(path, "w", encoding="utf-8") as f:
                    f.write(self.log_output.toPlainText())

                self.update_output.emit(log_message(f"Logs saved to {path}"))

            except Exception as e:
                self.update_output.emit(log_message(f"Error saving logs: {e}"))
                QMessageBox.warning(self, "Save Error",
                                    f"Error saving logs: {e}")

    def scan_protectors(self):
        """Scans the binary for bytecode protectors and displays results."""
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        self.update_output.emit(log_message(
            "[Protection Scanner] Scanning for bytecode protectors..."))

        results = scan_for_bytecode_protectors(self.binary_path)

        if "error" in results:
            self.update_output.emit(log_message(
                f"[Protection Scanner] Error: {results['error']}"))
            return

        # Display results
        if not results:
            self.update_output.emit(log_message(
                "[Protection Scanner] No protectors detected."))
            QMessageBox.information(
                self,
                "Scan Results",
                "No bytecode protectors detected in this binary.")
            return

        # Format results for display
        output = ["[Protection Scanner] Scan results:"]

        for protector, details in results.items():
            if isinstance(details, dict) and details.get("detected", False):
                output.append(f"  - {protector}: DETECTED")

                # Add details if available
                if "signature" in details:
                    output.append(
                        f"    Signature found: {details['signature']}")
                if "section_name" in details:
                    output.append(f"    Section: {details['section_name']}")
                if "section_entropy" in details:
                    output.append(
                        f"    Entropy: {details['section_entropy']:.2f}")
                if "note" in details:
                    output.append(f"    Note: {details['note']}")

        if not output[1:]:  # If no results after the header
            output.append("  No protectors detected")

        # Display in output panel
        for line in output:
            self.update_output.emit(log_message(line))

        # Show dialog with results
        QMessageBox.information(
            self, "Protection Scan Results", "\n".join(output))

    def select_program(self):
        """Opens a file dialog to select an executable or shortcut. Initializes analyzers."""
        path, _ = QFileDialog.getOpenFileName(
            # Allow selecting any file for broader analysis
            self, "Select Program", "", "Executables (*.exe *.lnk);;All Files (*.*)"
        )
        resolved_path = path  # Store original path or resolved path

        if not path:  # Handle case where user cancels dialog
            return

        # Resolve .lnk shortcuts if applicable (Windows only)
        if path.endswith(".lnk") and sys.platform == "win32":
            try:
                try:
                    pythoncom.CoInitialize()
                    shell = win32com.client.Dispatch("WScript.Shell")
                    shortcut = shell.CreateShortCut(path)
                    target = shortcut.Targetpath
                    if target and os.path.exists(target):
                        resolved_path = target
                    else:
                        QMessageBox.warning(
                            self,
                            "Shortcut Error",
                            f"Shortcut target does not exist or is invalid:\n{target}")
                        return
                finally:
                    pythoncom.CoUninitialize()
            except ImportError:
                QMessageBox.warning(
                    self,
                    "Shortcut Error",
                    f"Required 'pywin32' library not found. Cannot resolve .lnk files.")
                return
            except AttributeError:
                QMessageBox.warning(
                    self,
                    "Shortcut Error",
                    f"Could not resolve shortcut target. It might be invalid or broken:\n{path}")
                return
            except Exception as e:
                QMessageBox.warning(self, "Shortcut Error",
                                    f"Failed to resolve shortcut target: {e}")
                return
        elif not os.path.exists(resolved_path):
            QMessageBox.warning(
                self,
                "File Not Found",
                f"The selected file does not exist:\n{resolved_path}")
            return

        # Proceed if we have a valid, existing file path
        self.binary_path = resolved_path  # Set the binary path attribute

        # Extract binary information
        self.extract_binary_info(self.binary_path)

        # --- Instantiate AdvancedDynamicAnalyzer ---
        # This happens only AFTER self.binary_path is confirmed and valid.
        try:
            self.dynamic_analyzer = AdvancedDynamicAnalyzer(self.binary_path)
            self.update_output.emit(
                log_message("[Analyzer Init] AdvancedDynamicAnalyzer initialized."))
        except NameError:
            self.update_output.emit(log_message(
                "[Analyzer Init] Failed: AdvancedDynamicAnalyzer class not found (Import missing?)."))
            self.dynamic_analyzer = None  # Ensure it's None if class isn't found
        except Exception as e_dyn_init:
            self.update_output.emit(
                log_message(
                    f"[Analyzer Init] Failed to initialize AdvancedDynamicAnalyzer: {e_dyn_init}"))
            self.dynamic_analyzer = None  # Ensure it's None if init fails
        # --- End Analyzer Instantiation ---

        # --- Instantiate/Load MLVulnerabilityPredictor (if not done in init or needs reload) ---
        # This ensures the predictor is loaded/reloaded when a new binary is
        # selected.
        try:
            # Get path from config again
            ml_model_path = CONFIG.get("ml_model_path")
            if ml_model_path and os.path.exists(ml_model_path):
                # Only reload the model if it's not already loaded with the same path
                if not self.ml_predictor or not hasattr(self.ml_predictor, 'model_path') or self.ml_predictor.model_path != ml_model_path:
                    self.ml_predictor = MLVulnerabilityPredictor(model_path=ml_model_path)
                    self.update_output.emit(log_message(f"[ML] Predictor reloaded with model: {ml_model_path}"))
                else:
                    self.update_output.emit(log_message(f"[ML] Using existing predictor (already loaded)"))
            elif not self.ml_predictor:  # If not loaded in init and no path found now
                self.update_output.emit(
                    log_message("[ML] Predictor model not found. Prediction disabled."))
                self.ml_predictor = None  # Ensure it's None
        except NameError:
            self.update_output.emit(log_message(
                "[ML] Predictor Failed: MLVulnerabilityPredictor class not found (Import missing?)."))
            self.ml_predictor = None
        except Exception as e_ml_load:
            self.update_output.emit(
                log_message(
                    f"[ML] Failed to load predictor model on binary select: {e_ml_load}"))
            self.ml_predictor = None
        # --- End ML Predictor Instantiation ---

        # --- Update UI Elements ---
        self.program_info.setText(
            f"Selected: {
                os.path.basename(
                    self.binary_path)}\nPath: {
                self.binary_path}")

        pixmap = get_file_icon(self.binary_path)
        if not pixmap or pixmap.isNull():
            if not os.path.exists("assets"):
                os.makedirs("assets", exist_ok=True)
            # Provide a default icon
            pixmap = QPixmap("assets/icon_preview.png")

        self.program_icon.setPixmap(pixmap.scaled(
            64, 64, Qt.KeepAspectRatio, Qt.SmoothTransformation))

        self.analyze_status.setText(
            f"Selected: {
                os.path.basename(
                    self.binary_path)}")
        self.update_output.emit(
            log_message(
                f"Selected program: {
                    self.binary_path}"))

        # Clear previous results and patches when a new binary is selected
        self.analyze_results.clear()
        self.potential_patches = []
        self.update_output.emit(
            log_message("Previous analysis results cleared."))

        # Refresh dashboard with binary info and switch to dashboard tab
        if hasattr(self, "binary_info"):
            self._refresh_and_show_dashboard()

    def remove_program(self):
        """Removes the currently selected program."""
        if not self.binary_path:
            return

        self.binary_path = None
        self.program_info.setText("No program selected")
        self.program_icon.clear()

        self.analyze_status.setText("No program selected")
        self.update_output.emit(log_message("Program removed"))

    def extract_binary_info(self, binary_path):
        """
        Extract detailed information from a binary file.

        Args:
            binary_path: Path to the binary file

        Returns:
            dict: Dictionary containing extracted binary information
        """
        # Initialize binary info dictionary
        binary_info = self._initialize_binary_info(binary_path)

        self.update_output.emit(log_message(f"[Binary] Extracting info from {os.path.basename(binary_path)}"))

        try:
            # Determine file type
            with open(binary_path, "rb") as file_handle:
                magic_bytes = file_handle.read(4)

            # Process file based on its type
            if magic_bytes.startswith(b'MZ'):
                binary_info = self._extract_pe_info(binary_path, binary_info)
            elif magic_bytes.startswith(b'\x7fELF'):
                binary_info = self._extract_elf_info(binary_path, binary_info)

            # Store binary info
            self.binary_info = binary_info

            # Update dashboard with binary info
            self._update_dashboard_with_binary_info(binary_info)

            # Log completion
            self._log_analysis_completion(binary_info)

            return binary_info

        except Exception as e:
            self.update_output.emit(log_message(f"[Binary] Error extracting binary info: {e}"))
            self.update_output.emit(log_message(traceback.format_exc()))
            return binary_info

    def _initialize_binary_info(self, binary_path):
        """Initialize the binary info dictionary with default values."""
        return {
            "name": os.path.basename(binary_path),
            "path": binary_path,
            "size": os.path.getsize(binary_path),
            "format": "Unknown",
            "architecture": "Unknown",
            "endianness": "Unknown",
            "bit_width": "Unknown",
            "compile_time": "Unknown",
            "compiler": "Unknown",
            "os_target": "Unknown",
            "imports": [],
            "exports": [],
            "sections": [],
            "symbols": [],
            "strings": [],
            "has_overlay": False,
            "is_packed": False,
            "is_stripped": False,
            "is_debuggable": False,
            "has_protections": False,
            "protection_types": [],
            "entry_point": 0
        }

    def _extract_pe_info(self, binary_path, binary_info):
        """Extract information from PE (Windows) files."""
        binary_info["format"] = "PE (Windows)"
        try:
            pe = pefile.PE(binary_path)

            # Extract PE-specific information
            self._extract_pe_architecture(pe, binary_info)
            self._extract_pe_metadata(pe, binary_info)
            self._extract_pe_sections_and_imports(pe, binary_info)
            self._detect_pe_protections(pe, binary_info)

            # Clean up
            pe.close()

        except ImportError:
            self.update_output.emit(log_message("[Binary] pefile module not found, limited PE analysis available"))
        except Exception as e:
            self.update_output.emit(log_message(f"[Binary] Error analyzing PE file: {e}"))

        return binary_info

    def _extract_pe_architecture(self, pe, binary_info):
        """Extract architecture information from PE file."""
        machine_type = pe.FILE_HEADER.Machine
        if machine_type == 0x14c:
            binary_info["architecture"] = "x86"
            binary_info["bit_width"] = "32-bit"
        elif machine_type == 0x8664:
            binary_info["architecture"] = "x86_64"
            binary_info["bit_width"] = "64-bit"
        elif machine_type == 0x1c0:
            binary_info["architecture"] = "ARM"
            binary_info["bit_width"] = "32-bit"
        elif machine_type == 0xaa64:
            binary_info["architecture"] = "ARM64"
            binary_info["bit_width"] = "64-bit"

        # Endianness is always Little for PE files
        binary_info["endianness"] = "Little"

    def _extract_pe_metadata(self, pe, binary_info):
        """Extract metadata from PE file (timestamps, entry points)."""
        # Compile time
        if hasattr(pe, "FILE_HEADER") and hasattr(pe.FILE_HEADER, "TimeDateStamp"):
            timestamp = pe.FILE_HEADER.TimeDateStamp
            compile_time = datetime.datetime.fromtimestamp(timestamp)
            binary_info["compile_time"] = compile_time.strftime("%Y-%m-%d %H:%M:%S")

        # Entry point
        if hasattr(pe, "OPTIONAL_HEADER"):
            binary_info["entry_point"] = hex(pe.OPTIONAL_HEADER.AddressOfEntryPoint)

    def _extract_pe_sections_and_imports(self, pe, binary_info):
        """Extract sections, imports and exports from PE file."""
        # Sections
        binary_info["sections"] = [section.Name.decode('utf-8', 'ignore').strip('\x00') for section in pe.sections]

        # Imports
        if hasattr(pe, "DIRECTORY_ENTRY_IMPORT"):
            for entry in pe.DIRECTORY_ENTRY_IMPORT:
                dll_name = entry.dll.decode('utf-8', 'ignore') if hasattr(entry, 'dll') else "Unknown"
                for imp in entry.imports[:10]:  # Limit to first 10 imports per DLL
                    import_name = imp.name.decode('utf-8', 'ignore') if imp.name else f"Ordinal {imp.ordinal}"
                    binary_info["imports"].append(f"{dll_name}:{import_name}")

        # Exports
        if hasattr(pe, "DIRECTORY_ENTRY_EXPORT"):
            for exp in pe.DIRECTORY_ENTRY_EXPORT.symbols[:20]:  # Limit to first 20 exports
                export_name = exp.name.decode('utf-8', 'ignore') if exp.name else f"Ordinal {exp.ordinal}"
                binary_info["exports"].append(export_name)

    def _detect_pe_protections(self, pe, binary_info):
        """Detect protection mechanisms in P
E files."""
        protections = []

        # Check for code signing
        if hasattr(pe, "DIRECTORY_ENTRY_SECURITY") and pe.DIRECTORY_ENTRY_SECURITY.VirtualAddress != 0:
            protections.append("Authenticode Signature")

        # Check for high entropy sections (possible packing)
        for section in pe.sections:
            section_entropy = section.get_entropy()
            if section_entropy > 7.0:
                protections.append("High Entropy (Possible Packing/Encryption)")
                binary_info["is_packed"] = True
                break

        # Check section names for known packers
        section_names = " ".join(binary_info["sections"]).lower()
        known_packers = {
            "upx": ("UPX Packing", True, False),
            "enigma": ("Enigma Protector", False, True),
            "themida": ("Themida/Winlicense", False, True),
            "aspack": ("ASPack", True, False)
        }

        for packer_name, (protection_name, sets_packed, sets_protected) in known_packers.items():
            if packer_name in section_names:
                protections.append(protection_name)
                if sets_packed:
                    binary_info["is_packed"] = True
                if sets_protected:
                    binary_info["has_protections"] = True

        binary_info["protection_types"] = protections
        binary_info["has_protections"] = len(protections) > 0

    def _extract_elf_info(self, binary_path, binary_info):
        """Extract information from ELF (Linux/Unix) files."""
        binary_info["format"] = "ELF (Linux/Unix)"
        try:

            with open(binary_path, 'rb') as elf_file:
                elf = ELFFile(elf_file)
                self._extract_elf_architecture(elf, binary_info)
                self._extract_elf_metadata(elf, binary_info)
                self._extract_elf_sections_and_symbols(elf, binary_info)

        except ImportError:
            self.update_output.emit(log_message("[Binary] pyelftools module not found, limited ELF analysis available"))
        except Exception as e:
            self.update_output.emit(log_message(f"[Binary] Error analyzing ELF file: {e}"))

        return binary_info

    def _extract_elf_architecture(self, elf, binary_info):
        """Extract architecture information from ELF file."""
        # Architecture
        machine = elf.header['e_machine']
        arch_map = {
            'EM_386': 'x86',
            'EM_X86_64': 'x86_64',
            'EM_ARM': 'ARM',
            'EM_AARCH64': 'ARM64',
            'EM_MIPS': 'MIPS'
        }
        binary_info["architecture"] = arch_map.get(machine, machine)

        # Bit width
        binary_info["bit_width"] = "64-bit" if elf.elfclass == 64 else "32-bit"

        # Endianness
        binary_info["endianness"] = "Little" if elf.little_endian else "Big"

    def _extract_elf_metadata(self, elf, binary_info):
        """Extract metadata from ELF file."""
        # Entry point
        binary_info["entry_point"] = hex(elf.header['e_entry'])

        # OS target
        os_map = {
            'ELFOSABI_SYSV': 'System V',
            'ELFOSABI_HPUX': 'HP-UX',
            'ELFOSABI_NETBSD': 'NetBSD',
            'ELFOSABI_LINUX': 'Linux',
            'ELFOSABI_SOLARIS': 'Solaris',
            'ELFOSABI_AIX': 'AIX',
            'ELFOSABI_FREEBSD': 'FreeBSD'
        }
        os_abi = elf.header['e_ident']['EI_OSABI']
        binary_info["os_target"] = os_map.get(os_abi, os_abi)

    def _extract_elf_sections_and_symbols(self, elf, binary_info):
        """Extract sections and symbols from ELF file."""
        # Sections
        binary_info["sections"] = [section.name for section in elf.iter_sections()]

        # Symbols
        if elf.get_section_by_name('.symtab'):
            symbol_section = elf.get_section_by_name('.symtab')
            for i, symbol in enumerate(symbol_section.iter_symbols()):
                if i < 20:  # Limit to first 20 symbols
                    binary_info["symbols"].append(symbol.name)

        # Check if stripped
        binary_info["is_stripped"] = elf.get_section_by_name('.symtab') is None

        # Check for debugging info
        binary_info["is_debuggable"] = any(s.name.startswith('.debug_') for s in elf.iter_sections())

    def _update_dashboard_with_binary_info(self, binary_info):
        """Update dashboard with binary info if available."""
        try:
            if not hasattr(self, "dashboard_manager"):
                self.logger.warning("No dashboard manager available to update with binary info")
                return

            # Log diagnostic information
            self.logger.info(f"Updating dashboard with binary info: {binary_info.get('format', 'Unknown')}")

            # Update stats dict in dashboard manager
            stats_dict = {
                "binary_info": {
                    "format": binary_info.get("format", "Unknown"),
                    "architecture": binary_info.get("architecture", "Unknown"),
                    "bit_width": binary_info.get("bit_width", "Unknown"),
                    "has_protections": binary_info.get("has_protections", False),
                    "is_packed": binary_info.get("is_packed", False)
                }
            }

            # Call update_stats instead of update_statistics
            if hasattr(self.dashboard_manager, "update_stats"):
                # First ensure the stats dictionary exists
                if not hasattr(self.dashboard_manager, "stats"):
                    self.dashboard_manager.stats = {}

                # Then update it manually
                for key, value in stats_dict.items():
                    self.dashboard_manager.stats[key] = value

                # Refresh dashboard
                self.dashboard_manager.update_stats()
                self.logger.info("Successfully updated dashboard with binary info")
            else:
                self.logger.error("DashboardManager has no update_stats method")

            # Update the dashboard UI widgets with binary info
            self.refresh_dashboard_ui(binary_info)

        except Exception as e:
            self.logger.error(f"Error updating dashboard with binary info: {str(e)}")

    def _refresh_and_show_dashboard(self):
        """Updates dashboard with binary info and switches to dashboard tab to ensure visibility."""
        # Update the dashboard with current binary info
        self._update_dashboard_with_binary_info(self.binary_info if hasattr(self, 'binary_info') else {})

        # Switch to the dashboard tab to show the updated info
        if hasattr(self, 'tabs') and hasattr(self, 'dashboard_tab'):
            dashboard_index = self.tabs.indexOf(self.dashboard_tab)
            if dashboard_index >= 0:
                self.tabs.setCurrentIndex(dashboard_index)
                self.logger.debug("Switched to dashboard tab after refreshing data")
            else:
                self.logger.warning("Dashboard tab not found in tabs widget")

    def refresh_dashboard_ui(self, binary_info):
        """Explicitly updates dashboard UI widgets with binary information."""
        try:
            if not hasattr(self, "dashboard_tab") or not binary_info:
                return

            # Find the specific dashboard labels by their object names
            binary_name_label = self.dashboard_tab.findChild(QLabel, "dashboard_binary_name_label")
            binary_icon_label = self.dashboard_tab.findChild(QLabel, "dashboard_binary_icon_label")

            if binary_name_label:
                # Update binary name label with rich text formatting
                binary_path = binary_info.get("path", "Unknown")
                binary_name = os.path.basename(binary_path) if binary_path != "Unknown" else "Unknown"
                binary_name_label.setText(f"<b>{binary_name}</b><br><small>{binary_path}</small>")
                self.logger.debug(f"Updated dashboard binary name label with: {binary_name}")

            if binary_icon_label:
                # Update binary icon label with icon from file
                binary_path = binary_info.get("path", "")
                icon_pixmap = None

                if binary_path and os.path.exists(binary_path):
                    icon_pixmap = get_file_icon(binary_path)

                # Set a default icon if extraction fails or returns None
                if not icon_pixmap or icon_pixmap.isNull():
                    default_icon_path = "assets/binary_icon.png"
                    if os.path.exists(default_icon_path):
                        icon_pixmap = QPixmap(default_icon_path)
                    else:
                        # Create a default colored rectangle if no icon available
                        icon_pixmap = QPixmap(64, 64)
                        icon_pixmap.fill(QColor(0, 120, 215))

                # Set the icon pixmap to the label
                binary_icon_label.setPixmap(icon_pixmap.scaled(64, 64, Qt.KeepAspectRatio, Qt.SmoothTransformation))
                self.logger.debug("Updated dashboard binary icon label")

        except Exception as e:
            self.logger.error(f"Error refreshing dashboard UI: {str(e)}")

    def _log_analysis_completion(self, binary_info):
        """Log completion of binary analysis."""
        self.update_output.emit(log_message(
            f"[Binary] Analysis complete: {binary_info['format']} {binary_info['architecture']} {binary_info['bit_width']}"))

        if binary_info["has_protections"]:
            self.update_output.emit(log_message(
                f"[Binary] Detected protections: {', '.join(binary_info['protection_types'])}"))

    def run_autonomous_crack(self):
        """Initiates the autonomous crack process."""
        self.user_input.setPlainText(
            "Crack this program using all available tools")
        self.send_to_model()

    def run_analysis(self):
        """
        Performs full analysis of the selected binary and outputs the results.
        Enhanced with better organization and more detailed information.
        """
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        # Collect analysis options
        flags = []
        if self.stealth_checkbox.isChecked():
            flags.append("stealth")
        if self.auto_patch_checkbox.isChecked():
            flags.append("auto")
        if self.frida_checkbox.isChecked():
            flags.append("frida")
        if self.qiling_checkbox.isChecked():
            flags.append("qiling")
        if self.heuristic_patch_checkbox.isChecked():
            flags.append("heuristic")

        # Get analysis depth value
        analysis_depth = self.analysis_depth_slider.value()

        msg = "[Analysis] Starting full analysis..."
        self.update_output.emit(log_message(msg))
        self.log_output.append(log_message(msg))  # Also log to Live Logs tab
        self.analyze_status.setText("Analyzing...")

        # Run analysis in a background thread (TARGETING THE CORRECT FUNCTION
        # BELOW)
        threading.Thread(
            target=self._run_analysis_thread,
            args=(flags, analysis_depth)
        ).start()

    def _run_analysis_thread(self, flags, analysis_depth):
        """
        Background thread for running analysis.
        COMBINES original analysis functions with new Advanced Engines.
        (Corrected Version)

        Args:
            flags: List of enabled analysis flags
            analysis_depth: Integer value (10-100) indicating how deep the analysis should go
        """
        # Initialize variables that will be used throughout the function
        # These must be initialized before any try/except blocks to ensure they always exist
        ml_predictions = []
        vulnerabilities = []
        license_results = None
        detected_protectors = []
        packing_summary_line = ""

        # Log the analysis options being used
        self.update_output.emit(log_message(f"[Analysis] Using flags: {', '.join(flags)}"))
        self.update_output.emit(log_message(f"[Analysis] Analysis depth: {analysis_depth}"))
        self.update_analysis_results.emit(f"Analysis Options: {', '.join(flags)}\n")
        self.update_analysis_results.emit(f"Analysis Depth: {analysis_depth}\n")

        try:
            # --- Initial Setup ---
            self.clear_analysis_results.emit()
            self.update_analysis_results.emit("Starting Full Analysis...\n")

            filesize = os.path.getsize(self.binary_path)
            self.update_output.emit(log_message(
                f"[Analysis] File size: {filesize:,} bytes"))
            self.update_analysis_results.emit(
                f"File: {
                    os.path.basename(
                        self.binary_path)}, Size: {
                    filesize:,} bytes\n")

            # --- PE Check ---
            with open(self.binary_path, "rb") as binary_file:
                header = binary_file.read(4)
                if header[:2] == b"MZ":
                    pe_valid_msg = "[Analysis] PE signature found (Windows executable)"
                    self.update_output.emit(log_message(pe_valid_msg))
                    self.update_analysis_results.emit(pe_valid_msg + "\n")
                else:
                    pe_invalid_msg = "[Analysis] Not a valid PE executable"
                    self.update_output.emit(log_message(pe_invalid_msg))
                    self.update_analysis_results.emit(pe_invalid_msg + "\n")
                    self.update_status.emit("Not a valid PE executable")
                    return

            self.update_output.emit(
                log_message("[Analysis] Running standard binary structure analysis..."))
            self.update_analysis_results.emit(
                "\n=== Standard Binary Analysis ===\n")
            try:
                binary_structure_results = analyze_binary_internal(
                    self.binary_path, flags)
                for line in binary_structure_results:
                    if "Analyzing binary:" in line or "File size:" in line or "PE Header:" in line or "Imports:" in line or "Exports:" in line or "Sections:" in line or "WARNING:" in line:
                        self.update_output.emit(log_message(line))
                    self.update_analysis_results.emit(line + "\n")
            except Exception as e_struct:
                err_msg = f"[Analysis] Error during standard structure analysis: {e_struct}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")

            self.update_output.emit(
                log_message("[Analysis] Searching for embedded scripts..."))
            self.update_analysis_results.emit("\n=== Embedded Scripts ===\n")
            try:
                # Assuming decrypt_embedded_script is defined elsewhere
                embedded = decrypt_embedded_script(
                    self.binary_path)  # Original call
                if embedded and len(embedded) > 1:
                    for line in embedded:
                        if "Searching for" in line or "Found" in line or "No embedded" in line:
                            self.update_output.emit(log_message(line))
                        self.update_analysis_results.emit(line + "\n")
                else:
                    no_scripts_msg = "No embedded scripts found by standard scan."
                    self.update_output.emit(log_message(no_scripts_msg))
                    self.update_analysis_results.emit(no_scripts_msg + "\n")
            except Exception as e_embed:
                err_msg = f"[Analysis] Error scanning for embedded scripts: {e_embed}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")

            self.update_output.emit(
                log_message("[Analysis] Checking for protectors (standard scan)..."))
            self.update_analysis_results.emit(
                "\n=== Standard Protector Scan ===\n")
            detected_protectors = []
            try:
                protectors = scan_for_bytecode_protectors(self.binary_path)
                if "error" in protectors:
                    err_msg = f"[Analysis] Error scanning for protectors: {
                        protectors['error']}"
                    self.update_output.emit(log_message(err_msg))
                    self.update_analysis_results.emit(err_msg + "\n")
                else:
                    detected_protectors = [
                        name for name, details in protectors.items() if isinstance(
                            details, dict) and details.get(
                            "detected", False)]
                    if detected_protectors:
                        prot_msg = f"Detected protectors (standard scan): {
                            ', '.join(detected_protectors)}"
                        self.update_output.emit(log_message(prot_msg))
                        self.update_analysis_results.emit(prot_msg + "\n")
                        for name, details in protectors.items():
                            if isinstance(
                                    details, dict) and details.get("detected"):
                                details_str = f"  - {name}: {details}"
                                self.update_analysis_results.emit(
                                    details_str + "\n")
                    else:
                        no_prot_msg = "No specific protectors detected (standard scan)."
                        self.update_output.emit(log_message(no_prot_msg))
                        self.update_analysis_results.emit(no_prot_msg + "\n")
            except Exception as e_prot:
                err_msg = f"[Analysis] Error during standard protector scan: {e_prot}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")

            self.update_output.emit(
                log_message("[Analysis] Running packing/entropy analysis (standard scan)..."))
            self.update_analysis_results.emit(
                "\n=== Standard Packing/Entropy Analysis ===\n")
            packing_summary_line = ""
            try:
                entropy_report = detect_packing(self.binary_path)
                for line in entropy_report:
                    if "summary:" in line.lower():
                        packing_summary_line = line.split(":", 1)[1].strip()
                        self.update_output.emit(log_message(
                            f"[Packing Summary] {packing_summary_line}"))
                    self.update_analysis_results.emit(line + "\n")
            except Exception as e_pack:
                err_msg = f"[Analysis] Error during standard packing scan: {e_pack}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")

                self.update_output.emit(
                    log_message("[Analysis] Running advanced vulnerability scan (New Engine)..."))
                self.update_analysis_results.emit(
                    "\n=== Advanced Vulnerability Scan (New Engine) ===\n")
            try:
                vulnerabilities = AdvancedVulnerabilityEngine.scan_binary(
                    self.binary_path)
                if vulnerabilities:
                    vuln_summary = f"Found {
                        len(vulnerabilities)} vulnerabilities (Types: {
                        ', '.join(
                            list(
                                set(
                                    v['type'] for v in vulnerabilities)))})"
                    self.update_output.emit(log_message(
                        f"[Adv Vuln Scan] {vuln_summary}"))
                    self.update_analysis_results.emit(vuln_summary + "\n")
                    for i, vuln in enumerate(vulnerabilities):
                        vuln_str = f"[{i +
                                       1}] Type: {vuln['type']}, Risk: {vuln.get('risk', 'Unspecified')}"
                        if 'function' in vuln:
                            vuln_str += f", Function: {vuln['function']}"
                        if 'section_name' in vuln:
                            vuln_str += f", Section: {vuln['section_name']}"
                        if 'offset' in vuln:
                            vuln_str += f", Offset: {vuln['offset']}"
                        if 'severity' in vuln:
                            vuln_str += f", Severity: {vuln['severity']}"
                        self.update_analysis_results.emit(
                            "  " + vuln_str + "\n")
                else:
                    no_vulns_msg = "No specific vulnerabilities found by AdvancedVulnerabilityEngine."
                    self.update_output.emit(log_message(no_vulns_msg))
                    self.update_analysis_results.emit(no_vulns_msg + "\n")
            except NameError:
                err_msg = "[Analysis] AdvancedVulnerabilityEngine class not found. Make sure the class is defined in this file."
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")
            except Exception as e_vuln:
                err_msg = f"[Analysis] Error running AdvancedVulnerabilityEngine: {e_vuln}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")
                self.update_output.emit(
                    log_message("[Analysis] Running ML vulnerability prediction (New Engine)..."))
                self.update_analysis_results.emit(
                    "\n=== ML Vulnerability Predictions (New Engine) ===\n")

            # Enhanced ML prediction section with detailed diagnostics
            try:
                # Ensure ml_predictions is initialized even if it doesn't get set below
                if not isinstance(ml_predictions, list):
                    ml_predictions = []

                # Log detailed information about the ML predictor state
                if hasattr(self, 'ml_predictor'):
                    if self.ml_predictor:
                        if hasattr(self.ml_predictor, 'model') and self.ml_predictor.model:
                            model_path = getattr(self.ml_predictor, 'model_path', 'Unknown path')
                            self.update_output.emit(log_message(f"[ML Diagnostic] Found valid ML predictor with model at: {model_path}"))

                            # Get configuration details for diagnostics
                            config_model_path = CONFIG.get("ml_model_path", "Not set in CONFIG")
                            self.update_output.emit(log_message(f"[ML Diagnostic] CONFIG['ml_model_path']: {config_model_path}"))

                            # Check if file exists at the location where it's supposed to be
                            if hasattr(self.ml_predictor, 'model_path'):
                                model_exists = os.path.exists(self.ml_predictor.model_path)
                                self.update_output.emit(log_message(f"[ML Diagnostic] Model file exists: {model_exists}"))

                            # Attempt to run prediction
                            ml_predictions = self.ml_predictor.predict_vulnerabilities(self.binary_path)

                            # Check prediction results
                            if ml_predictions:
                                ml_summary = f"ML predicts potential: {', '.join(p['type'] for p in ml_predictions)}"
                                self.update_output.emit(log_message(f"[ML Predict] {ml_summary}"))
                                self.update_analysis_results.emit(ml_summary + "\n")

                                for pred in ml_predictions:
                                    pred_str = f"  Type: {pred['type']}, Probability: {pred['probability']:.2f}"
                                    self.update_analysis_results.emit(pred_str + "\n")
                            else:
                                no_ml_pred_msg = "ML predictor returned no specific predictions."
                                self.update_output.emit(log_message(no_ml_pred_msg))
                                self.update_analysis_results.emit(no_ml_pred_msg + "\n")
                        else:
                            err_msg = "[ML Diagnostic] ML predictor exists but has no valid model attribute."
                            self.update_output.emit(log_message(err_msg))
                            self.update_analysis_results.emit(err_msg + "\n")

                            # Try to get more details
                            if hasattr(self.ml_predictor, 'model_path'):
                                model_path = self.ml_predictor.model_path
                                model_exists = os.path.exists(model_path)
                                self.update_output.emit(log_message(f"[ML Diagnostic] Model path: {model_path}, Exists: {model_exists}"))
                    else:
                        ml_model_missing_msg = "[ML Diagnostic] ML predictor is None. Model was not properly loaded during initialization."
                        self.update_output.emit(log_message(ml_model_missing_msg))
                        self.update_analysis_results.emit(ml_model_missing_msg + "\n")
                else:
                    ml_attr_missing_msg = "[ML Diagnostic] No 'ml_predictor' attribute found on this object."
                    self.update_output.emit(log_message(ml_attr_missing_msg))
                    self.update_analysis_results.emit(ml_attr_missing_msg + "\n")
            except NameError as e_name:
                err_msg = f"[Analysis] MLVulnerabilityPredictor class not found: {str(e_name)}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")
                # Additional debug info
                self.update_output.emit(log_message(f"[ML Debug] NameError details: {traceback.format_exc()}"))
            except Exception as e_ml:
                err_msg = f"[Analysis] Error running MLVulnerabilityPredictor: {e_ml}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")
                # Additional debug info with full traceback
                self.update_output.emit(log_message(f"[ML Debug] Exception details: {traceback.format_exc()}"))

            try:
                license_results = enhanced_deep_license_analysis(
                    self.binary_path)
                if license_results:
                    lic_found_msg = f"Found {
                        len(license_results)} potential license-related code regions (deep scan)"
                    self.update_output.emit(log_message(
                        f"[Deep Scan] {lic_found_msg}"))
                    self.update_analysis_results.emit(lic_found_msg + "\n")
                    for i, result in enumerate(license_results[:5]):
                        msg = f"Region {
                            i +
                            1}: Found at 0x{
                            result['start']:X}, Keywords: {
                            ', '.join(
                                result.get(
                                    'keywords',
                                    []))}"
                        self.update_analysis_results.emit("  " + msg + "\n")
                        if 'instructions' in result and result['instructions']:
                            self.update_analysis_results.emit(
