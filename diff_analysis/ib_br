                                "    Instructions (Preview):\n")
                            for inst in result['instructions'][:3]:
                                self.update_analysis_results.emit(
                                    f"      {inst}\n")
                else:
                    no_lic_msg = "No specific license-related code found (deep scan)."
                    self.update_output.emit(log_message(no_lic_msg))
                    self.update_analysis_results.emit(no_lic_msg + "\n")
            except Exception as e_deep_lic:
                err_msg = f"[Analysis] Error during deep license analysis: {e_deep_lic}"
                self.update_output.emit(log_message(err_msg))
                self.update_analysis_results.emit(err_msg + "\n")

            # --- Final Summary ---
            self.update_output.emit(
                log_message("[Analysis] Analysis complete."))
            self.update_status.emit("Analysis complete")

            # Combine results for the summary
            summary = ["\n=== OVERALL ANALYSIS SUMMARY ==="]
            summary.append(f"File: {os.path.basename(self.binary_path)}")
            summary.append(f"Size: {filesize:,} bytes")
            if detected_protectors:
                summary.append(
                    f"Protectors (Standard Scan): {
                        ', '.join(detected_protectors)}")
            if packing_summary_line:
                summary.append(
                    f"Packing (Standard Scan): {packing_summary_line}")
            if vulnerabilities:
                summary.append(
                    f"Vulnerabilities (Advanced Scan): {
                        len(vulnerabilities)} found.")
            if ml_predictions:
                summary.append(
                    f"ML Predictions: {
                        len(ml_predictions)} potential issues.")
            if license_results:
                summary.append(
                    f"License Code (Deep Scan): {
                        len(license_results)} potential regions.")

            summary.append("\nRecommended actions:")
            summary.append("1. Review full results above.")
            summary.append(
                "2. Use 'Preview Patch Plan' or 'Automated Patch Agent'.")
            if detected_protectors or "PACKED" in packing_summary_line:
                summary.append(
                    "3. Consider 'Memory Patching' due to detected protection/packing.")

            self.update_analysis_results.emit("\n".join(summary))

        except Exception as e:
            # Catch-all for errors in the thread function
            error_msg = f"[Analysis] Error: {e}"
            trace_msg = traceback.format_exc()
            self.update_output.emit(log_message(error_msg))
            self.update_output.emit(log_message(trace_msg))
            self.update_analysis_results.emit("\n" + error_msg + "\n")
            self.update_analysis_results.emit(trace_msg + "\n")
            self.update_status.emit(f"Error: {str(e)}")

    def run_deep_license_analysis(self):
        """Runs deep license analysis and outputs the results."""
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        self.update_output.emit(log_message(
            "[Deep License Analysis] Starting analysis..."))
        self.analyze_status.setText("Running deep license analysis...")

        # Run in background thread
        threading.Thread(target=self._run_deep_license_analysis_thread).start()

    def _run_deep_license_analysis_thread(self):
        """Background thread for deep license analysis."""
        try:
            self.clear_analysis_results.emit()

            candidates = enhanced_deep_license_analysis(self.binary_path)

            if not candidates:
                self.update_output.emit(log_message(
                    "[Deep License Analysis] No licensing patterns detected."))
                self.update_analysis_results.emit(
                    "No licensing patterns detected.")
                self.update_status.emit("No licensing patterns found")
                return

            self.update_output.emit(
                log_message(
                    f"[Deep License Analysis] Found {
                        len(candidates)} potential licensing regions."))

            self.update_analysis_results.emit(
                f"Found {len(candidates)} potential licensing code regions:")
            self.update_analysis_results.emit("=" * 50)

            for i, candidate in enumerate(candidates):
                confidence = candidate.get("confidence", 0)
                keywords = ", ".join(candidate.get("keywords", []))

                self.update_output.emit(log_message(
                    f"[Deep Analysis] Region {
                        i +
                        1} at 0x{
                        candidate['start']:X}: "
                    f"Keywords: {keywords}, Confidence: {confidence}"
                ))

                self.update_analysis_results.emit(f"Region {i + 1}:")
                self.update_analysis_results.emit(
                    f"  Address range: 0x{
                        candidate['start']:X} - 0x{
                        candidate.get(
                            'end', candidate['start']):X}")
                self.update_analysis_results.emit(f"  Keywords: {keywords}")
                self.update_analysis_results.emit(
                    f"  Confidence: {confidence}")

                if 'instructions' in candidate and candidate['instructions']:
                    self.update_analysis_results.emit("  Instructions:")
                    for inst in candidate['instructions'][:10]:
                        self.update_analysis_results.emit(f"    {inst}")
                    if len(candidate['instructions']) > 10:
                        self.update_analysis_results.emit(
                            f"    ... plus {len(candidate['instructions']) - 10} more")

                self.update_analysis_results.emit("-" * 50)

            self.update_analysis_results.emit("\nRecommendations:")
            self.update_analysis_results.emit(
                "1. Use 'Automated Patch Agent' to attempt automatic patching")
            self.update_analysis_results.emit(
                "2. Try 'Deep Runtime Monitoring' to observe behavior during execution")
            self.update_analysis_results.emit(
                "3. Use 'Preview Patch Plan' to see potential patch locations")

            self.update_status.emit(
                f"Found {len(candidates)} licensing regions")

        except Exception as e:
            self.update_output.emit(log_message(
                f"[Deep License Analysis] Error: {e}"))
            self.update_output.emit(log_message(traceback.format_exc()))
            self.update_status.emit(f"Error: {str(e)}")

    def run_ghidra_analysis_gui(self):
        """Entry point for Ghidra GUI + license string scan"""
        # Renamed local variable to avoid name conflict with global function
        threading.Thread(
            target=run_ghidra_analysis_gui,  # This is the global function
            args=(self,),
            daemon=True
        ).start()

    def run_deep_runtime_monitoring(self):
        """Runs deep runtime monitoring on the selected binary."""
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        self.update_output.emit(log_message(
            "[Runtime Monitoring] Starting deep runtime monitoring..."))
        self.analyze_status.setText("Starting runtime monitoring...")

        # Run in background thread
        threading.Thread(
            target=self._run_deep_runtime_monitoring_thread).start()

    def _run_deep_runtime_monitoring_thread(self):
        """Background thread for deep runtime monitoring."""
        try:
            self.clear_analysis_results.emit()

            timeout = CONFIG.get("max_runtime_monitoring", 30000)
            logs = deep_runtime_monitoring(self.binary_path, timeout)

            for log in logs:
                self.update_output.emit(log_message(log))
                self.update_analysis_results.emit(log)

            self.update_output.emit(log_message(
                "[Runtime Monitoring] Monitoring complete."))
            self.update_status.emit("Runtime monitoring complete")

        except Exception as e:
            self.update_output.emit(log_message(
                f"[Runtime Monitoring] Error: {e}"))
            self.update_output.emit(log_message(traceback.format_exc()))
            self.update_status.emit(f"Error: {str(e)}")

    def run_autonomous_patching(self):
        """Wrapper to start the autonomous patching thread."""
        self.update_output.emit(log_message(
            "[AI Patching] Starting autonomous patching process via UI action..."))
        threading.Thread(
            target=self._run_autonomous_patching_thread, daemon=True
        ).start()

    def preview_patch(self):
        """
        Previews a patch plan by disassembling the binary and suggesting modifications.
        Enhanced with better detection and more detailed suggestions.
        """
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        self.update_output.emit(log_message(
            "[Patch Preview] Starting patch preview..."))
        self.analyze_status.setText("Generating patch preview...")

        # Run in background thread
        threading.Thread(target=self._preview_patch_thread).start()

    def _preview_patch_thread(self):
        """Background thread for patch preview."""
        try:
            self.clear_analysis_results.emit()
            pe = pefile.PE(self.binary_path)
            is_64bit = getattr(pe.FILE_HEADER, "Machine", 0) == 0x8664
            mode = CS_MODE_64 if is_64bit else CS_MODE_32

            code_section = next(
                (s for s in pe.sections if b".text" in s.Name), None)
            if not code_section:
                self.update_output.emit(log_message(
                    "[Patch Preview] .text section not found"))
                self.update_analysis_results.emit(
                    "Error: .text section not found")
                self.update_status.emit("Error: .text section not found")
                return

            code_data = code_section.get_data()
            base_addr = pe.OPTIONAL_HEADER.ImageBase + code_section.VirtualAddress

            md = Cs(CS_ARCH_X86, mode)
            md.detail = True

            self.update_output.emit(log_message(
                "[Patch Preview] Searching for license-related code..."))
            license_regions = enhanced_deep_license_analysis(self.binary_path)

            patches = []

            def find_jumps_in_region(instructions, region_start, region_end):
                """
                Find jump and call instructions within a specified address region.

                Args:
                    instructions: List of instruction objects.
                    region_start: Start address of the region.
                    region_end: End address of the region.

                Returns:
                    List of instructions that are jumps or calls within the region.
                """
                jumps = []
                for insn in instructions:
                    if insn.address >= region_start and insn.address <= region_end:
                        if insn.mnemonic in ["je", "jne", "jz", "jnz", "call"]:
                            jumps.append(insn)
                return jumps

            if license_regions:
                self.update_output.emit(
                    log_message(
                        f"[Patch Preview] Found {
                            len(license_regions)} license regions. Analyzing for patch points..."))
                self.update_analysis_results.emit(
                    f"Found {len(license_regions)} potential license regions:")

                all_instructions = list(md.disasm(code_data, base_addr))

                for region_idx, region in enumerate(license_regions):
                    region_start = region["start"]
                    region_end = region.get("end", region_start + 100)

                    self.update_analysis_results.emit(
                        f"\nRegion {region_idx + 1} (0x{region_start:X} - 0x{region_end:X}):")

                    jumps = find_jumps_in_region(
                        all_instructions, region_start, region_end)

                    if jumps:
                        self.update_analysis_results.emit(
                            f"  Found {len(jumps)} potential patch points:")

                        for i, jump in enumerate(jumps):
                            ctx_start = max(0, i - 2)
                            ctx_end = min(len(jumps), i + 3)
                            context = jumps[ctx_start:ctx_end]

                            # Build code context to show to user
                            context_lines = []
                            for ctx_insn in context:
                                prefix = "➤ " if ctx_insn.address == jump.address else "  "
                                context_lines.append(f"{prefix}0x{ctx_insn.address:x}: {ctx_insn.mnemonic} {ctx_insn.op_str}")

                            # Display code context
                            self.update_analysis_results.emit("\n".join(context_lines))

                            # Analyze context to determine best patch strategy
                            is_condition_check = any(
                                x.mnemonic in ["cmp", "test"] for x in context if context.index(x) < context.index(jump)
                            )
                            is_function_call = jump.mnemonic == "call"
                            patch_type = "bypass" if is_condition_check else "neutralize" if is_function_call else "modify"

                            # Use patch_type to determine the most effective patch strategy
                            self.update_output.emit(log_message(f"[Patch Preview] Recommended patch type: {patch_type}"))
                            self.update_analysis_results.emit(f"  Recommended strategy: {patch_type.upper()}")

                            patch_desc = ""
                            patch_bytes = ""

                            # Apply patching strategy based on patch_type and instruction
                            if patch_type == "neutralize" and jump.mnemonic == "call":
                                # For call instructions, replace with code that returns success
                                if is_64bit:
                                    patch_bytes = "48C7C001000000C3"
                                    patch_desc = "Replace call with 'mov rax, 1; ret' (always return success)"
                                else:
                                    patch_bytes = "B801000000C3"
                                    patch_desc = "Replace call with 'mov eax, 1; ret' (always return success)"
                            elif patch_type == "bypass" and jump.mnemonic in ["je", "jz"]:
                                # For conditional jumps after checks, replace with NOPs
                                nop_count = jump.size
                                patch_bytes = "90" * nop_count
                                patch_desc = f"Replace conditional jump with {nop_count} NOPs (always continue)"
                            elif jump.mnemonic in ["jne", "jnz"]:
                                if len(jump.op_str.split(",")) > 0:
                                    target = jump.op_str.split(",")[0].strip()
                                    patch_bytes = "E9" + target[2:]
                                    patch_desc = "Replace conditional jump with unconditional JMP (always take branch)"
                                else:
                                    nop_count = jump.size
                                    patch_bytes = "90" * nop_count
                                    patch_desc = f"Replace conditional jump with {nop_count} NOPs (never take branch)"

                            offset = jump.address - pe.OPTIONAL_HEADER.ImageBase
                            file_offset = pe.get_offset_from_rva(offset)

                            self.update_analysis_results.emit(
                                f"    Patch {i + 1}:")
                            self.update_analysis_results.emit(
                                f"      Address: 0x{
                                    jump.address:X} (File offset: 0x{
                                    file_offset:X})")
                            self.update_analysis_results.emit(
                                f"      Instruction: {
                                    jump.mnemonic} {
                                    jump.op_str}")
                            self.update_analysis_results.emit(
                                f"      Patch: {patch_desc}")
                            self.update_analysis_results.emit(
                                f"      Bytes: {patch_bytes}")

                            patches.append({
                                "address": jump.address,
                                "instruction": f"{jump.mnemonic} {jump.op_str}",
                                "new_bytes": bytes.fromhex(patch_bytes) if patch_bytes else None,
                                "description": patch_desc
                            })
                    else:
                        self.update_analysis_results.emit(
                            "  No suitable patch points found in this region.")
            else:
                self.update_output.emit(log_message(
                    "[Patch Preview] No license regions found. Using general approach..."))

                patch_count = 0
                instructions = list(md.disasm(code_data, base_addr))

                for i, insn in enumerate(instructions):
                    if i + \
                            1 < len(instructions) and insn.mnemonic in ["cmp", "test"]:
                        next_insn = instructions[i + 1]
                        if next_insn.mnemonic in ["je", "jne", "jz", "jnz"]:
                            patch_count += 1
                            patch_desc = ""
                            patch_bytes = ""
                            nop_count = next_insn.size
                            patch_bytes = "90" * nop_count
                            patch_desc = f"Replace conditional jump with {nop_count} NOPs"

                            offset = next_insn.address - pe.OPTIONAL_HEADER.ImageBase
                            file_offset = pe.get_offset_from_rva(offset)

                            self.update_output.emit(
                                log_message(
                                    f"[Patch Preview] Candidate {patch_count}: " f"0x{
                                        file_offset:X}: {
                                        next_insn.mnemonic} {
                                        next_insn.op_str} -> {patch_desc}"))

                            patches.append({
                                "address": next_insn.address,
                                "instruction": f"{next_insn.mnemonic} {next_insn.op_str}",
                                "new_bytes": bytes.fromhex(patch_bytes) if patch_bytes else None,
                                "description": patch_desc
                            })

                if patch_count == 0:
                    self.update_output.emit(log_message(
                        "[Patch Preview] No patch candidates found."))
                    self.update_analysis_results.emit(
                        "No suitable patch candidates found.")
                    self.update_status.emit("No patch candidates found")
                else:
                    self.update_analysis_results.emit(
                        f"Found {patch_count} general patch candidates:")
                    for i, patch in enumerate(patches):
                        self.update_analysis_results.emit(f"\nPatch {i + 1}:")
                        self.update_analysis_results.emit(
                            f"  Address: 0x{patch['address']:X}")
                        self.update_analysis_results.emit(
                            f"  Instruction: {patch['instruction']}")
                        self.update_analysis_results.emit(
                            f"  Description: {patch['description']}")
                        if patch['new_bytes']:
                            self.update_analysis_results.emit(
                                f"  Bytes: {patch['new_bytes'].hex().upper()}")

            self.potential_patches = patches

            if patches:
                self.update_output.emit(
                    log_message(
                        f"[Patch Preview] Generated {
                            len(patches)} potential patches."))
                self.update_status.emit(
                    f"Found {len(patches)} potential patches")

                self.update_analysis_results.emit("\nPatch Summary:")
                self.update_analysis_results.emit(
                    f"- Total patches: {len(patches)}")
                self.update_analysis_results.emit(
                    "- To apply these patches, use 'Apply Patch Plan' button")
                self.update_analysis_results.emit(
                    "- Patches will create a new file with '_patched' suffix")
                self.update_analysis_results.emit(
                    "- Original file will not be modified")
            else:
                self.update_output.emit(log_message(
                    "[Patch Preview] No patch candidates found."))
                self.update_status.emit("No patch candidates found")

        except (FileNotFoundError, PermissionError) as e:
            self.update_output.emit(log_message(f"[Patch Preview] File access error: {e}"))
            self.update_status.emit(f"File access error: {str(e)}")
        except (pefile.PEFormatError, ValueError) as e:
            self.update_output.emit(log_message(f"[Patch Preview] Binary parsing error: {e}"))
            self.update_status.emit(f"Binary parsing error: {str(e)}")
        except (TypeError, AttributeError) as e:
            self.update_output.emit(log_message(f"[Patch Preview] Data handling error: {e}"))
            self.update_status.emit(f"Data handling error: {str(e)}")
        except Exception as e:
            # Fallback for any unexpected errors, with traceback for debugging
            self.update_output.emit(log_message(f"[Patch Preview] Unexpected error: {e}"))
            self.update_output.emit(log_message(traceback.format_exc()))
            self.update_status.emit(f"Unexpected error: {str(e)}")

    def apply_patch_plan(self):
        """Applies the patch plan to the selected binary."""
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        # Check if we have patches from preview
        if hasattr(self, "potential_patches") and self.potential_patches:
            response = QMessageBox.question(
                self,
                "Apply Patches",
                f"Apply {len(self.potential_patches)} patches from preview?\n\nThis will create a new patched file.",
                QMessageBox.Yes | QMessageBox.No
            )

            if response == QMessageBox.Yes:
                self.update_output.emit(log_message(
                    f"[Apply Patch] Applying {len(self.potential_patches)} patches..."))
                apply_parsed_patch_instructions_with_validation(
                    self, self.potential_patches)
                return

        # If no patches from preview, run the license function rewriter
        self.update_output.emit(log_message(
            "[Apply Patch] No existing patch plan. Running license function rewriter..."))
        rewrite_license_functions_with_parsing(self)

    def start_guided_wizard(self):
        """Start the guided workflow wizard for new users."""
        wizard = GuidedWorkflowWizard(parent=self)
        wizard.exec_()

    def open_similarity_search(self):
        """Opens the binary similarity search dialog."""
        if not self.binary_path:
            QMessageBox.warning(
                self, "No Binary", "Please select a binary file first.")
            return

        # Open the binary similarity search dialog
        search_dialog = BinarySimilaritySearchDialog(self.binary_path, parent=self)
        search_dialog.exec_()

    def apply_cracking_pattern(self, source_binary, target_binary):
        """
        Apply cracking pattern from source binary to target binary.

        Args:
            source_binary: Path to the source binary (with working cracks)
            target_binary: Path to the target binary (to apply cracks to)
        """
        self.update_output.emit(log_message(f"[Pattern] Analyzing patterns from {os.path.basename(source_binary)}"))

        # Extract patterns from source binary
        patterns = self.extract_patterns_from_binary(source_binary)

        if patterns:
            self.update_output.emit(log_message(f"[Pattern] Found {len(patterns)} patterns to apply"))

            # Convert to patch instructions format
            instructions = []
            for pattern in patterns:
                instructions.append({
                    "offset": pattern.get("offset", 0),
                    "original": pattern.get("original_bytes", ""),
                    "patched": pattern.get("patched_bytes", ""),
                    "description": pattern.get("description", "Extracted from similar binary")
                })

            # Store patterns for potential application
            self.potential_patches = instructions

            # Apply patches with validation
            apply_parsed_patch_instructions_with_validation(self, instructions)
        else:
            self.update_output.emit(log_message("[Pattern] No applicable patterns found"))
            QMessageBox.warning(self, "No Patterns", "No applicable patterns were found in the source binary.")

    def extract_patterns_from_binary(self, binary_path):
        """
        Extract cracking patterns from a binary file.

        Args:
            binary_path: Path to the binary file

        Returns:
            list: List of pattern dictionaries containing potential license check,
                 activation mechanisms, and protection patterns
        """
        self.update_output.emit(log_message("[Pattern] Starting binary analysis for pattern extraction..."))

        # Initialize patterns list
        patterns = []
        binary_format = "unknown"

        try:
            # Check file exists
            if not os.path.exists(binary_path):
                raise FileNotFoundError(f"Binary file not found: {binary_path}")

            # Determine binary format
            with open(binary_path, 'rb') as f:
                header = f.read(4)
                if header.startswith(b'MZ'):
                    binary_format = "PE"
                elif header.startswith(b'\x7fELF'):
                    binary_format = "ELF"
                elif header in [b'\xca\xfe\xba\xbe', b'\xce\xfa\xed\xfe']:
                    binary_format = "MACHO"

            self.update_output.emit(log_message(f"[Pattern] Detected format: {binary_format}"))

            # Process binary based on format
            if binary_format == "PE":
                patterns = self._extract_patterns_from_pe(binary_path)
            elif binary_format == "ELF":
                patterns = self._extract_patterns_from_elf(binary_path)
            elif binary_format == "MACHO":
                patterns = self._extract_patterns_from_macho(binary_path)
            else:
                self.update_output.emit(log_message("[Pattern] Warning: Unsupported binary format, using generic patterns"))
                patterns = self._generate_generic_patterns()

        except Exception as e:
            self.update_output.emit(log_message(f"[Pattern] Error during pattern extraction: {str(e)}"))
            self.update_output.emit(log_message(f"[Pattern] Traceback: {traceback.format_exc()}"))
            self.update_output.emit(log_message("[Pattern] Using generic patterns due to analysis error"))
            patterns = self._generate_generic_patterns()

        # Log patterns found
        self.update_output.emit(log_message(f"[Pattern] Extracted {len(patterns)} potential patterns"))

        # Sort patterns by offset for better organization
        patterns.sort(key=lambda x: x.get("offset", 0))

        return patterns

    def _extract_patterns_from_pe(self, binary_path):
        """Extract patterns from PE format binaries"""
        patterns = []

        try:
            # Load PE file
            pe = pefile.PE(binary_path)

            # Get binary sections for analysis
            for section in pe.sections:
                section_name = section.Name.decode('utf-8', errors='ignore').strip('\x00')
                section_data = section.get_data()

                # Skip small or empty sections
                if len(section_data) < 10:
                    continue

                self.update_output.emit(log_message(f"[Pattern] Analyzing section: {section_name} ({len(section_data)} bytes)"))

                # Analyze executable sections for code patterns
                if section.Characteristics & 0x20000000:  # IMAGE_SCN_MEM_EXECUTE
                    # Find license check patterns using regex

                    # Pattern 1: Conditional jumps with function calls (common license check pattern)
                    # Example: JZ/JNZ followed by CALL then TEST
                    matches = re.finditer(b'\x74[\x00-\xFF]{1,3}\xE8[\x00-\xFF]{4}[\x84-\x85]\xC0', section_data)
                    for match in matches:
                        offset = section.VirtualAddress + match.start()
                        orig_bytes = binascii.hexlify(section_data[match.start():match.start()+10]).decode('utf-8').upper()
                        # Create bypass pattern (NOP out the conditional jump)
                        patched_bytes = "90" * 2 + orig_bytes[2:]

                        patterns.append({
                            "offset": offset,
                            "original_bytes": orig_bytes,
                            "patched_bytes": patched_bytes,
                            "description": f"License validation check in {section_name}",
                            "type": "license_check",
                            "confidence": "medium"
                        })

                    # Pattern 2: Call followed by test and conditional jump (common in activation flows)
                    # Example: CALL -> TEST EAX,EAX -> JZ
                    matches = re.finditer(b'\xE8[\x00-\xFF]{4}[\x84-\x85]\xC0[\x74-\x75]', section_data)
                    for match in matches:
                        offset = section.VirtualAddress + match.start()
                        orig_bytes = binascii.hexlify(section_data[match.start():match.start()+10]).decode('utf-8').upper()
                        # Force success return by replacing the conditional jump with NOPs
                        patched_bytes = orig_bytes[:-2] + "9090"

                        patterns.append({
                            "offset": offset,
                            "original_bytes": orig_bytes,
                            "patched_bytes": patched_bytes,
                            "description": f"Function result check in {section_name}",
                            "type": "activation_check",
                            "confidence": "medium"
                        })

                    # Pattern 3: Look for time-related API call patterns (for expiration checks)
                    time_related_strings = [b'GetSystemTime', b'GetLocalTime', b'FileTimeToSystemTime',
                                         b'CompareFileTime', b'GetFileTime', b'time32', b'time64']

                    for time_string in time_related_strings:
                        for match in re.finditer(time_string, section_data):
                            # Find nearby conditional jumps (within 30 bytes)
                            vicinity_start = max(0, match.start() - 30)
                            vicinity_end = min(len(section_data), match.end() + 30)
                            vicinity_data = section_data[vicinity_start:vicinity_end]

                            # Look for conditional jumps in the vicinity
                            for jmp_pattern in [b'\x74', b'\x75', b'\x0F\x84', b'\x0F\x85', b'\x79', b'\x7B', b'\x7C', b'\x7D']:
                                for jmp_match in re.finditer(re.escape(jmp_pattern), vicinity_data):
                                    jmp_offset = section.VirtualAddress + vicinity_start + jmp_match.start()
                                    jmp_size = len(jmp_pattern)

                                    # Get enough bytes for reliable patching
                                    jmp_area = vicinity_data[jmp_match.start():jmp_match.start() + jmp_size + 4]
                                    jmp_bytes = binascii.hexlify(jmp_area).decode('utf-8').upper()

                                    # Create NOPs for the jump instruction
                                    patch_bytes = "90" * len(jmp_area)

                                    patterns.append({
                                        "offset": jmp_offset,
                                        "original_bytes": jmp_bytes,
                                        "patched_bytes": patch_bytes,
                                        "description": f"Time/Expiration check near {time_string.decode('utf-8', errors='ignore')}",
                                        "type": "expiration_check",
                                        "confidence": "high"
                                    })

            # Check for licensing-related imports
            if hasattr(pe, 'DIRECTORY_ENTRY_IMPORT'):
                for entry in pe.DIRECTORY_ENTRY_IMPORT:
                    if not hasattr(entry, 'dll'):
                        continue

                    dll_name = entry.dll.decode('utf-8', errors='ignore').lower()
                    license_related_dlls = ['crypt', 'ssl', 'license', 'verify', 'auth', 'activ']

                    # Check if this DLL is likely related to licensing
                    if any(name in dll_name for name in license_related_dlls):
                        self.update_output.emit(log_message(f"[Pattern] Found licensing-related DLL: {dll_name}"))

                        # Look for key functions related to licensing
                        license_funcs = ['valid', 'check', 'license', 'activ', 'auth', 'verify', 'decrypt']

                        for imp in entry.imports:
                            if not hasattr(imp, 'name') or not imp.name:
                                continue

                            func_name = imp.name.decode('utf-8', errors='ignore')

                            if any(name in func_name.lower() for name in license_funcs):
                                self.update_output.emit(log_message(f"[Pattern] Found licensing function: {func_name}"))

                                # Try to find calls to this function in code sections
                                for section in pe.sections:
                                    if not (section.Characteristics & 0x20000000):
                                        continue

                                    section_data = section.get_data()
                                    calls_found = 0

                                    # Look for E8 (CALL) instructions
                                    for i in range(len(section_data) - 5):
                                        if section_data[i] == 0xE8:  # CALL opcode
                                            # Calculate the target of this call
                                            call_target = section.VirtualAddress + i + 5
                                            call_target += int.from_bytes(section_data[i+1:i+5], byteorder='little', signed=True)

                                            # Check if this call targets our import
                                            if hasattr(imp, 'address') and abs(call_target - imp.address) < 16:
                                                calls_found += 1

                                                offset = section.VirtualAddress + i
                                                orig_bytes = binascii.hexlify(section_data[i:i+5]).decode('utf-8').upper()

                                                if "check" in func_name.lower() or "valid" in func_name.lower():
                                                    # For validation functions, make them always return success (1)
                                                    patched_bytes = "B001909090"  # mov al, 1; nop; nop; nop
                                                else:
                                                    # For other functions, just NOP out the call
                                                    patched_bytes = "90" * len(orig_bytes)

                                                patterns.append({
                                                    "offset": offset,
                                                    "original_bytes": orig_bytes,
                                                    "patched_bytes": patched_bytes,
                                                    "description": f"Call to {func_name} in {dll_name}",
                                                    "type": "api_license_check",
                                                    "confidence": "high",
                                                    "api_name": func_name
                                                })

                                # Only process first few calls to avoid excessive patterns
                                if calls_found > 0:
                                    self.update_output.emit(log_message(f"[Pattern] Found {calls_found} calls to {func_name}"))

            # If no patterns found so far, look for common API calls that could be used for licensing
            if not patterns:
                self.update_output.emit(log_message("[Pattern] No specific patterns found, analyzing API usage..."))

                # Common Windows API calls often used in license checks
                api_patterns = {
                    "CryptVerifySignature": b"CryptVerifySignature",
                    "CheckTokenMembership": b"CheckTokenMembership",
                    "GetVolumeInformation": b"GetVolumeInformation",
                    "RegQueryValueEx": b"RegQueryValueEx",
                    "GetAdaptersInfo": b"GetAdaptersInfo",
                    "GetModuleHandle": b"GetModuleHandle",
                }

                for api_name, api_pattern in api_patterns.items():
                    for section in pe.sections:
                        section_data = section.get_data()
                        for match in re.finditer(api_pattern, section_data):
                            self.update_output.emit(log_message(f"[Pattern] Found potential API usage: {api_name}"))

                            patterns.append({
                                "offset": section.VirtualAddress + match.start(),
                                "original_bytes": "",  # Can't determine without disassembly
                                "patched_bytes": "",
                                "description": f"Potential {api_name} usage for hardware/license checks",
                                "type": "api_reference",
                                "confidence": "low",
                                "requires_manual_analysis": True
                            })

                # Add entry point pattern for manual inspection
                try:
                    entry_point = pe.OPTIONAL_HEADER.AddressOfEntryPoint
                    for section in pe.sections:
                        if section.VirtualAddress <= entry_point < (section.VirtualAddress + section.Misc_VirtualSize):
                            section_data = section.get_data()
                            offset_in_section = entry_point - section.VirtualAddress

                            if offset_in_section < len(section_data) - 16:
                                entry_bytes = binascii.hexlify(section_data[offset_in_section:offset_in_section+16]).decode('utf-8').upper()

                                patterns.append({
                                    "offset": entry_point,
                                    "original_bytes": entry_bytes,
                                    "patched_bytes": entry_bytes,  # Same bytes initially
                                    "description": "Entry point (inspect for initialization checks)",
                                    "type": "entry_point",
                                    "confidence": "low",
                                    "requires_manual_analysis": True
                                })
                                break
                except Exception as e:
                    self.update_output.emit(log_message(f"[Pattern] Error analyzing entry point: {str(e)}"))

        except Exception as e:
            self.update_output.emit(log_message(f"[Pattern] Error in PE pattern extraction: {str(e)}"))

        return patterns

    def _extract_patterns_from_elf(self, binary_path):
        """Extract patterns from ELF format binaries"""
        # Basic pattern detection for ELF binaries
        patterns = []

        try:
            # Try to find common license check patterns in ELF binaries
            with open(binary_path, 'rb') as f:
                binary_data = f.read()

            # Look for common strings related to licensing
            license_strings = [b'license', b'activation', b'register', b'trial', b'expire',
                             b'hardware', b'hwid', b'serial', b'key']

            for pattern in license_strings:
                for match in re.finditer(pattern, binary_data, re.IGNORECASE):
                    # Create a pattern entry for each match
                    offset = match.start()
                    context_start = max(0, offset - 20)
                    context_end = min(len(binary_data), offset + len(pattern) + 20)
                    context_data = binary_data[context_start:context_end]

                    # Convert binary context to readable format for reporting
                    context_hex = binascii.hexlify(context_data).decode('utf-8').upper()
                    context_readable = context_data.decode('utf-8', errors='replace')

                    # Check if the pattern appears in a possible code region
                    is_code_region = any(opcode in context_data for opcode in [b'\x55', b'\x8B', b'\x89', b'\xE8', b'\xE9', b'\xFF'])

                    # Check if pattern is surrounded by string terminators or other strings
                    is_text_section = (b'\x00' in context_data and context_data.count(b'\x00') > 2)

                    # Determine confidence level based on context
                    confidence_level = "high" if is_code_region else "medium" if is_text_section else "low"

                    patterns.append({
                        "offset": offset,
                        "original_bytes": binascii.hexlify(pattern).decode('utf-8').upper(),
                        "patched_bytes": "",  # Can't determine without proper disassembly
                        "description": f"Reference to '{pattern.decode('utf-8', errors='ignore')}' (needs manual analysis)",
                        "type": "string_reference",
                        "confidence": confidence_level,
                        "requires_manual_analysis": True,
                        "context": {
                            "hex": context_hex[:30] + "..." if len(context_hex) > 30 else context_hex,
                            "text": context_readable[:30] + "..." if len(context_readable) > 30 else context_readable,
                            "is_code_region": is_code_region,
                            "is_text_section": is_text_section
                        }
                    })

                    # Log the finding
                    self.update_output.emit(log_message(
                        f"[Pattern Finder] Found '{pattern.decode('utf-8', errors='ignore')}' at offset 0x{offset:X} ({confidence_level} confidence)"
                    ))

        except Exception as e:
            self.update_output.emit(log_message(f"[Pattern] Error in ELF pattern extraction: {str(e)}"))

        return patterns or self._generate_generic_patterns()

    def _extract_patterns_from_macho(self, binary_path):
        """Extract patterns from Mach-O format binaries"""
        # Basic pattern detection for Mach-O binaries
        # Similar approach to ELF, with format-specific adjustments
        return self._generate_generic_patterns()

    def _generate_generic_patterns(self):
        """Generate generic patterns when specific analysis fails"""
        self.update_output.emit(log_message("[Pattern] Generating generic pattern suggestions"))

        # Create a list of common patterns that might be useful
        patterns = [
            {
                "offset": 0x1000,  # Common offset where code might start
                "original_bytes": "7405E80000000084C0",  # Common pattern: JZ CALL TEST AL,AL
                "patched_bytes": "7405E8000000009090",  # Replace with NOPs
                "description": "Generic license check pattern (conditional jump + function call)",
                "type": "license_check",
                "confidence": "low",
                "requires_manual_verification": True
            },
            {
                "offset": 0x2000,  # Another potential code offset
                "original_bytes": "E8????????85C07403",  # CALL, TEST EAX,EAX, JZ
                "patched_bytes": "E8????????85C09090",  # Replace conditional jump with NOPs
                "description": "Generic function result check pattern",
                "type": "result_check",
                "confidence": "low",
                "requires_manual_verification": True
            },
            {
                "offset": 0x3000,
                "original_bytes": "833D????????007405",  # CMP DWORD PTR [addr], 0; JZ
                "patched_bytes": "833D????????009090",  # Replace jump with NOPs
                "description": "Generic global flag check pattern",
                "type": "flag_check",
                "confidence": "low",
                "requires_manual_verification": True
            }
        ]

        return patterns

    def open_visual_patch_editor(self):
        """Opens the visual patch editor dialog."""
        if not self.binary_path:
            QMessageBox.warning(
                self, "No Binary", "Please select a binary file first.")
            return

        # Check if we have patches from preview
        if not hasattr(self, "potential_patches") or not self.potential_patches:
            response = QMessageBox.question(
                self,
                "No Patches",
                "No patches available. Would you like to run patch preview first?",
                QMessageBox.Yes | QMessageBox.No
            )
            if response == QMessageBox.Yes:
                self.preview_patch()
                # Wait for preview to complete before opening editor
                QTimer.singleShot(1000, self.open_visual_patch_editor)
                return
            else:
                return

        # Open the visual patch editor dialog
        editor = VisualPatchEditorDialog(self.binary_path, self.potential_patches, parent=self)
        if editor.exec_() == QDialog.Accepted:
            # Update patches if user accepted changes
            self.potential_patches = editor.patches
            self.update_output.emit(log_message(
                f"[Patch Editor] Updated patch plan with {len(self.potential_patches)} patches"))

    def run_full_autonomous_mode(self):
        """Runs the full autonomous mode with enhanced AI-driven patching."""
        if not self.binary_path:
            QMessageBox.warning(self, "No File Selected",
                                "Please select a program first.")
            return

        self.update_output.emit(log_message(
            "[Autonomous Mode] Starting full autonomous mode..."))
        self.analyze_status.setText("Running autonomous mode...")

        # Run in background thread
        threading.Thread(target=self._run_full_autonomous_mode_thread).start()

    def _run_full_autonomous_mode_thread(self):
        """Background thread for full autonomous mode."""
        # Create thread-local storage for UI updates to prevent race conditions
        ui_updates = []

        def queue_output_update(message):
            """
            Queue an output message for the UI to process.

            Args:
                message: The output message to display.
            """
            ui_updates.append(("output", message))

        def queue_status_update(status):
            """
            Queue a status update for the UI to process.

            Args:
                status: The status message to display.
            """
            ui_updates.append(("status", status))

        def queue_analysis_update(analysis):
            """
            Queue an analysis update for the UI to process.
