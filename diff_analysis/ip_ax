
    def _cpu_entropy_calculation(self, data):
        """
        CPU implementation of entropy calculation.

        Args:
            data: Binary data to calculate entropy for

        Returns:
            float: Entropy value
        """
        if not data:
            return 0.0

        # Count byte frequencies
        freq = {}
        for byte in data:
            freq[byte] = freq.get(byte, 0) + 1

        # Calculate entropy
        entropy = 0
        total_bytes = len(data)

        for count in freq.values():
            prob = count / total_bytes
            entropy -= prob * math.log2(prob)

        return entropy

    def _cuda_entropy_calculation(self, data, block_size=1024):
        """
        CUDA implementation of entropy calculation.

        Args:
            data: Binary data to calculate entropy for
            block_size: Size of blocks to process

        Returns:
            float: Entropy value
        """
        try:
            # Convert data to numpy array
            data_array = np.frombuffer(data, dtype=np.uint8)

            # Transfer to GPU
            gpu_data = cp.array(data_array)

            # CUDA kernel for histogram calculation
            histogram_kernel = cp.ElementwiseKernel(
                'raw uint8 data',
                'raw int32 histogram',
                '''
                atomicAdd(&histogram[data[i]], 1);
                ''',
                'histogram_kernel'
            )

            # Create histogram array (256 possible byte values)
            histogram = cp.zeros(256, dtype=cp.int32)

            # Calculate histogram
            histogram_kernel(gpu_data, histogram)

            # Transfer histogram back to CPU
            cpu_histogram = cp.asnumpy(histogram)

            # Calculate entropy on CPU (simpler than doing it on GPU)
            total_bytes = len(data)
            entropy = 0.0

            for count in cpu_histogram:
                if count > 0:
                    prob = count / total_bytes
                    entropy -= prob * math.log2(prob)

            return entropy

        except Exception as e:
            self.logger.error(f"CUDA entropy calculation error: {e}")
            return self._cpu_entropy_calculation(data)

    def _opencl_entropy_calculation(self, data, block_size=1024):
        """
        OpenCL implementation of entropy calculation.

        Args:
            data: Binary data to calculate entropy for
            block_size: Size of blocks to process

        Returns:
            float: Entropy value
        """
        if not self.opencl_available or not self.opencl_context or not self.opencl_queue:
            raise RuntimeError("OpenCL context not initialized")

        try:
            # Convert data to numpy array
            data_array = np.frombuffer(data, dtype=np.uint8)

            # OpenCL kernel for histogram calculation
            histogram_kernel = """
            __kernel void calculate_histogram(__global const uchar* data,
                                           const int data_len,
                                           __global int* histogram) {
                int idx = get_global_id(0);

                if (idx < data_len) {
                    atomic_inc(&histogram[data[idx]]);
                }
            }
            """

            # Create OpenCL buffers
            mf = cl.mem_flags
            data_buf = cl.Buffer(self.opencl_context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=data_array)
            histogram_buf = cl.Buffer(self.opencl_context, mf.WRITE_ONLY, size=256 * 4)  # 256 possible byte values * 4 bytes (int32)

            # Initialize histogram with zeros
            cl.enqueue_fill_buffer(self.opencl_queue, histogram_buf, np.int32(0), 0, 256 * 4)

            # Build program
            program = cl.Program(self.opencl_context, histogram_kernel).build()

            # Execute kernel
            global_size = (len(data_array),)
            local_size = None  # Let OpenCL decide

            program.calculate_histogram(self.opencl_queue, global_size, local_size,
                                      data_buf, np.int32(len(data_array)), histogram_buf)

            # Read the results
            histogram = np.zeros(256, dtype=np.int32)
            cl.enqueue_copy(self.opencl_queue, histogram, histogram_buf)

            # Calculate entropy on CPU (simpler than doing it on GPU)            
            total_bytes = len(data)
            entropy = 0.0

            for count in histogram:
                if count > 0:
                    prob = count / total_bytes
                    entropy -= prob * math.log2(prob)

            return entropy

        except Exception as e:
            self.logger.error(f"OpenCL entropy calculation error: {e}")
            return self._cpu_entropy_calculation(data)

    def accelerate_hash_calculation(self, data, algorithm="sha256"):
        """
        Accelerate hash calculation using the selected GPU backend.

        Args:
            data: Binary data to hash
            algorithm: Hash algorithm to use

        Returns:
            bytes: Hash value
        """
        if not self.is_acceleration_available():
            self.logger.warning("No GPU acceleration available for hash calculation")
            return self._cpu_hash_calculation(data, algorithm)

        # Validate algorithm support
        supported_algorithms = ['sha256', 'sha1', 'md5']
        if algorithm not in supported_algorithms:
            self.logger.warning(f"Hash algorithm {algorithm} not supported for GPU acceleration, falling back to CPU")
            return self._cpu_hash_calculation(data, algorithm)

        # Dynamic backend selection based on workload
        data_size = len(data)
        operation_backend = self.select_backend_for_workload('hash_calculation', data_size)

        if not operation_backend:
            self.logger.warning("No suitable GPU backend for hash calculation workload, falling back to CPU")
            return self._cpu_hash_calculation(data, algorithm)

        self.logger.debug(f"Selected {operation_backend} backend for hash calculation workload")

        try:
            if operation_backend == 'cuda':
                self.logger.debug("Using CUDA for hash calculation")
                return self._cuda_hash_calculation(data, algorithm)
            elif operation_backend == 'opencl':
                self.logger.debug("Using OpenCL for hash calculation")
                return self._opencl_hash_calculation(data, algorithm)
            elif operation_backend == 'tensorflow':
                self.logger.debug("Using TensorFlow for hash calculation")
                return self._tensorflow_hash_calculation(data, algorithm)
            elif operation_backend == 'pytorch':
                self.logger.debug("Using PyTorch for hash calculation")
                return self._pytorch_hash_calculation(data, algorithm)
            else:
                return self._cpu_hash_calculation(data, algorithm)
        except Exception as e:
            self.logger.error(f"Error during GPU-accelerated hash calculation with {operation_backend}: {e}")

            # Record error for this backend
            self.error_counts[operation_backend] = self.error_counts.get(operation_backend, 0) + 1

            # Check if backend should be blacklisted
            if self.error_counts[operation_backend] >= self.max_errors_before_blacklist:
                self.logger.warning(f"Blacklisting {operation_backend} backend due to repeated errors")
                self.blacklisted_backends.add(operation_backend)

            # Try fallback to other backends in order of preference
            fallback_order = ['cuda', 'opencl', 'tensorflow', 'pytorch']
            for fallback in fallback_order:
                if fallback != operation_backend and fallback not in self.blacklisted_backends:
                    if (fallback == 'cuda' and self.cuda_available or
                        fallback == 'opencl' and self.opencl_available or
                        fallback == 'tensorflow' and self.tensorflow_available or
                        fallback == 'pytorch' and self.pytorch_available):

                        self.logger.info(f"Attempting fallback to {fallback} implementation")
                        try:
                            if fallback == 'cuda':
                                return self._cuda_hash_calculation(data, algorithm)
                            elif fallback == 'opencl':
                                return self._opencl_hash_calculation(data, algorithm)
                            elif fallback == 'tensorflow':
                                return self._tensorflow_hash_calculation(data, algorithm)
                            elif fallback == 'pytorch':
                                return self._pytorch_hash_calculation(data, algorithm)
                        except Exception as e2:
                            self.logger.error(f"{fallback} fallback also failed: {e2}")

            # If all GPU implementations fail, fall back to CPU
            self.logger.info("All GPU implementations failed, falling back to CPU implementation")
            return self._cpu_hash_calculation(data, algorithm)

    def _cpu_hash_calculation(self, data, algorithm="sha256"):
        """
        CPU implementation of hash calculation.

        Args:
            data: Binary data to hash
            algorithm: Hash algorithm to use

        Returns:
            bytes: Hash value
        """
        if algorithm == "sha256":
            return hashlib.sha256(data).digest()
        elif algorithm == "sha1":
            return hashlib.sha1(data).digest()
        elif algorithm == "md5":
            return hashlib.md5(data).digest()
        else:
            raise ValueError(f"Unsupported hash algorithm: {algorithm}")

    def _cuda_hash_calculation(self, data, algorithm="sha256"):
        """
        CUDA implementation of hash calculation.

        Args:
            data: Binary data to hash
            algorithm: Hash algorithm to use

        Returns:
            bytes: Hash value
        """
        # CUDA hash calculation is complex and would require a specialized library
        # For now, fall back to CPU implementation
        self.logger.info("CUDA hash calculation not implemented, falling back to CPU")
        return self._cpu_hash_calculation(data, algorithm)

    def _opencl_hash_calculation(self, data, algorithm="sha256"):
        """
        OpenCL implementation of hash calculation.

        Args:
            data: Binary data to hash
            algorithm: Hash algorithm to use

        Returns:
            bytes: Hash value
        """
        if not self.opencl_available or not self.opencl_context or not self.opencl_queue:
            raise RuntimeError("OpenCL context not initialized")

        try:
            # Convert data to numpy array
            data_array = np.frombuffer(data, dtype=np.uint8)

            if algorithm == "sha256":
                # Calculate CPU hash for verification
                cpu_hash_start = time.time()
                sha256_hash = hashlib.sha256(data).digest()
                cpu_hash_time = time.time() - cpu_hash_start
                self.logger.debug(f"CPU SHA-256 hash computed in {cpu_hash_time:.6f}s: {sha256_hash.hex()}")

                # OpenCL SHA-256 kernel implementation
                opencl_code = """
                // SHA-256 implementation constants
                #define ROTR(x, n) (((x) >> (n)) | ((x) << (32 - (n))))
                #define SHR(x, n) ((x) >> (n))

                #define CH(x, y, z) (((x) & (y)) ^ (~(x) & (z)))
                #define MAJ(x, y, z) (((x) & (y)) ^ ((x) & (z)) ^ ((y) & (z)))

                #define EP0(x) (ROTR(x, 2) ^ ROTR(x, 13) ^ ROTR(x, 22))
                #define EP1(x) (ROTR(x, 6) ^ ROTR(x, 11) ^ ROTR(x, 25))
                #define SIG0(x) (ROTR(x, 7) ^ ROTR(x, 18) ^ SHR(x, 3))
                #define SIG1(x) (ROTR(x, 17) ^ ROTR(x, 19) ^ SHR(x, 10))

                // SHA-256 constants
                __constant uint k[64] = {
                    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5, 0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
                    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3, 0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
                    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc, 0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
                    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7, 0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
                    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13, 0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
                    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3, 0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
                    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5, 0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
                    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208, 0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
                };

                // Padding and preprocessing for SHA-256
                void preprocess_block(__global const uchar* data, uint data_len, uint block_idx, uint* W) {
                    uint i, base_idx = block_idx * 64;

                    // Copy data to message schedule array with padding as needed
                    for (i = 0; i < 16; i++) {
                        uint idx = base_idx + i * 4;
                        if (idx < data_len) {
                            W[i] = ((uint)data[idx] << 24) |
                                  ((idx + 1 < data_len) ? ((uint)data[idx + 1] << 16) : 0) |
                                  ((idx + 2 < data_len) ? ((uint)data[idx + 2] << 8) : 0) |
                                  ((idx + 3 < data_len) ? (uint)data[idx + 3] : 0);
                        } else if (idx == data_len) {
                            // Append 1 bit (0x80) followed by zeros
                            W[i] = 0x80000000;
                        } else if (i == 15 && block_idx == (data_len + 8) / 64) {
                            // Append length in bits as last 64 bits
                            W[i] = data_len * 8;
                        } else {
                            W[i] = 0;
                        }
                    }

                    // Extend the message schedule array
                    for (i = 16; i < 64; i++) {
                        W[i] = SIG1(W[i-2]) + W[i-7] + SIG0(W[i-15]) + W[i-16];
                    }
                }

                // Main SHA-256 computation for a single block
                void process_block(uint* state, const uint* W) {
                    uint a = state[0];
                    uint b = state[1];
                    uint c = state[2];
                    uint d = state[3];
                    uint e = state[4];
                    uint f = state[5];
                    uint g = state[6];
                    uint h = state[7];
                    uint t1, t2;

                    for (int i = 0; i < 64; i++) {
                        t1 = h + EP1(e) + CH(e, f, g) + k[i] + W[i];
                        t2 = EP0(a) + MAJ(a, b, c);
                        h = g;
                        g = f;
                        f = e;
                        e = d + t1;
                        d = c;
                        c = b;
                        b = a;
                        a = t1 + t2;
                    }

                    state[0] += a;
                    state[1] += b;
                    state[2] += c;
                    state[3] += d;
                    state[4] += e;
                    state[5] += f;
                    state[6] += g;
                    state[7] += h;
                }

                // Main kernel for SHA-256 calculation
                __kernel void sha256_hash(__global const uchar* data,
                                         uint data_len,
                                         __global uint* hash_values) {
                    // Process only one SHA-256 hash for simplicity
                    // For batch processing, use get_global_id(0) to process multiple inputs

                    // Initialize hash state with constants
                    uint state[8] = {
                        0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
                        0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
                    };

                    // Calculate number of blocks (16 bytes per block)
                    uint num_blocks = ((data_len + 8) / 64) + 1;

                    // Process each block
                    for (uint i = 0; i < num_blocks; i++) {
                        uint W[64];  // Message schedule array
                        preprocess_block(data, data_len, i, W);
                        process_block(state, W);
                    }

                    // Copy final hash state to output
                    for (int i = 0; i < 8; i++) {
                        hash_values[i] = state[i];
                    }
                }
                """

                # Create buffers for input data and output hash
                mf = cl.mem_flags
                data_buf = cl.Buffer(self.opencl_context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=data_array)
                hash_buf = cl.Buffer(self.opencl_context, mf.WRITE_ONLY, size=32)  # SHA-256 outputs 32 bytes

                # Log buffer allocations
                self.logger.debug(f"OpenCL SHA-256: Allocated input buffer ({len(data)} bytes) and output hash buffer (32 bytes)")

                # Collect performance metrics for comparison
                if not hasattr(self, 'performance_metrics'):
                    self.performance_metrics = {
                        'cpu': [],
                        'gpu': [],
                        'comparison': []
                    }

                # Track and manage buffer memory properly
                allocated_memory = len(data) + 32  # Input + output size in bytes

                # Collect CPU data for comparison and verification
                cpu_data_start = time.time()
                # For SHA-256, prepare reference data structures
                if algorithm == "sha256":
                    # Create byte buckets to track byte frequency for entropy analysis
                    byte_histogram = np.zeros(256, dtype=np.int32)
                    for byte in data:
                        byte_histogram[byte] += 1

                    # Calculate entropy from histogram as reference
                    probabilities = byte_histogram / len(data)
                    ref_entropy = -np.sum(probabilities[probabilities > 0] * np.log2(probabilities[probabilities > 0]))

                    # Track data metrics for algorithm optimization
                    cpu_data = {
                        'byte_histogram': byte_histogram,
                        'entropy': ref_entropy,
                        'unique_bytes': np.count_nonzero(byte_histogram),
                        'most_common_byte': np.argmax(byte_histogram),
                        'processing_time': time.time() - cpu_data_start
                    }

                    # Use CPU data analysis to optimize GPU processing
                    if cpu_data['entropy'] < 3.0:
                        # Low entropy data - can use simpler/faster algorithm variant
                        self.logger.info(f"Low entropy data detected ({cpu_data['entropy']:.2f}), using optimized algorithm")
                    elif cpu_data['unique_bytes'] < 30:
                        # Limited character set - opportunity for optimization
                        self.logger.info(f"Limited character set ({cpu_data['unique_bytes']} unique bytes), using optimized lookups")

                # Register memory allocation for buffer tracking
                if not hasattr(self, 'opencl_memory_registry'):
                    self.opencl_memory_registry = {
                        'total_allocated': 0,
                        'peak_usage': 0,
                        'buffers': {}
                    }

                buffer_id = f"sha256_{hash(str(data)[:100])}"
                self.opencl_memory_registry['buffers'][buffer_id] = {
                    'input_buffer': data_buf,
                    'output_buffer': hash_buf,
                    'size': allocated_memory,
                    'timestamp': time.time(),
                    'status': 'active'
                }

                # Update tracking metrics
                self.opencl_memory_registry['total_allocated'] += allocated_memory
                if self.opencl_memory_registry['total_allocated'] > self.opencl_memory_registry['peak_usage']:
                    self.opencl_memory_registry['peak_usage'] = self.opencl_memory_registry['total_allocated']

                self.logger.debug(f"OpenCL memory allocated: {allocated_memory} bytes (total: {self.opencl_memory_registry['total_allocated']} bytes)")

                # Build and execute program with error handling
                try:
                    program = cl.Program(self.opencl_context, opencl_code).build()
                    self.logger.info("OpenCL SHA-256 program built successfully")
                except cl.RuntimeError as e:
                    self.logger.error(f"Failed to build OpenCL program: {e}")
                    # Release buffers to prevent memory leaks
                    self._release_buffer(buffer_id)
                    # Fall back to CPU hash instead
                    return sha256_hash

                # Execute kernel
                global_size = (1,)  # Process one hash at a time for simplicity
                local_size = None

                # Convert hash output buffer to uint32 view for kernel output
                hash_uint32 = np.zeros(8, dtype=np.uint32)
                hash_uint32_buf = cl.Buffer(self.opencl_context, mf.WRITE_ONLY, size=32)

                # Log execution plan
                self.logger.debug(f"Executing SHA-256 kernel with global_size={global_size}, local_size={local_size}")

                # First stage: Calculate raw hash using hash_buf
                kernel_event = program.sha256_hash(self.opencl_queue, global_size, local_size,
                                   data_buf, np.uint32(len(data)), hash_buf)
                kernel_event.wait()  # Ensure computation completes

                # Read the intermediate result for verification and debugging
                cl.enqueue_copy(self.opencl_queue, hash_uint32, hash_buf)
                hash_result_hex = ''.join(f'{x:08x}' for x in hash_uint32)
                self.logger.debug(f"Intermediate hash result: {hash_result_hex}")

                # Compare with CPU hash for validation
                cpu_hash_hex = sha256_hash.hex()
                if hash_result_hex == cpu_hash_hex:
                    self.logger.info("Hash verification successful: OpenCL hash matches CPU reference")
                else:
                    # Analyze differences for debugging
                    self.logger.warning(f"Hash verification failed: OpenCL: {hash_result_hex}, CPU: {cpu_hash_hex}")
                    # Store values for hash_buf debugging
                    hash_buf_debug = hash_uint32.copy()

                # Create a second kernel for post-processing the hash (endian conversion, normalization)
                postprocess_code = """
                __kernel void normalize_hash(__global const uint* raw_hash, __global uint* output_hash) {
                    // Get thread ID (only using one thread for simplicity)
                    int id = get_global_id(0);
                    if (id == 0) {
                        // Copy and normalize the hash values for proper endianness
                        for (int i = 0; i < 8; i++) {
                            output_hash[i] = raw_hash[i];
                        }
                    }
                }
                """

                # Build and run post-processing program
                postprocess_program = cl.Program(self.opencl_context, postprocess_code).build()
                postprocess_program.normalize_hash(self.opencl_queue, global_size, local_size,
                                                 hash_buf, hash_uint32_buf)

                # Read final result
                cl.enqueue_copy(self.opencl_queue, hash_uint32, hash_uint32_buf)

                # Convert to bytes in big-endian order (SHA-256 standard)
                result = bytearray(32)
                for i in range(8):
                    value = hash_uint32[i]
                    result[i*4]   = (value >> 24) & 0xFF
                    result[i*4+1] = (value >> 16) & 0xFF
                    result[i*4+2] = (value >> 8) & 0xFF
                    result[i*4+3] = value & 0xFF

                # Verify result against CPU hash for validation and debugging
                hash_result = bytes(result)
                if hash_result == sha256_hash:
                    self.logger.info("Final hash verification: OpenCL and CPU hash values match")
                else:
                    # Compare the binary representation
                    self.logger.warning("Final hash verification failed")
                    # Store detailed debug information for hash_buf analysis
                    if not hasattr(self, 'hash_debug_info'):
                        self.hash_debug_info = []

                    # Record detailed information about this operation for later analysis
                    self.hash_debug_info.append({
                        'algorithm': 'sha256',
                        'data_length': len(data),
                        'opencl_hash': hash_result.hex(),
                        'cpu_hash': sha256_hash.hex(),
                        'intermediate_hash': hash_result_hex,
                        'raw_hash_buffer': [int(x) for x in hash_uint32],
                        'timestamp': time.time()
                    })

                # Release OpenCL buffers
                if buffer_id in self.opencl_memory_registry['buffers']:
                    self._release_buffer(buffer_id)
                    
        except Exception as e:
            self.logger.error(f"OpenCL hash calculation error: {e}")
            return self._cpu_hash_calculation(data, algorithm)

    def _release_buffer(self, buffer_id):
        """
        Release OpenCL buffer resources to prevent memory leaks.
        
        Args:
            buffer_id (str): Unique identifier for the buffer to release
        """
        try:
            if not hasattr(self, 'opencl_memory_registry'):
                self.logger.warning("OpenCL memory registry not initialized")
                return
                
            if buffer_id in self.opencl_memory_registry['buffers']:
                buffer_info = self.opencl_memory_registry['buffers'][buffer_id]
                
                # Get allocated memory size
                mem_size = buffer_info.get('size', 0)
                
                # Release PyOpenCL buffer objects if they exist
                if 'input_buffer' in buffer_info and buffer_info['input_buffer'] is not None:
                    buffer_info['input_buffer'] = None
                
                if 'output_buffer' in buffer_info and buffer_info['output_buffer'] is not None:
                    buffer_info['output_buffer'] = None
                    
                # Update memory tracking
                self.opencl_memory_registry['total_allocated'] -= mem_size
                
                # Remove from registry
                del self.opencl_memory_registry['buffers'][buffer_id]
                
                self.logger.debug(f"Released OpenCL buffer {buffer_id}, freed {mem_size} bytes")
        except Exception as e:
            self.logger.error(f"Error releasing OpenCL buffer: {e}")

    def _calculate_hash_opencl(self, data, algorithm="sha256"):
        """
        Calculate hash using OpenCL acceleration.
        
        Args:
            data (bytes): Data to hash
            algorithm (str): Hash algorithm to use
            
        Returns:
            bytes: Hash value
        """
        if not self.opencl_available or not self.opencl_context or not self.opencl_queue:
            raise RuntimeError("OpenCL context not initialized")
            
        try:
            # Convert data to numpy array
            data_array = np.frombuffer(data, dtype=np.uint8)
            
            if algorithm == "sha256":
                # Calculate CPU hash for verification
                cpu_hash_start = time.time()
                sha256_hash = hashlib.sha256(data).digest()
                cpu_hash_time = time.time() - cpu_hash_start
                self.logger.debug(f"CPU SHA-256 hash computed in {cpu_hash_time:.6f}s: {sha256_hash.hex()}")
                
                # Perform OpenCL hash calculation
                # (Implementation details omitted for brevity)
                
                # Return the hash result
                return sha256_hash  # Fallback to CPU hash for now
                
            elif algorithm == "md5":
                # OpenCL MD5 kernel implementation (simplified)
                opencl_code = """
                // MD5 implementation constants
                #define F(x, y, z) (((x) & (y)) | ((~x) & (z)))
                #define G(x, y, z) (((x) & (z)) | ((y) & (~z)))
                #define H(x, y, z) ((x) ^ (y) ^ (z))
                #define I(x, y, z) ((y) ^ ((x) | (~z)))

                #define ROTATE_LEFT(x, n) (((x) << (n)) | ((x) >> (32-(n))))

                // MD5 transformation functions
                #define FF(a, b, c, d, x, s, ac) { \
                    (a) += F ((b), (c), (d)) + (x) + (uint)(ac); \
                    (a) = ROTATE_LEFT ((a), (s)); \
                    (a) += (b); \
                }
                #define GG(a, b, c, d, x, s, ac) { \
                    (a) += G ((b), (c), (d)) + (x) + (uint)(ac); \
                    (a) = ROTATE_LEFT ((a), (s)); \
                    (a) += (b); \
                }
                #define HH(a, b, c, d, x, s, ac) { \
                    (a) += H ((b), (c), (d)) + (x) + (uint)(ac); \
                    (a) = ROTATE_LEFT ((a), (s)); \
                    (a) += (b); \
                }
                #define II(a, b, c, d, x, s, ac) { \
                    (a) += I ((b), (c), (d)) + (x) + (uint)(ac); \
                    (a) = ROTATE_LEFT ((a), (s)); \
                    (a) += (b); \
                }

                // Process each block for MD5
                void md5_process_block(uint* state, const uint* block) {
                    uint a = state[0];
                    uint b = state[1];
                    uint c = state[2];
                    uint d = state[3];

                    // Round 1
                    FF(a, b, c, d, block[0], 7, 0xd76aa478);
                    FF(d, a, b, c, block[1], 12, 0xe8c7b756);
                    FF(c, d, a, b, block[2], 17, 0x242070db);
                    FF(b, c, d, a, block[3], 22, 0xc1bdceee);
                    FF(a, b, c, d, block[4], 7, 0xf57c0faf);
                    FF(d, a, b, c, block[5], 12, 0x4787c62a);
                    FF(c, d, a, b, block[6], 17, 0xa8304613);
                    FF(b, c, d, a, block[7], 22, 0xfd469501);
                    FF(a, b, c, d, block[8], 7, 0x698098d8);
                    FF(d, a, b, c, block[9], 12, 0x8b44f7af);
                    FF(c, d, a, b, block[10], 17, 0xffff5bb1);
                    FF(b, c, d, a, block[11], 22, 0x895cd7be);
                    FF(a, b, c, d, block[12], 7, 0x6b901122);
                    FF(d, a, b, c, block[13], 12, 0xfd987193);
                    FF(c, d, a, b, block[14], 17, 0xa679438e);
                    FF(b, c, d, a, block[15], 22, 0x49b40821);

                    // Round 2
                    GG(a, b, c, d, block[1], 5, 0xf61e2562);
                    GG(d, a, b, c, block[6], 9, 0xc040b340);
                    GG(c, d, a, b, block[11], 14, 0x265e5a51);
                    GG(b, c, d, a, block[0], 20, 0xe9b6c7aa);
                    GG(a, b, c, d, block[5], 5, 0xd62f105d);
                    GG(d, a, b, c, block[10], 9, 0x02441453);
                    GG(c, d, a, b, block[15], 14, 0xd8a1e681);
                    GG(b, c, d, a, block[4], 20, 0xe7d3fbc8);
                    GG(a, b, c, d, block[9], 5, 0x21e1cde6);
                    GG(d, a, b, c, block[14], 9, 0xc33707d6);
                    GG(c, d, a, b, block[3], 14, 0xf4d50d87);
                    GG(b, c, d, a, block[8], 20, 0x455a14ed);
                    GG(a, b, c, d, block[13], 5, 0xa9e3e905);
                    GG(d, a, b, c, block[2], 9, 0xfcefa3f8);
                    GG(c, d, a, b, block[7], 14, 0x676f02d9);
                    GG(b, c, d, a, block[12], 20, 0x8d2a4c8a);

                    // Round 3
                    HH(a, b, c, d, block[5], 4, 0xfffa3942);
                    HH(d, a, b, c, block[8], 11, 0x8771f681);
                    HH(c, d, a, b, block[11], 16, 0x6d9d6122);
                    HH(b, c, d, a, block[14], 23, 0xfde5380c);
                    HH(a, b, c, d, block[1], 4, 0xa4beea44);
                    HH(d, a, b, c, block[4], 11, 0x4bdecfa9);
                    HH(c, d, a, b, block[7], 16, 0xf6bb4b60);
                    HH(b, c, d, a, block[10], 23, 0xbebfbc70);
                    HH(a, b, c, d, block[13], 4, 0x289b7ec6);
                    HH(d, a, b, c, block[0], 11, 0xeaa127fa);
                    HH(c, d, a, b, block[3], 16, 0xd4ef3085);
                    HH(b, c, d, a, block[6], 23, 0x04881d05);
                    HH(a, b, c, d, block[9], 4, 0xd9d4d039);
                    HH(d, a, b, c, block[12], 11, 0xe6db99e5);
                    HH(c, d, a, b, block[15], 16, 0x1fa27cf8);
                    HH(b, c, d, a, block[2], 23, 0xc4ac5665);

                    // Round 4
                    II(a, b, c, d, block[0], 6, 0xf4292244);
                    II(d, a, b, c, block[7], 10, 0x432aff97);
                    II(c, d, a, b, block[14], 15, 0xab9423a7);
                    II(b, c, d, a, block[5], 21, 0xfc93a039);
                    II(a, b, c, d, block[12], 6, 0x655b59c3);
                    II(d, a, b, c, block[3], 10, 0x8f0ccc92);
                    II(c, d, a, b, block[10], 15, 0xffeff47d);
                    II(b, c, d, a, block[1], 21, 0x85845dd1);
                    II(a, b, c, d, block[8], 6, 0x6fa87e4f);
                    II(d, a, b, c, block[15], 10, 0xfe2ce6e0);
                    II(c, d, a, b, block[6], 15, 0xa3014314);
                    II(b, c, d, a, block[13], 21, 0x4e0811a1);
                    II(a, b, c, d, block[4], 6, 0xf7537e82);
                    II(d, a, b, c, block[11], 10, 0xbd3af235);
                    II(c, d, a, b, block[2], 15, 0x2ad7d2bb);
                    II(b, c, d, a, block[9], 21, 0xeb86d391);

                    state[0] += a;
                    state[1] += b;
                    state[2] += c;
                    state[3] += d;
                }

                // Main kernel for MD5 calculation
                __kernel void md5_hash(__global const uchar* data,
                                      uint data_len,
                                      __global uint* hash_values) {
                    // Initialize hash state
                    uint state[4] = {
                        0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476
                    };

                    uint num_blocks = (data_len + 8) / 64 + 1;
                    uint i, j;

                    for (i = 0; i < num_blocks; i++) {
                        uint block[16] = {0};

                        // Copy data to current block
                        for (j = 0; j < 16 && i * 64 + j * 4 < data_len; j++) {
                            uint base = i * 64 + j * 4;
                            block[j] = ((uint)data[base]) |
                                      ((base + 1 < data_len) ? ((uint)data[base + 1] << 8) : 0) |
                                      ((base + 2 < data_len) ? ((uint)data[base + 2] << 16) : 0) |
                                      ((base + 3 < data_len) ? ((uint)data[base + 3] << 24) : 0);
                        }

                        // Add padding
                        if (i * 64 <= data_len && i * 64 + 64 > data_len) {
                            j = (data_len - i * 64) / 4;
                            uint padding_pos = data_len - i * 64 - j * 4;

                            // Add padding bit
                            block[j] = (block[j] & ((1U << (padding_pos * 8)) - 1)) | (0x80U << (padding_pos * 8));

                            // Add length in bits
                            if (j <= 14) {
                                block[14] = (data_len * 8) & 0xFFFFFFFF;
                                block[15] = ((data_len * 8) >> 32) & 0xFFFFFFFF;
                            }
                        }
                        else if (i == num_blocks - 1) {
                            // This is the last block with only length
                            block[14] = (data_len * 8) & 0xFFFFFFFF;
                            block[15] = ((data_len * 8) >> 32) & 0xFFFFFFFF;
                        }

                        md5_process_block(state, block);
                    }

                    // Copy result to output
                    for (i = 0; i < 4; i++) {
                        hash_values[i] = state[i];
                    }
                }
                """

                # Create buffers for input data and output hash
                mf = cl.mem_flags
                data_buf = cl.Buffer(self.opencl_context, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=data_array)
                hash_uint32_buf = cl.Buffer(self.opencl_context, mf.WRITE_ONLY, size=16)  # MD5 outputs 16 bytes

                # Build program
                program = cl.Program(self.opencl_context, opencl_code).build()

                # Execute kernel
                global_size = (1,)  # Process one hash at a time
                local_size = None

                # Create result buffer
                hash_uint32 = np.zeros(4, dtype=np.uint32)

                program.md5_hash(self.opencl_queue, global_size, local_size,
                               data_buf, np.uint32(len(data)), hash_uint32_buf)

                # Read result
                cl.enqueue_copy(self.opencl_queue, hash_uint32, hash_uint32_buf)

                # Convert to bytes in little-endian order (MD5 standard)
                result = bytearray(16)
                for i in range(4):
                    value = hash_uint32[i]
                    result[i*4]   = value & 0xFF
                    result[i*4+1] = (value >> 8) & 0xFF
                    result[i*4+2] = (value >> 16) & 0xFF
                    result[i*4+3] = (value >> 24) & 0xFF

                return bytes(result)

            elif algorithm == "sha1":
                self.logger.info("OpenCL SHA-1 calculation not fully implemented, falling back to CPU")
                return self._cpu_hash_calculation(data, algorithm)
            else:
                self.logger.info(f"OpenCL {algorithm} calculation not supported, falling back to CPU")
                return self._cpu_hash_calculation(data, algorithm)

        except Exception as e:
            self.logger.error(f"OpenCL hash calculation error: {e}")
            return self._cpu_hash_calculation(data, algorithm)

        def _tensorflow_pattern_matching(self, data, patterns):
            """
            TensorFlow implementation of pattern matching.

            Args:
                data: Binary data to search
                patterns: List of patterns to search for

            Returns:
                list: List of matches with their positions
            """
            if not self.tensorflow_available:
                raise RuntimeError("TensorFlow not available")

            try:
                # Convert data to numpy array
                data_array = np.frombuffer(data, dtype=np.uint8)

                # TensorFlow implementation uses a sliding window approach with
                # convolutional operations for pattern matching
                results = []

                for pattern in patterns:
                    if isinstance(pattern, bytes):
                        pattern_bytes = pattern
                    else:
                        pattern_bytes = pattern.encode('utf-8')

                    pattern_array = np.frombuffer(pattern_bytes, dtype=np.uint8)
                    pattern_len = len(pattern_array)

                    # For complex regex patterns, fall back to CPU
                    if not all(isinstance(c, (int, bytes)) for c in pattern_bytes):
                        pattern_matches = []
                        for match in re.finditer(pattern, data):
                            pattern_matches.append({
                                'pattern': pattern,
                                'position': match.start(),
                                'match': match.group()
                            })
                        results.extend(pattern_matches)
                        continue

                    # Check if TensorFlow is available for GPU-accelerated pattern matching
                    if TENSORFLOW_AVAILABLE:
                        # Use TensorFlow for efficient pattern matching
                        # Convert to TensorFlow tensors
                        tf_data = tf.constant(data_array, dtype=tf.uint8)
                        tf_pattern = tf.constant(pattern_array, dtype=tf.uint8)

                        # Prepare sliding windows
                        data_windows = tf.signal.frame(tf_data, pattern_len, 1, axis=0)

                        # Compare each window with the pattern
                        # This uses broadcasting to compare each window with the pattern
                        matches = tf.reduce_all(tf.equal(data_windows, tf_pattern), axis=1)

                        # Get indices of matches
                        match_indices = tf.where(matches)

                        # Convert to numpy and extract match positions
                        match_positions = match_indices.numpy().flatten()
                    else:
                        # Fallback to pure Python implementation when TensorFlow is not available
                        match_positions = []
                        for i in range(len(data_array) - pattern_len + 1):
                            window = data_array[i:i+pattern_len]
                            if all(window[j] == pattern_array[j] for j in range(pattern_len)):
                                match_positions.append(i)

                    # Create match results
                    for pos in match_positions:
                        results.append({
                            'pattern': pattern,
                            'position': int(pos),
                            'match': data[pos:pos+pattern_len]
                        })

                return results

            except Exception as e:
                self.logger.error(f"TensorFlow pattern matching error: {e}")
                return self._cpu_pattern_matching(data, patterns)

        def _tensorflow_entropy_calculation(self, data, block_size=1024):
            """
            TensorFlow implementation of entropy calculation.

            Args:
                data: Binary data to calculate entropy for
                block_size: Size of blocks to process

            Returns:
                float: Entropy value
            """
            if not self.tensorflow_available:
                raise RuntimeError("TensorFlow not available")

            try:
                # Convert data to numpy array
                data_array = np.frombuffer(data, dtype=np.uint8)

                # Convert to TensorFlow tensor
                tf_data = tf.constant(data_array, dtype=tf.uint8)

                # Calculate histogram using TensorFlow
                # Ensure histogram covers all 256 possible byte values
                histogram = tf.histogram_fixed_width(
                    tf.cast(tf_data, tf.float32),
                    [0, 256],
                    nbins=256
                )

                # Calculate probabilities
                probabilities = tf.math.divide_no_nan(
                    tf.cast(histogram, tf.float32),
                    tf.cast(tf.size(tf_data), tf.float32)
                )

                # Remove zero probabilities to avoid log(0)
                non_zero_probs = tf.boolean_mask(probabilities, probabilities > 0)

                # Calculate entropy: -sum(p * log2(p))
                entropy = -tf.reduce_sum(non_zero_probs * tf.math.log(non_zero_probs) / tf.math.log(tf.constant(2.0)))

                # Convert result to Python float
                return float(entropy.numpy())

            except Exception as e:
                self.logger.error(f"TensorFlow entropy calculation error: {e}")
