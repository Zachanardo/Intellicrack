            try:
                pe = pefile.PE(binary_path)

                section_hashes = {}
                for section in pe.sections:
                    section_name = section.Name.decode('utf-8', 'ignore').strip('\x00')
                    section_data = section.get_data()
                    section_hash = hashlib.sha256(section_data).hexdigest()
                    section_hashes[section_name] = section_hash

                return section_hashes
            except Exception as e:
                self.logger.error(f"Error computing section hashes: {e}")
                return {}

        def get_cached_analysis(self, binary_path, analysis_type):
            """
            Get cached analysis results if available.

            Args:
                binary_path: Path to the binary file
                analysis_type: Type of analysis (e.g., "vulnerability", "license")

            Returns:
                dict: Cached analysis results, or None if not available
            """
            binary_hash = self.compute_binary_hash(binary_path)
            if not binary_hash:
                return None

            # Check if we have cached results for this binary
            if binary_hash in self.cache_index:
                cache_entry = self.cache_index[binary_hash]

                # Check if we have cached results for this analysis type
                if analysis_type in cache_entry:
                    cache_file = cache_entry[analysis_type]

                    # Load cached results
                    try:
                        with open(os.path.join(self.cache_dir, cache_file), "r", encoding="utf-8") as f:
                            cached_results = json.load(f)

                        self.logger.info(f"Using cached {analysis_type} analysis for {binary_path}")
                        return cached_results
                    except Exception as e:
                        self.logger.error(f"Error loading cached results: {e}")

            return None

        def cache_analysis_results(self, binary_path, analysis_type, results):
            """
            Cache analysis results for future use.

            Args:
                binary_path: Path to the binary file
                analysis_type: Type of analysis (e.g., "vulnerability", "license")
                results: Analysis results to cache

            Returns:
                bool: True if caching was successful, False otherwise
            """
            binary_hash = self.compute_binary_hash(binary_path)
            if not binary_hash:
                return False

            # Create cache entry for this binary if it doesn't exist
            if binary_hash not in self.cache_index:
                self.cache_index[binary_hash] = {}

            # Generate cache file name
            cache_file = f"{binary_hash}_{analysis_type}.json"

            # Save results to cache file
            try:
                with open(os.path.join(self.cache_dir, cache_file), "w", encoding="utf-8") as f:
                    json.dump(results, f, indent=2)

                # Update cache index
                self.cache_index[binary_hash][analysis_type] = cache_file
                self._save_cache_index()

                self.logger.info(f"Cached {analysis_type} analysis for {binary_path}")
                return True
            except Exception as e:
                self.logger.error(f"Error caching analysis results: {e}")
                return False

        def identify_changed_sections(self, binary_path, previous_binary_path):
            """
            Identify which sections have changed between two versions of a binary.

            Args:
                binary_path: Path to the current binary file
                previous_binary_path: Path to the previous binary file

            Returns:
                list: Names of sections that have changed
            """
            current_section_hashes = self.compute_section_hashes(binary_path)
            previous_section_hashes = self.compute_section_hashes(previous_binary_path)

            changed_sections = []

            # Check for sections that have changed
            for section_name, current_hash in current_section_hashes.items():
                if section_name in previous_section_hashes:
                    if current_hash != previous_section_hashes[section_name]:
                        changed_sections.append(section_name)
                else:
                    # New section
                    changed_sections.append(section_name)

            return changed_sections

        def run_incremental_analysis(self, binary_path, analysis_func, analysis_type, force_full=False):
            """
            Run analysis incrementally, reusing cached results for unchanged sections.

            Args:
                binary_path: Path to the binary file
                analysis_func: Function to perform the analysis
                analysis_type: Type of analysis (e.g., "vulnerability", "license")
                force_full: Force full analysis even if cached results are available

            Returns:
                dict: Analysis results
            """
            if force_full:
                self.logger.info(f"Forcing full {analysis_type} analysis for {binary_path}")
                results = analysis_func(binary_path)
                self.cache_analysis_results(binary_path, analysis_type, results)
                return results

            # Check for cached results
            cached_results = self.get_cached_analysis(binary_path, analysis_type)
            if cached_results:
                return cached_results

            # No cached results, run full analysis
            self.logger.info(f"Running full {analysis_type} analysis for {binary_path}")
            results = analysis_func(binary_path)
            self.cache_analysis_results(binary_path, analysis_type, results)
            return results

    # This function is used as a callback by UI buttons and menu items
    def run_incremental_analysis_ui(app):
        """
        Run incremental analysis on the selected binary via the UI.
        This is the callback version connected to UI elements.

        Args:
            app: Application instance
        """
        # Configuration settings for UI-based incremental analysis
        run_incremental_analysis_ui = {
            "mode": "ui_trigger",
            "analysis_depth": app.config.get("incremental_analysis_depth", "medium"),
            "timeout": app.config.get("analysis_timeout_seconds", 120),
            "ui_updates": True,
            "memory_optimized": app.config.get("use_memory_optimization", True),
            "show_progress": True,
            "analysis_options": app.get_active_analysis_options() if hasattr(app, "get_active_analysis_options") else {}
        }

        # Register in usage tracking system
        if hasattr(app, 'usage_tracker'):
            app.usage_tracker.track_feature_usage('incremental_analysis', run_incremental_analysis_ui)

        if not app.binary_path:
            app.update_output.emit(log_message("[Incremental] No binary selected."))
            return

        # Log the analysis configuration
        app.logger.debug(f"Starting UI incremental analysis with settings: {run_incremental_analysis_ui}")

        app.update_output.emit(log_message("[Incremental] Starting incremental analysis..."))

        # Create incremental analysis manager
        incremental_manager = IncrementalAnalysisManager()

        # Ask for analysis type
        analysis_types = ["Vulnerability", "License", "Protection"]
        analysis_type, ok = QInputDialog.getItem(app, "Analysis Type", "Select analysis type:", analysis_types, 0, False)
        if not ok:
            app.update_output.emit(log_message("[Incremental] Cancelled"))
            return

        # Ask if force full analysis
        force_full = QMessageBox.question(
            app,
            "Force Full Analysis",
            "Force full analysis (ignore cache)?",
            QMessageBox.Yes | QMessageBox.No
        ) == QMessageBox.Yes

        # Define analysis functions
        analysis_functions = {
            "Vulnerability": lambda binary: AdvancedVulnerabilityEngine.scan_binary(binary),
            "License": lambda binary: enhanced_deep_license_analysis(binary),
            "Protection": lambda binary: detect_commercial_protections(binary)
        }

        if analysis_type not in analysis_functions:
            app.update_output.emit(log_message(f"[Incremental] Unsupported analysis type: {analysis_type}"))
            return

        # Run incremental analysis
        app.update_output.emit(log_message(f"[Incremental] Running {analysis_type.lower()} analysis..."))

        start_time = time.time()
        results = incremental_manager.run_incremental_analysis(
            app.binary_path,
            analysis_functions[analysis_type],
            analysis_type.lower(),
            force_full
        )
        end_time = time.time()

        # Display results
        app.update_output.emit(log_message(f"[Incremental] Analysis completed in {end_time - start_time:.2f} seconds"))

        # Process results based on analysis type
        if analysis_type == "Vulnerability":
            app.update_output.emit(log_message(f"[Incremental] Found {len(results)} vulnerabilities"))

            # Add to analyze results
            if not hasattr(app, "analyze_results"):
                app.analyze_results = []

            app.analyze_results.append("\n=== INCREMENTAL VULNERABILITY ANALYSIS RESULTS ===")
            app.analyze_results.append(f"Analysis time: {end_time - start_time:.2f} seconds")
            app.analyze_results.append(f"Vulnerabilities found: {len(results)}")

            if results:
                app.analyze_results.append("\nTop vulnerabilities:")
                for i, vuln in enumerate(results[:5]):  # Show up to 5 vulnerabilities
                    app.analyze_results.append(f"\nVulnerability {i+1}:")
                    app.analyze_results.append(f"  Type: {vuln.get('type', 'Unknown')}")
                    app.analyze_results.append(f"  Risk: {vuln.get('risk', 'Unknown')}")
                    if 'function' in vuln:
                        app.analyze_results.append(f"  Function: {vuln['function']}")
                    if 'address' in vuln:
                        app.analyze_results.append(f"  Address: {vuln['address']}")

        elif analysis_type == "License":
            app.update_output.emit(log_message("[Incremental] License analysis completed"))

            # Add to analyze results
            if not hasattr(app, "analyze_results"):
                app.analyze_results = []

            app.analyze_results.append("\n=== INCREMENTAL LICENSE ANALYSIS RESULTS ===")
            app.analyze_results.append(f"Analysis time: {end_time - start_time:.2f} seconds")

            for line in results:
                app.analyze_results.append(line)

        elif analysis_type == "Protection":
            app.update_output.emit(log_message("[Incremental] Protection analysis completed"))

            # Add to analyze results
            if not hasattr(app, "analyze_results"):
                app.analyze_results = []

            app.analyze_results.append("\n=== INCREMENTAL PROTECTION ANALYSIS RESULTS ===")
            app.analyze_results.append(f"Analysis time: {end_time - start_time:.2f} seconds")

            for line in results:
                app.analyze_results.append(line)

    # -------------------------------
    # Visual Network Traffic Analyzer
    # -------------------------------

class NetworkTrafficAnalyzer:
    """
    Visual network traffic analyzer for license communications.

    This system captures, analyzes, and visualizes network traffic related to
    license verification, providing insights into license check mechanisms.
    """

    def __init__(self, config=None):
        """
        Initialize the network traffic analyzer.

        Args:
            config: Configuration dictionary (optional)
        """
        self.logger = logging.getLogger(__name__)

        # Default configuration
        self.config = {
            'capture_file': 'license_traffic.pcap',
            'max_packets': 10000,
            'filter': 'tcp',
            'visualization_dir': 'visualizations',
            'auto_analyze': True
        }

        # Update with provided configuration
        if config:
            self.config.update(config)

        # Initialize components
        self.packets = []
        self.connections = {}
        self.license_servers = set()
        self.license_patterns = [
            b'license', b'activation', b'auth', b'key', b'valid',
            b'FEATURE', b'INCREMENT', b'VENDOR', b'SERVER',
            b'HASP', b'Sentinel', b'FLEXLM', b'LCSAP'
        ]

        # Create visualization directory
        os.makedirs(self.config['visualization_dir'], exist_ok=True)

    def start_capture(self, interface=None):
        """
        Start capturing network traffic.

        Args:
            interface: Network interface to capture on (optional)

        Returns:
            bool: True if capture started successfully, False otherwise
        """
        try:
            # Define capture thread function
            def capture_thread():
                """
                Thread function for packet capture operations.

                This function executes the packet capture operation in a separate thread,
                allowing the network monitoring to run concurrently with the main application.
                It calls the internal _capture_packets method with the specified interface
                and provides exception handling to prevent thread crashes.

                Args:
                    None: Uses the interface parameter from the parent function scope

                Returns:
                    None

                Raises:
                    No exceptions are propagated as they are caught and logged internally
                """
                try:
                    self._capture_packets(interface)
                except Exception as e:
                    self.logger.error(f"Error in capture thread: {e}")

            # Start capture in a separate thread
            thread = threading.Thread(target=capture_thread)
            thread.daemon = True
            thread.start()

            self.logger.info(f"Started packet capture on {interface or 'default interface'}")
            return True

        except Exception as e:
            self.logger.error(f"Error starting capture: {e}")
            self.logger.error(traceback.format_exc())
            return False

    def _capture_packets(self, interface=None):
        """
        Capture packets using available libraries.

        Args:
            interface: Network interface to capture on (optional)
        """
        # Try different packet capture libraries
        # Use the detected library based on PACKET_CAPTURE_LIB global variable
        try:
            if PACKET_CAPTURE_LIB == "scapy":
                self._capture_with_scapy(interface)
                return
            elif PACKET_CAPTURE_LIB == "pyshark":
                self._capture_with_pyshark(interface)
                return
            elif PACKET_CAPTURE_LIB == "socket":
                self._capture_with_socket(interface)
                return
            else:
                self.logger.error("No packet capture library available")
        except Exception as e:
            self.logger.error(f"Packet capture failed: {str(e)}")

    def _capture_with_socket(self, interface=None, capture_filter=None, output_file=None, packet_count=None, timeout=None):
        """
        Capture packets using Python's native socket library.
        This is a fallback method when specialized packet capture libraries are not available.

        Args:
            interface: Network interface to capture on (optional)
            capture_filter: Display filter (partially supported - only basic filtering possible)
            output_file: Path to save the capture (optional)
            packet_count: Maximum number of packets to capture (optional)
            timeout: Timeout in seconds (optional)
        """

        self.logger.info("Starting packet capture using native socket library")

        # Create a raw socket
        try:
            try:
                if os.name == "nt":  # Windows
                    # On Windows, socket.SOCK_RAW requires administrator privileges
                    s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
                    if interface:
                        # Try to bind to the specified interface
                        try:
                            s.bind((interface, 0))
                        except Exception as e:
                            self.logger.warning(f"Could not bind to interface {interface}, using default: {str(e)}")
                            # Get host name and attempt to bind to its IP
                            host = socket.gethostbyname(socket.gethostname())
                            s.bind((host, 0))
                    else:
                        # Get host name and bind to its IP
                        host = socket.gethostbyname(socket.gethostname())
                        s.bind((host, 0))

                    # Enable promiscuous mode
                    s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
                else:  # Linux, macOS, etc.
                    s = socket.socket(socket.AF_PACKET, socket.SOCK_RAW, socket.ntohs(0x0003))
                    if interface:
                        try:
                            s.bind((interface, 0))
                        except Exception as e:
                            self.logger.warning(f"Could not bind to interface {interface}: {str(e)}")
            except PermissionError:
                self.logger.error("Permission denied: Raw socket capture requires administrator/root privileges")
                raise
            except OSError as e:
                if "access" in str(e).lower() or "permission" in str(e).lower():
                    self.logger.error("Permission denied: Raw socket capture requires administrator/root privileges")
                raise

            # Set timeout if specified
            if timeout:
                s.settimeout(timeout)

            # Initialize capture statistics
            start_time = time.time()
            packets_captured = 0
            capture_stats = {
                'start_time': start_time,
                'packets_total': 0,
                'capture_time': 0
            }

            # Prepare output file if specified
            out_file = None
            if output_file:
                try:
                    out_file = open(output_file, 'wb')
                    # Write a simple header (not pcap format, just timestamped raw packets)
                    out_file.write(f"# Intellicrack socket capture started at {datetime.now()}\n".encode('utf-8'))
                except Exception as e:
                    self.logger.error(f"Failed to open output file: {str(e)}")
                    out_file = None

            # Capture loop
            try:
                while True:
                    # Break if we've captured enough packets
                    if packet_count and packets_captured >= packet_count:
                        break

                    # Check if overall timeout has elapsed before waiting for more packets
                    current_time = time.time()
                    if timeout and (current_time - start_time) > timeout:
                        self.logger.info(f"Capture timeout reached after {current_time - start_time:.2f} seconds")
                        break

                    # Wait for packets with timeout
                    ready, _, _ = select.select([s], [], [], 0.1)  # Short timeout for responsiveness

                    if not ready:
                        continue

                    # Receive packet
                    packet = s.recv(65535)
                    packets_captured += 1

                    # Apply very basic filtering if requested (exact string match only)
                    if capture_filter and capture_filter.encode() not in packet:
                        continue

                    # Write to output file if specified
                    if out_file:
                        timestamp = time.time()
                        # Write timestamp + packet size + packet data
                        header = struct.pack("!dI", timestamp, len(packet))
                        out_file.write(header)
                        out_file.write(packet)

                    # Display basic packet info (simplified)
                    if packets_captured % 10 == 0:  # Don't flood the logs
                        self.logger.info(f"Captured {packets_captured} packets")

                    # Process the packet (simplified)
                    self._process_captured_packet(packet)

            except KeyboardInterrupt:
                self.logger.info("Packet capture interrupted by user")
            except socket.timeout:
                self.logger.info("Packet capture timeout reached")
            except Exception as e:
                self.logger.error(f"Error during packet capture: {str(e)}")
            finally:
                # Clean up
                capture_stats['packets_total'] = packets_captured
                capture_stats['capture_time'] = time.time() - start_time

                if os.name == "nt":
                    # Disable promiscuous mode on Windows
                    try:
                        s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
                    except:
                        pass

                s.close()

                if out_file:
                    out_file.close()

                self.logger.info(f"Socket-based packet capture completed: {packets_captured} packets in {capture_stats['capture_time']:.2f} seconds")
            return capture_stats

        except Exception as e:
            self.logger.error(f"Failed to initialize socket for packet capture: {str(e)}")
            raise

    def _process_captured_packet(self, packet_data):
        """
        Simple packet processor for socket-captured packets
        """
        try:
            # Very basic packet processing - extract IP header info
            if len(packet_data) >= 20:  # Minimum IP header size
                # Ensure we're working with bytes for consistent handling
                if not isinstance(packet_data, (bytes, bytearray)):
                    self.logger.warning("Unexpected packet_data type, expected bytes or bytearray")
                    return

                # Extract version and header length
                version_ihl = packet_data[0]
                version = version_ihl >> 4
                ihl = (version_ihl & 0xF) * 4

                # Log and validate IP version
                if version != 4:
                    self.logger.warning(f"Unexpected IP version: {version}, expected IPv4")
                    return

                # Extract other IP header fields if needed
                if len(packet_data) >= 20:
                    # Protocol (TCP=6, UDP=17, ICMP=1, etc.)
                    protocol = packet_data[9]

                    # For license analysis, focus on common license server protocols
                    if protocol == 6:  # TCP
                        # Check for common license server ports
                        if len(packet_data) >= ihl + 4:  # Ensure we have TCP header
                            # Extract source and destination ports from TCP header using struct for proper byte handling
                            try:
                                src_port = (packet_data[ihl] << 8) | packet_data[ihl + 1]
                                dst_port = (packet_data[ihl + 2] << 8) | packet_data[ihl + 3]

                                # Common license server ports
                                license_ports = [1111, 1234, 2222, 27000, 27001, 8224, 8225]
                                if src_port in license_ports or dst_port in license_ports:
                                    self.logger.info(f"Potential license traffic detected: port {src_port}->{dst_port}")
                            except Exception as e:
                                self.logger.debug(f"Error extracting TCP ports: {str(e)}")
        except Exception as e:
            # Just log the error and continue
            self.logger.error(f"Error processing packet: {str(e)}")

    def _capture_with_pyshark(self, interface=None, capture_filter=None, output_file=None, packet_count=None, timeout=None):
        """
        Capture packets using pyshark with enhanced functionality for license traffic analysis.

        Args:
            interface: Network interface to capture on (optional)
            capture_filter: Custom display filter to override default license filter (optional)
            output_file: Path to save the capture in pcapng format (optional)
            packet_count: Maximum number of packets to capture before stopping (optional)
            timeout: Timeout in seconds after which to stop capturing (optional)
        """
        try:
            # Initialize capture statistics
            start_time = time.time()
            packets_captured = 0
            packets_analyzed = 0
            capture_stats = {
                'start_time': start_time,
                'packets_total': 0,
                'packets_analyzed': 0,
                'errors': 0
            }

            # Prepare capture options
            capture_options = {}
            if interface:
                capture_options['interface'] = interface
            if output_file:
                capture_options['output_file'] = output_file

            # Create capture object
            # Use either custom filter or the one from config
            display_filter = capture_filter if capture_filter else self.config['filter']

            # If no filter is specified, use comprehensive license-related traffic filter
            if not display_filter:
                display_filter = (
                    # FlexLM ports
                    'tcp.port == 27000-27009 or tcp.port == 2080 or tcp.port == 8224 or '
                    # HASP/Sentinel ports
                    'tcp.port == 1947 or tcp.port == 6001 or '
                    # CodeMeter ports
                    'tcp.port == 22350 or tcp.port == 22351 or '
                    # Common web license ports
                    'tcp.port == 80 or tcp.port == 443 or tcp.port == 8080 or '
                    # Known application license ports
                    'tcp.port == 1234 or tcp.port == 5093 or tcp.port == 49684 or '
                    # DNS lookups for license validation
                    'dns.qry.name contains "license" or dns.qry.name contains "activation" or '
                    # HTTP license-related requests
                    '(http and (http.request.uri contains "license" or http.request.uri contains "activation" or '
                    'http.request.uri contains "validate" or http.request.uri contains "auth"))'
                )

            capture_options['display_filter'] = display_filter
            capture = pyshark.LiveCapture(**capture_options)

            # Log capture start
            self.logger.info(f"Starting packet capture on {'all interfaces' if not interface else interface}")
            self.logger.info(f"Using filter: {display_filter}")

            # Define signal handler for graceful exit
            original_sigint_handler = signal.getsignal(signal.SIGINT)

            def signal_handler(sig, frame):
                """
                Handle SIGINT for graceful packet capture termination.

                Logs the interrupt and restores the original signal handler.
                """
                self.logger.info("Received interrupt signal, stopping capture...")
                signal.signal(signal.SIGINT, original_sigint_handler)

            signal.signal(signal.SIGINT, signal_handler)

            # Start capturing with appropriate method based on parameters
            max_packets = packet_count if packet_count else self.config.get('max_packets', float('inf'))
            capture_start_time = time.time()

            # Process packets
            for packet in capture.sniff_continuously():
                # Check for timeout
                if timeout and time.time() - capture_start_time > timeout:
                    self.logger.info(f"Capture timeout reached ({timeout}s), stopping...")
                    break

                # Process the packet
                try:
                    if self._process_pyshark_packet(packet):
                        # Increment analyzed packets count when processing is successful
                        packets_analyzed += 1
                        capture_stats['packets_analyzed'] = packets_analyzed

                    packets_captured += 1
                    capture_stats['packets_total'] = packets_captured

                    # Check if we've reached the max packet count
                    if len(self.packets) >= max_packets:
                        self.logger.info(f"Reached maximum packet count ({max_packets}), stopping capture")
                        capture.close()
                        break

                    # Log progress periodically
                    if packets_captured % 100 == 0:
                        elapsed = time.time() - start_time
                        rate = packets_captured / elapsed if elapsed > 0 else 0
                        self.logger.info(f"Captured {packets_captured} packets ({rate:.2f} packets/sec), " +
                                        f"analyzed {len(self.packets)} license-related packets")

                except Exception as packet_ex:
                    self.logger.error(f"Error processing packet: {str(packet_ex)}")
                    capture_stats['errors'] += 1
                    # Continue capturing despite errors in individual packets
                    continue

            # Capture complete, log statistics
            end_time = time.time()
            duration = end_time - start_time
            packet_rate = packets_captured / duration if duration > 0 else 0

            summary_msg = (
                f"Capture complete. Duration: {duration:.2f}s, "
                f"Total packets: {packets_captured}, "
                f"Analyzed packets: {packets_analyzed}, "
                f"License-related packets: {len(self.packets)}, "
                f"Errors: {capture_stats['errors']}, "
                f"Rate: {packet_rate:.2f} packets/sec"
            )
            self.logger.info(summary_msg)

            # If output file was specified, verify it was saved
            if output_file and os.path.exists(output_file):
                self.logger.info(f"Capture saved to file: {output_file}")

        except Exception as e:
            self.logger.error(f"Failed to capture packets: {str(e)}")
            self.logger.error(traceback.format_exc())
            raise

    def _process_pyshark_packet(self, packet):
        """
        Process a captured packet from pyshark.

        Args:
            packet: Captured packet
        """
        try:
            # Check if it's a TCP packet
            if hasattr(packet, 'tcp') and hasattr(packet, 'ip'):
                # Extract connection information
                src_ip = packet.ip.src
                dst_ip = packet.ip.dst
                src_port = packet.tcp.srcport
                dst_port = packet.tcp.dstport

                # Create connection key for tracking connections
                conn_key = f"{src_ip}:{src_port}-{dst_ip}:{dst_port}"

                # Store connection direction information
                is_outbound = src_ip in self.local_networks
                direction = "outbound" if is_outbound else "inbound"

                # Track unique connections with enhanced metadata
                if conn_key not in self.connections:
                    # Initialize new connection with detailed tracking info
                    self.connections[conn_key] = {
                        'first_seen': float(packet.sniff_timestamp),
                        'last_seen': float(packet.sniff_timestamp),
                        'packets': 0,
                        'bytes': 0,
                        'status': 'active',
                        'direction': direction,
                        'src_ip': src_ip,
                        'src_port': src_port,
                        'dst_ip': dst_ip,
                        'dst_port': dst_port,
                        'protocol': 'TCP'
                    }

                    # Analyze connection pattern
                    if dst_port in self.license_ports:
                        self.connections[conn_key]['type'] = 'license'
                        self.license_connections.append(conn_key)
                        self.logger.info(f"Potential license traffic detected: {conn_key}")

                    self.logger.debug(f"New {direction} connection detected: {conn_key}")

                    # Add to connection timeline for temporal analysis
                    if not hasattr(self, 'connection_timeline'):
                        self.connection_timeline = []

                    self.connection_timeline.append({
                        'timestamp': float(packet.sniff_timestamp),
                        'action': 'new',
                        'conn_key': conn_key,
                        'direction': direction
                    })
                else:
                    # Update existing connection
                    self.connections[conn_key]['last_seen'] = float(packet.sniff_timestamp)

                # Check for payload
                payload = None
                if hasattr(packet, 'tcp') and hasattr(packet.tcp, 'payload'):
                    payload = bytes.fromhex(packet.tcp.payload.replace(':', ''))

                    # Look for license-related strings in payload
                    if payload and len(payload) > 10:
                        if self._check_payload_for_license_content(payload, conn_key):
                            # Mark as potential license traffic
                            self.connections[conn_key]['license_related'] = True

                # Create packet info
                packet_info = {
                    'timestamp': float(packet.sniff_timestamp),
                    'src_ip': src_ip,
                    'dst_ip': dst_ip,
                    'src_port': int(src_port),
                    'dst_port': int(dst_port),
                    'payload': payload,
                    'size': int(packet.length),
                    'connection_id': conn_key
                }

                # Update connection stats
                self.connections[conn_key]['packets'] += 1
                self.connections[conn_key]['bytes'] += int(packet.length)
                self.connections[conn_key]['last_seen'] = float(packet.sniff_timestamp)

                # Add to packets list
                self.packets.append(packet_info)

                # Update connections
                if conn_key not in self.connections:
                    self.connections[conn_key] = {
                        'src_ip': src_ip,
                        'dst_ip': dst_ip,
                        'src_port': int(src_port),
                        'dst_port': int(dst_port),
                        'packets': [],
                        'bytes_sent': 0,
                        'bytes_received': 0,
                        'start_time': float(packet.sniff_timestamp),
                        'last_time': float(packet.sniff_timestamp),
                        'is_license': False
                    }

                # Update connection info
                conn = self.connections[conn_key]
                conn['packets'].append(packet_info)
                conn['last_time'] = float(packet.sniff_timestamp)

                if src_ip == conn['src_ip']:
                    conn['bytes_sent'] += int(packet.length)
                else:
                    conn['bytes_received'] += int(packet.length)

                # Check if this is a license-related connection
                if payload:
                    for pattern in self.license_patterns:
                        if pattern in payload:
                            conn['is_license'] = True

                            # Add to license servers
                            if int(dst_port) > 1024:
                                self.license_servers.add(dst_ip)
                            else:
                                self.license_servers.add(src_ip)

                            break

                # Auto-analyze if enabled
                if self.config['auto_analyze'] and len(self.packets) % 100 == 0:
                    self.analyze_traffic()

        except Exception as e:
            self.logger.error(f"Error processing packet: {e}")

    def analyze_traffic(self):
        """
        Analyze captured traffic for license communications.

        Returns:
            dict: Analysis results
        """
        try:
            # Count packets and connections
            total_packets = len(self.packets)
            total_connections = len(self.connections)
            license_connections = sum(1 for conn in self.connections.values() if conn['is_license'])

            # Identify license servers
            license_servers = list(self.license_servers)

            # Analyze license connections
            license_conn_details = []
            # Track connection importance based on connection key patterns
            important_connections = {}
            for conn_key, conn in self.connections.items():
                # Use conn_key to determine if this is a high-priority connection
                # (e.g., if it contains specific identifiers or patterns)
                is_high_priority = any(marker in conn_key for marker in ['license', 'auth', 'key'])
                if is_high_priority:
                    important_connections[conn_key] = "HIGH"
                else:
                    important_connections[conn_key] = "NORMAL"

                if conn['is_license']:
                    # Extract connection details
                    conn_details = {
                        'conn_id': conn_key,
                        'priority': important_connections[conn_key],
                        'src_ip': conn['src_ip'],
                        'dst_ip': conn['dst_ip'],
                        'src_port': conn['src_port'],
                        'dst_port': conn['dst_port'],
                        'packets': len(conn['packets']),
                        'bytes_sent': conn['bytes_sent'],
                        'bytes_received': conn['bytes_received'],
                        'duration': conn['last_time'] - conn['start_time']
                    }

                    # Extract license patterns
                    patterns_found = set()
                    for packet in conn['packets']:
                        if packet['payload']:
                            for pattern in self.license_patterns:
                                if pattern in packet['payload']:
                                    patterns_found.add(pattern.decode('utf-8', errors='ignore'))

                    conn_details['patterns'] = list(patterns_found)
                    license_conn_details.append(conn_details)

            # Create analysis results
            results = {
                'total_packets': total_packets,
                'total_connections': total_connections,
                'license_connections': license_connections,
                'license_servers': license_servers,
                'connections_by_key': {conn_key: conn['packets'] for conn_key, conn in self.connections.items() if conn['is_license']},
                'license_conn_details': license_conn_details
            }

            # Generate visualizations
            self._generate_visualizations(results)

            return results

        except Exception as e:
            self.logger.error(f"Error analyzing traffic: {e}")
            return None

    def _generate_visualizations(self, results):
        """
        Generate visualizations of license traffic.

        Args:
            results: Analysis results
        """
        try:
            # Create timestamp for visualizations
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')

            # 1. Connection graph
            plt.figure(figsize=(10, 6))
            plt.title('License Connections')

            # Extract data
            ips = set()
            for conn in results['license_conn_details']:
                ips.add(conn['src_ip'])
                ips.add(conn['dst_ip'])

            # Create positions
            pos = {}
            client_x = 0.2
            server_x = 0.8

            client_ips = [ip for ip in ips if ip not in results['license_servers']]
            server_ips = results['license_servers']

            for i, ip in enumerate(client_ips):
                pos[ip] = (client_x, (i + 1) / (len(client_ips) + 1))

            for i, ip in enumerate(server_ips):
                pos[ip] = (server_x, (i + 1) / (len(server_ips) + 1))

            # Draw nodes
            for ip in client_ips:
                plt.plot(pos[ip][0], pos[ip][1], 'bo', markersize=10)
                plt.text(pos[ip][0] - 0.05, pos[ip][1], ip, ha='right', va='center')

            for ip in server_ips:
                plt.plot(pos[ip][0], pos[ip][1], 'rs', markersize=10)
                plt.text(pos[ip][0] + 0.05, pos[ip][1], ip, ha='left', va='center')

            # Draw edges
            for conn in results['license_conn_details']:
                src_pos = pos[conn['src_ip']]
                dst_pos = pos[conn['dst_ip']]

                # Calculate edge width based on bytes
                width = 0.5 + 2.0 * conn['bytes_sent'] / (conn['bytes_sent'] + conn['bytes_received'] + 1)

                plt.plot([src_pos[0], dst_pos[0]], [src_pos[1], dst_pos[1]], 'g-', linewidth=width)

            plt.xlim(0, 1)
            plt.ylim(0, 1)
            plt.axis('off')

            # Add legend
            plt.plot([], [], 'bo', markersize=10, label='Clients')
            plt.plot([], [], 'rs', markersize=10, label='License Servers')
            plt.plot([], [], 'g-', linewidth=2, label='Connections')
            plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=3)

